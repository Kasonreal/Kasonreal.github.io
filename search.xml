<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[概率论]]></title>
    <url>%2F2020%2F02%2F25%2F%E6%A6%82%E7%8E%87%E8%AE%BA%2F</url>
    <content type="text"><![CDATA[贝叶斯公式 $P(A|B)=P(A)\frac{P(B|A)}{P(B)}$ 先验概率： $P(A)$ 可能性函数： $P(B|A)P(B)$ 后验概率： $P(A|B)$ 似然函数 $P(x|\theta)$ $x$是已知确定的，$\theta$是变量，函数描述对于不同的模型参数，出现$x$个这样样本点的概率 最大似然估计（MLE) 利用已知的样本信息，反推最具有可能（最大概率）导致这些样本结果出现的模型参数值 使得似然函数的值最大的参数$\theta$就是我们要找的模型参数 最大后验概率估计（MAP) MAP是求$\theta$使得$P(x_0|\theta)P(\theta)$最大。即最大化$P(\theta|x_0)$ MAP就是多个作为因子的先验概率$P(\theta)$]]></content>
      <categories>
        <category>理论基础</category>
      </categories>
      <tags>
        <tag>概率论</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[论文模板]]></title>
    <url>%2F2020%2F02%2F21%2F%E8%AE%BA%E6%96%87%E7%A0%94%E7%A9%B6%E6%A8%A1%E6%9D%BF%2F</url>
    <content type="text"><![CDATA[TitleResearch ObjectiveBackground and Problems为什么要研究？ 先前研究阶段 有哪些困难？ Method(s)解决问题的理论/模型？ 是否基于前人的方法？ Conclusionstrong conclusions weak conclusions 构思 Evaluation数据来源 重要指标 Baseline 评价方案 步骤 SummaryReference]]></content>
      <categories>
        <category>论文合集</category>
      </categories>
      <tags>
        <tag>reural recommender library</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[用户画像推荐系统]]></title>
    <url>%2F2020%2F01%2F13%2F%E7%94%A8%E6%88%B7%E7%94%BB%E5%83%8F%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%2F</url>
    <content type="text"><![CDATA[用户画像推荐系统用户画像是特征空间中的高维向量 每个标签是特征空间中的基向量 用户画像系统流程 一、明确问题 我们的需求和数据的匹配 我们是用来做分类、聚类、推荐还是回归等 数据的规模、重要特征的覆盖度等 二、 数据预处理 数据集成、冗余处理、冲突处理、采样、清洗、缺失值处理、噪声处理 三、 特征工程数据和特征决定了机器学习的上限，而模型和算法只是逼近这个上限而已。 特征提取 业务日志 WEB公开数据抓取 第三方合作 特征处理 特征清洗 特征预处理： 特征选择、特征组合、降维等 特征监控 指标：时效性、覆盖率和异常值 可视化&amp;预警 四、 模型和算法 用户画像建模标签化是用户定性画像的核心，需要考虑如下问题： 如何定义和表示标签 如何对标签进行表示 如何对标签进行推理 如何验证标签 以视频画像为例 电商推荐系统基于内容 基于协同过滤 用户画像举例：医学用户画像 音乐推荐系统]]></content>
      <categories>
        <category>推荐系统</category>
      </categories>
      <tags>
        <tag>推荐系统</tag>
        <tag>用户画像</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Flink商品实时推荐系统]]></title>
    <url>%2F2020%2F01%2F11%2FFlink%E5%95%86%E5%93%81%E5%AE%9E%E6%97%B6%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%2F</url>
    <content type="text"><![CDATA[Flink商品实时推荐系统]]></content>
      <categories>
        <category>推荐系统</category>
      </categories>
      <tags>
        <tag>推荐系统</tag>
        <tag>用户画像</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[What Are You Known For? Learning User Topical Profiles with Implicit and Explicit Footprints]]></title>
    <url>%2F2019%2F12%2F26%2FWhat%20Are%20You%20Known%20For%20Learning%20User%20Topical%20Profiles%20with%20Implicit%20and%20Explicit%20Footprints%2F</url>
    <content type="text"><![CDATA[Title 你以什么著称？通过隐式和显示足迹学习用户主题画像 Research Objective通过多个足迹（多源异构）构造用户主题画像 Background and Problems 为什么 挑战 先前研究 Method(s) 解决了匿名化Web浏览历史记录的问题，同时保留服务实用性 提出PBooster框架，用于量化用户隐私和在线服务质量之间的权衡，并进行验证 Conclusion作者给了哪些结论，哪些是strong conclusions,哪些是weak的conclusions？哪些构思？ 同时考虑隐私性和效用性，设置 $\lambda$=10时，可以返回尽可能高的隐私性，同时保持与原始数据相当的效用。 Evaluation作者如何评估自己的方法，实验的setup是什么样的，有没有问题或者可以借鉴的地方 数据来源+重要指标+模型步骤+每个步骤得出的结论 Summary写完笔记之后最后填，概述文章的内容。切记需要通过自己的思考，用自己的语言描述 Notes额外笔记 Reference(optional)列出相关性高的文献，一遍之后可以继续track]]></content>
      <categories>
        <category>论文合集</category>
      </categories>
      <tags>
        <tag>用户画像</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Protecting User Privacy An Approach for Untraceable Web Browsing History and Unambiguous User Profiles]]></title>
    <url>%2F2019%2F12%2F25%2FProtecting%20User%20Privacy%20An%20Approach%20for%20Untraceable%20Web%20Browsing%20History%20and%20Unambiguous%20User%20Profiles%2F</url>
    <content type="text"><![CDATA[Title 保护用户隐私：一种不可跟踪的网页浏览历史和明确的用户画像方法 Research Objective保护用户的隐私的同时保留他们的网页浏览历史的效用。 Background and Problems 为什么 挑战 先前研究 Method(s) 解决了匿名化Web浏览历史记录的问题，同时保留服务实用性 提出PBooster框架，用于量化用户隐私和在线服务质量之间的权衡，并进行验证 Conclusion作者给了哪些结论，哪些是strong conclusions,哪些是weak的conclusions？哪些构思？ 同时考虑隐私性和效用性，设置 $\lambda$=10时，可以返回尽可能高的隐私性，同时保持与原始数据相当的效用。 Evaluation作者如何评估自己的方法，实验的setup是什么样的，有没有问题或者可以借鉴的地方 数据来源+重要指标+模型步骤+每个步骤得出的结论 Summary写完笔记之后最后填，概述文章的内容。切记需要通过自己的思考，用自己的语言描述 Notes额外笔记 Reference(optional)列出相关性高的文献，一遍之后可以继续track]]></content>
      <categories>
        <category>论文合集</category>
      </categories>
      <tags>
        <tag>用户画像</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[机器学习]]></title>
    <url>%2F2019%2F11%2F22%2F%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%2F</url>
    <content type="text"><![CDATA[机器学习引言监督学习(Supervised learning)数据集中的每个样本都有相应的“正确答案”，根据这些样本作出预测。 监督学习的类型 回归： 推出一个连续的输出 分类： 推出一组离散的结果 非监督学习(Unsupervised learning)在未加标签的数据中，试图找到隐藏的结构。 非监督学习的类型聚类，降维，隐马尔可夫模型等。 聚类的应用： 谷歌新闻：将非常多的新闻事件自动地聚类到一起 基因学的应用：根据基因将个体聚类到不同的类或组 社交网络的分析：根据Facebook或email自动给出朋友的分组 市场分析 线性回归(Linear Regression)描述回归问题的标记$m$ 代表训练集中实例的数量 $x$ 代表特征/输入变量 $y$ 代表目标变量/输出变量 $\left( x,y \right)$ 代表训练集中的实例 $\left(x^\left(i\right),y^\left(i\right)\right)$ 代表第$i$ 个观察实例 $h$ 代表学习算法的解决方案或函数也称为假设（hypothesis） h的表达形式： 一种表达形式 $h_\theta \left( x \right)=\theta_{0} + \theta_{1}x_1 +···+\theta_nx_n$ 代价函数：（均方误差） $J(\theta_0,\theta_1,···\theta_n)=\frac{1}{2m}\sum_{i=1}^m (h_\theta(x^{(i)})-y^{(i)})^2$ 这里除以m是希望之后计算梯度时大小不随样本数量的增多而增大 批量梯度下降算法： $\theta_j:=\theta_j-\alpha\frac{\partial }{\partial \theta_j}J(\theta_0,\theta_1,···\theta_n) $ 线性回归问题可以改写为： $\theta_0:=\theta_0-\alpha\frac{1}{m}\sum_{i=1}^m(h_\theta(x^{(i)})-y^{(i)}·x_0^{(i)})$ $x_0^{(i)}=1$ $\theta_1:=\theta_1-\alpha\frac{1}{m}\sum_{i=1}^m(h_\theta(x^{(i)})-y^{(i)}·x_1^{(i)})$ $···$ 123456789101112131415theta = np.zeros(X.shape[1]) # theta代表特征（变量）数def gradient(theta, X, y): # 求导，这里将x0赋为1，同其他变量一起求导 m = X.shape[0] # 样本数 inner = X.T @ (X @ theta - y) return inner / mdef batch_gradient_decent(theta, X, y, epoch, alpha=0.01): _theta = theta.copy() cost_data = [lr_cost(theta, X, y)] for _ in range(epoch): _theta = _theta - alpha * gradient(_theta, X, y) cost_data.append(lr_cost(_theta, X, y)) return _theta, cost_data 梯度下降实践特征缩放 最简单的方法: $x_n=\frac{x_n-\mu_n}{s_n}$，其中$\mu_n$是平均值，$s_n$是范围 学习率 画出代价函数随迭代次数的图像。若出现上升情形，很可能是因为学习率$\alpha$取值过大 通常考虑$\alpha=0.03,0.3,1,3,10$ 正规方程算术求解出最优$\theta$ $\theta=(X^TX)^{-1}X^Ty$ 大多数情况下，$(X^TX)^{-1}$是可逆的，若不可逆，有以下两种情况： 特征值里有一些多余的特征，如果其中$x_1$和$x_2$是线性相关的，会导致不可逆，我们需要删除重复特征里的其中一个 特征数量太多(m&lt;=n)，导致不可逆。可以用较少的特征来反映尽可能多内容，或者考虑使用正则化的方法。 $\theta$的推导过程（略） 逻辑回归在分类问题中，逻辑回归（Logistic Regression)是目前最流行使用最广泛的一种学习算法。 二分类模型假设 $h_\theta(x)=g(\theta^TX)$ 其中 X代表特征向量，g代表逻辑函数 一个常用的逻辑函数为S形函数，公式为$g(z)=\frac{1}{1+e^{-z}}$ 代价函数（交叉熵） 若仍使用平方误差，得到的代价函数是非凸函数，因此采用交叉熵 $J(\theta ) = -\frac{1}{m}\left[\sum_{i=1}^{m}y^{(i)}log(h_\theta (x^{(i)}))+(1-y^{(i)})log(1-h_\theta (x^{(i)})) \right]$ 其中，$h_\theta (x^{(i)}) = \frac{1}{1+e^{-\theta^\mathrm {T} x}}$ 梯度下降 $\frac{\partial J(\theta)}{\partial \theta_{j}} = \frac{1}{m}\left[\sum_{i=1}^{m}(h_\theta(x^{(i)})-y^{(i)})x_{j}^{(i)}\right]$ $\theta_j:=\theta_j-\alpha\frac{1}{m}\left[\sum_{i=1}^{m}(h_\theta(x^{(i)})-y^{(i)})x_{j}^{(i)}\right]$ 即使更新参数的规则看起来和线性回归一致，由于假设的定义发生了变化，所以是完全不同的 高级优化 除了梯度下降法，我们还可以采用其他方法进行优化，比如共轭梯度法，BFGS（变尺度法），L-BFGS（限制变尺度法）。这三种算法不需要手动选择学习率$\alpha$，它们内部有一个线性搜索算法 一对多使用二分类的思想，将一个类别标记为正向类，其他的所有类标记为负向类，进行多次分类。 得到的一系列模型记为： $h_\theta^{(i)}(x)=p(y=i|x;\theta)$其中：i=(1,2,…k) 目标 $\max_i h_\theta^{(i)}(x)$ 在n个分类器中输入x，选择一个让$h_\theta^{(i)}(x)$最大的i Exercise(多项式特征映射)如果样本量多，逻辑问题很复杂原始特征只有x1，x2，可以用多项式创建更多的特征。因为更多的特征可以得到的分割线可以是高阶函数的形状 eg: 有a,b两个特征，那么它的2次多项式的次数为[1,a,b,$a^2$,ab,$b^2$] 123456789101112def feature_mapping(x, y, power, as_ndarray=False):# """return mapped features as ndarray or dataframe""" # data = &#123;&#125; # # inclusive # for i in np.arange(power + 1): # for p in np.arange(i + 1): # data["f&#123;&#125;&#123;&#125;".format(i - p, p)] = np.power(x, i - p) * np.power(y, p) data = &#123;"f&#123;&#125;&#123;&#125;".format(i - p, p): np.power(x, i - p) * np.power(y, p) for i in np.arange(power + 1) for p in np.arange(i + 1) &#125; 其中power的值代表最高阶次数 Question 逻辑回归为什么是线性的？而神经网络不是线性的？ 主要依据决策边界。LR的决策边界是线性的。$\hat\theta·x=0$是线性的 而神经网络的边界不是线性的。 正则化如何解决过拟合： 减少特征变量 正则化。保留所有的特征，但是减少参数的大小 正则化线性回归正则化线性回归的代价函数： $J( \theta)=\frac{1}{2m}[ {\sum\limits_{i = 1}^m ( h_\theta( x^{(i)} - y^{(i)}) ^2+ \lambda \sum\limits_{j = 1}^n {\theta _j^2} } ]$ 此时梯度下降法： Repeat{ ${\theta _0}: = {\theta _0} - \alpha \left[ {\frac{1}{m}\sum\limits_{i = 1}^m {\left( {h_\theta \left( {x^{\left( i \right)}} \right) - {y^{\left( i \right)}}} \right)x_0^{\left( i \right)}} } \right]$ {\theta _j}: = {\theta _j} - \alpha \left[ {\frac{1}{m}\sum\limits_{i = 1}^m {\left( {h_\theta \left( {x^{\left( i \right)}} \right) - {y^{\left( i \right)}}} \right)x_j^{\left( i \right)} + \frac{\lambda }{m}{\theta _j}} } \right]\left( {j = 1,2,...,n} \right)} 正规方程求解： \theta = {\left( {X^TX + \lambda \left[ {\begin{array}{*{20}{c}} 0&0&0&0\\ 0&1&0&0\\ .&.&.&.\\ 0&0&0&1 \end{array}} \right]} \right)^{ - 1}}{X^T}y图中的矩阵尺寸为（n+1)*（n+1) 正则化逻辑回归 正规化逻辑回归代价函数 $J(\theta ) = -\frac{1}{m}\left[\sum_{i=1}^{m}y^{(i)}log(h_\theta (x^{(i)}))+(1-y^{(i)})log(1-h_\theta (x^{(i)})) \right]+\frac{\lambda}{2m}\sum_\limits{j=1}^n\theta_j^2$ 此时梯度下降法： Repeat{ ${\theta _0}: = {\theta _0} - \alpha \left[ {\frac{1}{m}\sum\limits_{i = 1}^m {\left( {h_\theta \left( {x^{\left( i \right)}} \right) - {y^{\left( i \right)}}} \right)x_0^{\left( i \right)}} } \right]$ ${\theta _j}: = {\theta _j} - \alpha \left[ {\frac{1}{m}\sum\limits_{i = 1}^m {\left( {h_\theta \left( {x^{\left( i \right)}} \right) - {y^{\left( i \right)}}} \right)x_j^{\left( i \right)} + \frac{\lambda }{m}{\theta _j}} } \right]\left( {j = 1,2,…,n} \right)$ } 神经网络代价函数 $J(\Theta) = -\frac{ 1 }{ m }[\sum_\limits{ i=1 }^{ m } \sum_\limits{ k=1 }^{ k } ({y_k^{(i)} \log(h_\Theta(x^{(i)}))_k + (1 - y_k^{(i)}) \log (1 - (h_\Theta(x^{(i)}))_k})]+\frac{\lambda}{2m}\sum_\limits{l=1}^{L-1}\sum_\limits{i=1}^{s_l}\sum_\limits{j=1}^{s_{l+1}}(\Theta_{ji}^{(l)})^2)$ 其中 ${\left( {h_\Theta }\left( x \right) \right)_i}$ = 神经网络的第i个输出 正则化项中：最里层的j循环所有的行，i循环所有的列，最外层是神经元的层数。 向前传播公式$a_j^l=\sigma(\sum\limits_kw_{jk}^l\alpha_k^{l-1}+b_j^l)$ $b_j^l$表示在$l^{th}$层第$j^{th}$个神经元的偏置，$\alpha_j^{l}$表示$l^{th}$层第$j^{th}$个神经元的激活值 $w_{jk}^l$是从$(l-1)^{th}$层的第$k^{th}$个神经元到$l^{th}$层的第$j^{th}$个神经元的连接上的权重 对于一个四层的神经网络 $\begin{array}{l} {a^{\left( 1 \right)}} = x\\ {z^{\left( 2 \right)}} = {\Theta ^{\left( 1 \right)}}{a^{\left( 1 \right)}}\\ {a^{\left( 2 \right)}} = g\left( {z^{\left( 2 \right)}} \right)\left( { + a_0^{\left( 2 \right)}} \right)\\ {z^{\left( 3 \right)}} = {\Theta ^{\left( 2 \right)}}{a^{\left( 2 \right)}}\\ {a^{\left( 3 \right)}} = g\left( {z^{\left( 3 \right)}} \right)\left( { + a_0^{\left( 3 \right)}} \right)\\ {z^{\left( 4 \right)}} = {\Theta ^{\left( 3 \right)}}{a^{\left( 3 \right)}}\\ {a^{\left( 4 \right)}} = {h_\Theta }\left( x \right) = g\left( {z^{\left( 4 \right)}} \right) \end{array}$ 反向传播反向传播的目标是计算代价函数C分别关于w和b的偏导数$\frac{\partial C}{\partial w}$和$\frac{\partial C}{\partial b}$ 反向传播算法描述 梯度检查 $\frac{\text{d}}{\text{d}\Theta}J(\Theta)\approx\frac{J(\Theta+\epsilon)-J(\Theta-\epsilon)}{2\epsilon}$ 没有使用这种方法计算偏导数的原因：反向传播可以同时计算所有的偏导数$\frac{\partial C}{\partial w}$ 随机初始化 初始化所有的$\theta$为0是不行的，因此随机初始化参数矩阵 Exercise（手写数字识别）正向传播 一维模型（一对多分类） 12for k in range(1, 11): y_matrix.append((raw_y == k).astype(int)) 采用LR，一次只能在2个类之间进行分类 k维模型 123456k_theta = np.array([logistic_regression(X, y[k]) for k in range(10)])prob_matrix = sigmoid(X @ k_theta.T)y_pred = np.argmax(prob_matrix, axis=1) #返回沿轴axis最大值的索引，axis=1代表行y_answer = raw_y.copy()y_answer[y_answer==10] = 0 # 之前已将标签为10移至第1列print(classification_report(y_answer, y_pred)) 可以进行所有标签预测 前馈预测（默认已有weight和b矩阵） 12345678910111213141516171819202122232425262728293031323334353637import numpy as npimport scipy.io as siofrom sklearn.metrics import classification_reportdef sigmoid(z): return 1 / (1 + np.exp(-z))def load_weight(path): data = sio.loadmat(path) return data['Theta1'], data['Theta2']def load_data(path): data = sio.loadmat(path) y = data.get('y') # (5000,1) y = y.reshape(y.shape[0]) # make it back to column vector X = data.get('X') # (5000,400) return X, ytheta1, theta2 = load_weight('ex3weights.mat')X, y = load_data('ex3data1.mat')X = np.insert(X, 0, values=np.ones(X.shape[0]), axis=1) # intercepta1 = Xz2 = a1 @ theta1.T # (5000, 401) @ (25,401).T = (5000, 25)z2 = np.insert(z2, 0, values=np.ones(z2.shape[0]), axis=1)a2 = sigmoid(z2)z3 = a2 @ theta2.Ta3 = sigmoid(z3)y_pred = np.argmax(a3, axis=1) + 1 # numpy is 0 base index, +1 for matlab conventionprint(classification_report(y, y_pred)) 反向传播首先进行正向传播 12345678910111213141516def feed_forward(theta, X): """apply to architecture 400+1 * 25+1 *10 X: 5000 * 401 """ t1, t2 = deserialize(theta) # t1: (25,401) t2: (10,26) m = X.shape[0] a1 = X # 5000 * 401 z2 = a1 @ t1.T # 5000 * 25 a2 = np.insert(sigmoid(z2), 0, np.ones(m), axis=1) # 5000*26 z3 = a2 @ t2.T # 5000 * 10 h = sigmoid(z3) # 5000*10, this is h_theta(X) return a1, z2, a2, z3, h # you need all those for backprop 接着进行反向梯度下降 1234567891011121314151617181920212223242526272829303132# 反向传播梯度下降def gradient(theta, X, y): # initialize t1, t2 = deserialize(theta) # t1: (25,401) t2: (10,26) m = X.shape[0] delta1 = np.zeros(t1.shape) # (25, 401) delta2 = np.zeros(t2.shape) # (10, 26) a1, z2, a2, z3, h = feed_forward(theta, X) for i in range(m): a1i = a1[i, :] # (1, 401) z2i = z2[i, :] # (1, 25) a2i = a2[i, :] # (1, 26) hi = h[i, :] # (1, 10) yi = y[i, :] # (1, 10) d3i = hi - yi # (1, 10) z2i = np.insert(z2i, 0, np.ones(1)) # make it (1, 26) to compute d2i d2i = np.multiply(t2.T @ d3i, sigmoid_gradient(z2i)) # (1, 26) # careful with np vector transpose delta2 += np.matrix(d3i).T @ np.matrix(a2i) # (1, 10).T @ (1, 26) -&gt; (10, 26) delta1 += np.matrix(d2i[1:]).T @ np.matrix(a1i) # (1, 25).T @ (1, 401) -&gt; (25, 401) delta1 = delta1 / m delta2 = delta2 / m return serialize(delta1, delta2) 注：$d3i$即为输出层误差，$d2i$为隐含层误差 这里返回的delta1，delta2是C对w求偏导的结果，这里的w包括b 梯度校验12345678910111213141516171819202122232425262728293031323334353637383940def gradient_checking(theta, X, y, epsilon, regularized=False): def a_numeric_grad(plus, minus, regularized=False): """calculate a partial gradient with respect to 1 theta""" if regularized: return (regularized_cost(plus, X, y) - regularized_cost(minus, X, y)) / (epsilon * 2) else: return (cost(plus, X, y) - cost(minus, X, y)) / (epsilon * 2) theta_matrix = expand_array(theta) # expand to (10285, 10285) epsilon_matrix = np.identity(len(theta)) * epsilon plus_matrix = theta_matrix + epsilon_matrix minus_matrix = theta_matrix - epsilon_matrix # calculate numerical gradient with respect to all theta numeric_grad = np.array([a_numeric_grad(plus_matrix[i], minus_matrix[i], regularized) for i in range(len(theta))]) # analytical grad will depend on if you want it to be regularized or not analytic_grad = regularized_gradient(theta, X, y) if regularized else gradient(theta, X, y) # If you have a correct implementation, and assuming you used EPSILON = 0.0001 # the diff below should be less than 1e-9 # this is how original matlab code do gradient checking diff = np.linalg.norm(numeric_grad - analytic_grad) / np.linalg.norm(numeric_grad + analytic_grad) def expand_array(arr): """replicate array into matrix [1, 2, 3] [[1, 2, 3], [1, 2, 3], [1, 2, 3]] """ # turn matrix back to ndarray return np.array(np.matrix(np.ones(arr.shape[0])).T @ np.matrix(arr))# 运行gradient_checking(theta, X, y, epsilon= 0.0001)#这个运行很慢，谨慎运行 If your backpropagation implementation is correct，the relative difference will be smaller than 10e-9 (assume epsilon=0.0001) 机器学习诊断法模型选择一般使用60%的数据作为训练集，使用20%的数据作为交叉验证集，20%的数据作为测试集。 这样比只分训练集和测试集相比，可以得到更好的泛化误差。 模型选择的方法 使用训练集训练出（比如）10个模型 用这些模型在交叉验证集中计算交叉验证误差（代价函数） 选取交叉验证误差最小的模型 利用这个模型计算测试集中的泛化误差（代价函数的值） 训练误差： $J_{train}(\Theta)=\frac{1}{2m}\sum_\limits{i=1}^m (h_\Theta(x^{(i)})-y^{(i)})^2$ 交叉验证误差： $J_{CV}(\Theta)=\frac{1}{2m}\sum_\limits{i=1}^m (h_\Theta(x_{CV}^{(i)})-y_{CV}^{(i)})^2$ 偏差(Bias)和方差(Variance) 如何判断是欠拟合（偏差）还是过拟合（方差）： 训练集误差和交叉验证集误差近似时：偏差/欠拟合- 交叉验证集误差&gt;&gt;训练集误差时：方差/过拟合 正则化对于${h_\theta }\left( x \right) = {\theta _0} + {\theta _1}x + {\theta _2}{x^2} + {\theta _3}{x^3} + {\theta _4}{x^4}$ 及$J( \theta)=\frac{1}{2m}[ {\sum\limits_{i = 1}^m ( h_\theta( x^{(i)} - y^{(i)}) ^2+ \lambda \sum\limits_{j = 1}^n {\theta _j^2} } ]$ 选择$\lambda$的方法 类似选择模型的方法，将训练集和交叉验证集的代价函数误差与$\lambda$的值绘制在一张图表上 当$\lambda$较小时，训练集误差较小（过拟合），交叉验证集误差较大 随着$\lambda$的增加，训练集误差不断增加（欠拟合），而交叉验证集误差先减小后增加 学习曲线学习曲线是学习算法的一个很好的合理检验（sanity check）。绘制训练集误差和交叉验证集误差随训练实例数量（m）的变化图 高偏差 高方差 对于欠拟合，增加数据到训练集不一定有帮助 对于过拟合，增加更多数据到训练集可能提高算法效果 小结改进算法策略 获取更多的训练实例 —解决高方差 尝试减少特征的数量 —解决高方差 获取更多特征 —解决高偏差 增加多项式特征 —解决高偏差 减少正则化程度$\lambda$ —解决高偏差 增加正则化程度$\lambda$ —解决高方差 神经网络中的偏差和方差 使用较小的神经网络，容易导致高偏差和欠拟合 使用较大地神经网络，容易导致高方差和过拟合 通常选择较大的神经网络并采用正则化处理，这样比使用较小网络效果要好 选择隐含层的方法和选择模型的方法类似。 机器学习系统设计学习算法的推荐方法 简答快速的实现一个算法，并用交叉验证集数据测试这个算法 绘制学习曲线，决定是增加更多数据，特征还是其他 进行误差分析：人工检查交叉验证集中我们算法产生预测误差的实例，看看这些实例是否有某种系统化变化的趋势 类偏斜类偏斜（skewed classes）：训练集中有非常多的同一种类的实例，只有很少或没有其他类的实例 分类问题指标 真阳性 TP : 预测为正，实际为正 假阳性 FP：预测为正，实际为负 假阴性 FN：预测为负，实际为正 真阴性 TN：预测为负，实际为负 查准率：预测为正的样本中有多少正样本 $P=\frac{TP}{TP+FP}$ 查全率：样本中的正例有多少被预测正确了 $R=\frac{TP}{TP+FN}$ F1-Score 衡量二分类模型精确度的一种指标 $F_1=2·\frac{precision·recall}{precision+recall}$ 机器学习数据得到一个性能很好的学习算法思路： 特征值有足够多信息，这样可以保证低偏差 支持向量机（SVM)假设函数在逻辑回归中，对于一个样本（x,y)来说，它的损失函数为：$-ylog(\frac{1}{1+e^{-\theta^Tx}})-(1-y)log(1-\frac{1}{1+e^{-\theta^Tx}})$ 对于y=1的情况，损失函数变为$-log(\frac{1}{1+e^{-z}})$ 支持向量机将绿线替换成红线，称改变后的损失函数为：$Cost_1(z)$ 对于y=0的情况 因此，支持向量机的目标是： $\underbrace{min}_\theta\left\{C\left[\sum_\limits{i=1}^my^{(i)}Cost_1\left(\theta^Tx^{(i)}\right)+\left(1-y^{(i)}\right)Cost_0\left(\theta^Tx^{(i)}\right)\right]+\frac{1}{2}\sum_\limits{j=1}^n\theta_j^2\right\}$ 其中，假设函数为： $h_\theta(x)=\begin{cases}1 &amp; \theta^Tx\geq0\\0 &amp; \theta^Tx&lt;0\end{cases}$ 大间距分类器（Large Margin Classifier)支持向量机的目标是： $\underbrace{min}_\theta\left\{C\left[\sum_\limits{i=1}^my^{(i)}Cost_1\left(\theta^Tx^{(i)}\right)+\left(1-y^{(i)}\right)Cost_0\left(\theta^Tx^{(i)}\right)\right]+\frac{1}{2}\sum_\limits{j=1}^n\theta_j^2\right\}$ 下图分别是$Cost_1(z)$和$Cost_0(z)$的示意图： 如果y=1，我们想要$\theta^Tx\geq1$（而不仅仅是$\theta^Tx\geq0)$ 如果y=0，我们想要$\theta^Tx\leq-1$（而不仅仅是$\theta^Tx&lt;0)$ 参数C对decision boundary的影响 当C非常大时，会得到黄色的线，此时过拟合 当C不是适当时，它可以忽略掉一些异常点的影响，得到更好的决策界 大间距分类器的原因 对于代价目标的后半部分：$\frac{1}{2}\sum_\limits{j=1}^n\theta_j^2$=$\frac{1}{2}\parallel\theta\parallel^2$ 当y=1时，$\theta^Tx$会朝着$\theta^Tx\geq1$的趋势去优化$\theta$，加上第二部分的$\theta$尽量小，则对于 $\theta^Tx^{(i)}=p^{(i)}\parallel\theta\parallel$，$p^{(i)}$需要尽量大 支持向量机会选择后者，因为它有较大的p 内核高斯内核 这里的”similarity”函数就是“内核”，这种内核又称为“高斯内核” 当x距离$l^{(1)}$越近，$f_1$越接近于1，越远越接近于0 选定l 通常根据训练集的数量选择地标的数量，即如果训练集中有m个实例，则选取m个地标。并且令：$l^{(1)}=x^{(1)}$，…，$l^{(m)}=x^{(m)}$。现在支持向量机的任务是： $\underbrace{min}_\theta\left\{C\left[\sum_\limits{i=1}^my^{(i)}Cost_1\left(\theta^Tf^{(i)}\right)+\left(1-y^{(i)}\right)Cost_0\left(\theta^Tf^{(i)}\right)\right]+\frac{1}{2}\sum_\limits{j=1}^n\theta_j^2\right\}$ 并且对正则化做出调整，计算$\sum_\limits{j=1}^{n=m}\theta^2=\theta^T\theta$时，用$\theta^TM\theta$代替$\theta^T\theta$，其中M是根据我们选择的核函数而不同的一个矩阵，这样做简化了计算。 参数影响 C较大，过拟合，高方差 C较小，欠拟合，高偏差 $\sigma$较大，低方差，高偏差 $\sigma$较小，低偏差，高方差 SVM使用准则 n为特征数，m为训练样本数。 n比m大很多，选用逻辑回归模型或者线性支持向量机 n较小，m大小中等，比如n在1-1000之间，m在10-10000之间，使用高斯内核的向量机 n较小，m较大，n在1-1000之间，m&gt;50000，使用支持向量机会很慢，解决方案：创造增加更多的特征，然后使用逻辑回归或者线性内核 一般，支持向量机比神经网络快，因为SVM的代价函数是凸函数，不存在局部最小值 Exercise线性内核12345678910111213141516171819202122232425import numpy as npimport pandas as pdimport sklearn.svmimport scipy.io as sioimport matplotlib.pyplot as pltmat = sio.loadmat('./data/ex6data1.mat')data = pd.DataFrame(mat.get('X'), columns=['X1', 'X2'])data['y'] = mat.get('y')# try C=1svc1 = sklearn.svm.LinearSVC(C=1, loss='hinge')svc1.fit(data[['X1', 'X2']], data['y'])# 类别预测的置信水平，这是该点与超平面距离的函数。data['SVM1 Confidence'] = svc1.decision_function(data[['X1', 'X2']])fig, ax = plt.subplots(figsize=(8,6))ax.scatter(data['X1'], data['X2'], s=50, c=data['SVM1 Confidence'], cmap='RdBu')ax.set_title('SVM (C=1) Decision Confidence')plt.show()# try C=100# 此时过拟合，decision_function的值变大 注意：svc.decision_function含义，C的取值影响 Gaussion kernels1234567891011121314151617181920212223242526272829303132333435import matplotlib.pyplot as pltfrom sklearn import svmimport numpy as npimport pandas as pdimport scipy.io as sio# kernek function 高斯核函数def gaussian_kernel(x1, x2, sigma): return np.exp(- np.power(x1 - x2, 2).sum() / (2 * (sigma ** 2)))mat = sio.loadmat('./data/ex6data2.mat')data = pd.DataFrame(mat.get('X'), columns=['X1', 'X2'])data['y'] = mat.get('y')# matplotlib画出分类图# positive = data[data['y'].isin([1])]# negative = data[data['y'].isin([0])]## fig, ax = plt.subplots(figsize=(12,8))# ax.scatter(positive['X1'], positive['X2'], s=30, marker='x', label='Positive')# ax.scatter(negative['X1'], negative['X2'], s=30, marker='o', label='Negative')# ax.legend()# plt.show()# 将使用内置的RBF内核构建支持向量机分类器，并检查其对训练数据的准确性svc = svm.SVC(C=100, kernel='rbf', gamma=10, probability=True)svc.fit(data[['X1', 'X2']], data['y'])# the predict_proba显示类别，是positive还是negativepredict_prob = svc.predict_proba(data[['X1', 'X2']])[:, 1]fig, ax = plt.subplots(figsize=(8,6))ax.scatter(data['X1'], data['X2'], s=30, c=predict_prob, cmap='Reds')plt.show() 注意：画图方法，svc.predict_proba含义 选择参数123456789101112131415161718192021222324252627282930313233343536373839404142from sklearn import svmfrom sklearn.model_selection import GridSearchCVfrom sklearn import metricsimport numpy as npimport pandas as pdimport scipy.io as siomat = sio.loadmat('./data/ex6data3.mat')training = pd.DataFrame(mat.get('X'), columns=['X1', 'X2'])training['y'] = mat.get('y')# 交叉验证集cv = pd.DataFrame(mat.get('Xval'), columns=['X1', 'X2'])cv['y'] = mat.get('yval')# manual grid searchcandidate = [0.01, 0.03, 0.1, 0.3, 1, 3, 10, 30, 100]combination = [(C, gamma) for C in candidate for gamma in candidate]search = []for C, gamma in combination: svc = svm.SVC(C=C, gamma=gamma) svc.fit(training[['X1', 'X2']], training['y']) search.append(svc.score(cv[['X1', 'X2']], cv['y']))best_score = search[np.argmax(search)]best_param = combination[np.argmax(search)]best_svc = svm.SVC(C=100, gamma=0.3)best_svc.fit(training[['X1', 'X2']], training['y'])ypred = best_svc.predict(cv[['X1', 'X2']])print(metrics.classification_report(cv['y'], ypred))# sklearn GridSearchCVparameters = &#123;'C': candidate, 'gamma': candidate&#125;svc = svm.SVC()clf = GridSearchCV(svc, parameters, n_jobs=-1)clf.fit(training[['X1', 'X2']], training['y'])ypred = clf.predict(cv[['X1', 'X2']])print(metrics.classification_report(cv['y'], ypred)) 自动搜索与人工搜索搜索得到参数不同的原因: 自动搜索只使用了部分training data,把剩余training当做CV. 垃圾邮件分类123456789101112131415161718192021222324from sklearn import svmfrom sklearn import metricsfrom sklearn.linear_model import LogisticRegressionimport scipy.io as siomat_tr = sio.loadmat('data/spamTrain.mat')X, y = mat_tr.get('X'), mat_tr.get('y').ravel()mat_test = sio.loadmat('data/spamTest.mat')test_X, test_y = mat_test.get('Xtest'), mat_test.get('ytest').ravel()svc = svm.SVC()svc.fit(X, y)pred = svc.predict(test_X)print(metrics.classification_report(test_y, pred))# 逻辑回归试试logit = LogisticRegression()logit.fit(X, y)pred = logit.predict(test_X)print(metrics.classification_report(test_y, pred)) 无监督学习K-means算法步骤随机选择K个聚类中心 重复{ 将所有样本点划分在这K类中 在每个类中重新计算聚类中心 }直至聚类中心不再变化 优化目标符号： $c^{(i)}$—样本$x^{(i)}$当前所属的类 $\mu_k$—第k个类别的中心 $\mu_c^{(i)}$—样本x(i)所属类的聚类中心 目标：$\underbrace \min _{c^{( 1 )},…,c^{( m )},\mu _1,…,\mu _K}J( c^{( 1 )},…,c^{( m )},\mu _1,…,\mu _K ) = \frac{1}{m}\sum\limits_{i = 1}^m \parallel x^{(i)}-\mu_c^{(i)} \parallel^2$ 随机初始化通常多次运行K-means算法，选取代价函数最小的结果。当K=(2-10)时可行。若K值较大，这么做也可能不会有明显改善 K值选择 “肘部法则” 根据聚类后的“后续目的”人工选择]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Tensorflow2.0]]></title>
    <url>%2F2019%2F11%2F15%2FTensorflow2.0%E4%B8%8E%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%2F</url>
    <content type="text"><![CDATA[Tensorflow 基础数据类型数值类型在Tensorflow中，为了表示方便，一般把标量、向量、矩阵统称为张量（Tensor） 通过打印张量信息，得到 123456In [2]: x = tf.constant([1,2.,3.3])xOut[2]:&lt;tf.Tensor: id=165, shape=(3,), dtype=float32, numpy=array([1. , 2. , 3.3],dtype=float32)&gt; 其中id是TensorFlow中内部索引对象的编号，shape表示张量的形状，dtype表示张量的精度，张量numpy（）方法可以返回Numpy.array类型的数据 x.numpy() 返回Numpy.array类型的数据 tf.constant([[1,2], [3,4]]) 定义2维张量 字符串类型提供常见的join()，length()，split()，lower()等工具函数 布尔类型 Tensorflow的布尔类型和Python语言的布尔类型不对等 123456In [11]:a = tf.constant(True) # 创建布尔张量a == TrueOut[11]:False 数值精度]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
        <tag>Tensorflow</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Learning Geo-Social User Topical Profiles with Bayesian Hierarchical User Factorization]]></title>
    <url>%2F2019%2F11%2F13%2FLearning%20Geo-Social%20User%20Topical%20Profiles%20with%20Bayesian%20Hierarchical%20User%20Factorization%2F</url>
    <content type="text"><![CDATA[Title 使用贝叶斯分层用户分解学习地理-社交用户主题画像 Research Objective在社会空间系统中，实现地理位置和用户画像的交互 给出已观测到的用户地理画像，对user的tag-location进行ranking预测未知的画像 Background and Problems 虽然很多现有用户画像关注的每个用户的全局视角，但仍有一些重要的地缘社会因素需要考虑 每个用户在不同地方被不同感知 具有相似画像的用户可能有巨大的地缘影响差异 建模地理画像挑战 可以采用BPTF（贝叶斯泊松张量分解）进行预测，但存在如下问题： 经常分散，由于用户异质性，地理画像中的受欢迎程度计数存在很大差异 由于多维性，通常非常稀疏 先前研究 先前研究大多集中在揭示用户的主题画像或潜在兴趣，没有明确考虑地缘社会因素。 新兴的研究方向侧重于用Gamma-Poisson分布代替传统的高斯分布对离散数据建模 利用各种背景信号来改善学习。包括文本、社交网络等 Method(s) 为了克服异质性，提出了一个两层的贝叶斯层级用户分解生成框架（bHUF），该框架很容易推广到深度用户分解。 为了减少稀疏性，研究用户上下文（特别是地理位置和社会关系），针对多层因式分解方案的非共轭性,提出一个增强模型（bHUF+）。然后，使用NB分布的数据增强方案，开发一种有效的封闭式吉布斯抽样方案进行推理 两层贝叶斯分层用户分解，将泊松伽马信念网络从二维非负计数推广到多维异构计数。与单层分解相比，用户分解的额外层通过允许更大的用户地理位置分布方差-均值比，比单层具有的学习。更好地处理过度分散和用户异质性。 Conclusion作者给了哪些结论，哪些是strong conclusions,哪些是weak的conclusions？哪些构思？ 根据GPS标记的Twitter数据集上的几个基线，对bHUF和bHUF+进行了评估，观察到bHUF在最佳替代单层基线的精确度和召回率上提高了约5%~13%，对用户地理位置和社会环境的改善率提高了6%~11% Evaluation作者如何评估自己的方法，实验的setup是什么样的，有没有问题或者可以借鉴的地方 数据来源+重要指标+模型步骤+每个步骤得出的结论 Summary写完笔记之后最后填，概述文章的内容。切记需要通过自己的思考，用自己的语言描述 Notes额外笔记 Reference(optional)列出相关性高的文献，一遍之后可以继续track]]></content>
      <categories>
        <category>论文合集</category>
      </categories>
      <tags>
        <tag>用户画像</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[推荐系统可解释性]]></title>
    <url>%2F2019%2F11%2F13%2F%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E5%8F%AF%E8%A7%A3%E9%87%8A%E6%80%A7%2F</url>
    <content type="text"><![CDATA[Introduction解释的两个维度： 显示样式（display style）： 相关用户或项目 用户或项目特征 文本解释 图像解释 社会解释 词簇 模型/方法 基于邻域 矩阵分解 主题建模 基于图 深度学习 知识图谱 关联分析 两种可解释性： 以人为方式工作的可解释模型。目前大多数属于这一类 只关注产品，将推荐模型视为一个复杂的黑盒。称为事后可解释性。 可解释性与时效性： 近些年的研究表明，这两项并不冲突，可以使用深度学习等方法来解决。 不同显示风格的解释基于相关用户和项目的解释 协同过滤和基于相关商品的解释 存在信任性和可依赖性问题，因为我并不认识相似用户。 基于特征的解释 基于特征与基于内容密切相关，推荐与用户目标文件匹配的项目特征作为解释 采用标签解释 雷达图 基于文本解释 可以分为两个方面 Aspect-level 类似基于功能的解释，通常不直接提供aspect，而是从用户意见、评论中提取。 为了提取aspect，采用 方面-观点-情感三元组 或者采用主题建模的方法。生成词云，从几个角度进行推荐 sentence-level 可以基于模板，生成句子进行推荐。 无模板，基于自然语言生成模型直接生成。将众包和计算相结合，生成个性化的自然语言解释 图像解释 通过整个图像或图像中特定视觉亮点作为解释 运用于衣服推荐（对某种样式特别钟爱）等，目前处于起步阶段。 社会解释 依据目标用户的社交关系提供解释，有助于提高用户对推荐的信任 地理-社会推荐 基于深交网络的小组推荐 推荐解释模型矩阵分解 Explicit Factor Models(EFM) 推荐用户关心的特征表现好的产品 学习基于张量分解学习对可解释推荐的特征进行排序 张量分解多任务学习，“用户偏好建模”和“有针对性的内容建模”被整合 Explainable Matrix Factorization(EMF) 基于用户项评级矩阵提供可解释的建议 主题建模基于可用的文本信息。主题建模通常以主题词云的形式为用户提供直观的解释 FLAME model(Factorized Latent Aspect Model) 了解用户对商品不同方面的不同看法。 在词云中显示与其情感成正比的方面进行解释 同时利用社会评论和可信赖的社会关系来改善评分预测 基于图的推荐解释 在top-N推荐中引入 user-item-aspect三元关系。对三元图的顶点进行排名。 不使用外部信息下，基于用户-项目聚类得到推荐。 深度学习 在文本评论中使用CNN对用户的偏好和商品属性进行建模。有选择地从具有不同注意权重的评论中选择单词，通过获得的注意权重，指出哪个部分更重要。可以突出相关词作为解释。 基于字符级RNN结构自动生成自然语言解释。 结合众包和计算的过程，生成个性化自然语言解释 为突出显示的图像区域生成自然语言解释 基于自然语言生成的可解释推荐 知识库嵌入 构造用户-物品知识图，通过知识图找到从用户到推荐商品的最短路径来进行解释 关联规则挖掘事后解释有时推荐解释不是从推荐模型本身生成的。它是在推荐模型推荐了某个项目之后，由解释模型生成的。 总结 以人为方式工作的可解释模型。目前大多数属于这一类 只关注产品，将推荐模型视为一个复杂的黑盒。称为事后可解释性]]></content>
      <categories>
        <category>推荐系统</category>
      </categories>
      <tags>
        <tag>可解释性</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[推荐系统实践]]></title>
    <url>%2F2019%2F10%2F18%2F%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E5%AE%9E%E8%B7%B5%2F</url>
    <content type="text"><![CDATA[好的推荐系统随着信息技术和互联网的发展，人们逐渐从信息匮乏的时代走入了信息过载（information overload) 。为了解决信息过载问题，出现了分类目录（雅虎、hao123） 和 搜索引擎(google) 。 和搜索引擎一样，推荐系统也是一种帮助用户快速发现有用信息的工具。但是它不需要用户提供明确需求，而是通过分析用户的历史行为给用户的兴趣建模，从而主动给用户推荐。 物品的长尾(long tail)。长尾商品代表一小部分用户的个性化需求。推荐系统通过发掘用户的行为，找到用户的个性化需求，从而将长尾商品准确地推荐给需要它的用户。 个性化推荐系统的应用几乎所有的推荐系统都是由前台的展示页面、后台的日志系统、推荐算法系统3部分构成 电子商务在亚马逊平台上 个性化推荐：基于物品、 基于好友 相关推荐列表：购买（浏览）过这个商品的用户购买的其它商品，然后进行打包销售（cross selling) 电影视频、音乐推荐电影视频主要通过基于物品的推荐 音乐推荐是推荐系统里非常特殊的领域。具有一些特点 物品空间大 听一首歌耗时很少 物品重用率很高 上下文相关 次序很重要 不需要全神贯注 高度社会化 以上特点决定了音乐是一种非常适合用来推荐的物品。 社交网络社交网络中的个性化推荐技术主要应用在三个方面： 利用用户的社交网络信息对用户进行个性化的物品推荐 信息流的会话推荐 推荐好友 会话推荐用户在Facebook上的每个分享和它的所有评论被称为一个会话，如何给这些会话排序是重要的。 个性化阅读、邮件，位置推荐个性化广告（计算广告）个性化广告与狭义个性化推荐的区别： 个性化推荐这种帮助用户找到可能令他们感兴趣的物品，而广告推荐着重帮助广告找到对他们感兴趣的用户。 个性化广告投放技术主要分3种： 上下文广告 搜索广告 个性化展示广告： 根据用户的兴趣 推荐系统的评测一个完整的推荐系统一般存在3个参与方：用户、物品提供者和提供推荐系统的网站。推荐系统是一个三方共赢的系统 推荐系统的实验方法离线实验步骤 通过日志系统获取用户行为数据，按照一定标准生成一个数据集 将数据集划分成训练集和测试集 在训练集上训练用户兴趣模型，在测试集上进行预测 通过事先定义的离线指标评测算法在测试集上预测结果 离线实验的优缺点如下： 用户调查在上线之前，需要做一次用户调查的测试。以减少直接上线的巨大风险。优点是：可以获得用户主观的感受，相对在线风险低。缺点是：很难组织大规模的测试用户，测试环境下的用户行为和真实环境下可能有所不同 在线实验AB测试是一种常见的在线评测算法的实验方法。通过一定的规则将用户随机分成几组，并对不同组的用户采用不同的算法，然后统计不同组用户的各种不同的评测指标。优点：公平缺点：周期长，所以一般只测试在离线实验和用户调查中表现好的算法。AB测试设计也是一项复杂的工程（一般不同层及控制这些层的团队需要从一个统一的地方获得自己AB测试的流量，不同层之间的流量应该是正交的） AB测试系统： 一个新的推荐算法最终上线，需要完成以上3个实验 离线实验证明它在很多离线指标上优于现有的算法 用户调查保证满意度 AB测试确定优越性 评测指标用户满意度用户满意度不能通过离线实验得到，只能通过用户调查或者在线实验。用户调查主要使用调查问卷在线实验可以通过点击率、停留时间、转化率等指标 预测准确度最重要的离线评测指标。准确度有几个方向 评分预测一般通过均方根误差(RMSE)和平均绝对误差(RAM)计算 令$r_{ui}$是用户u对物品i的实际评分，而$\hat{r}_{ui}$是推荐算法给出的预测评分 RMSE=\frac{\sqrt{\sum _{u,i\in T} ( r_{ui} - \hat{r}_{ui})^2}}{|T|}RAM=\frac{\sum _{u,i\in T} | r_{ui} - \hat{r}_{ui}|}{|T|} 如果评分系统是基于整数建立的（即用户给的评分都是整数），那么对预测结果取整会降低MAE的误差 TopN推荐TopN推荐的准确率一般通过准确率（precision)，召回率（recall)度量 令R(u)是根据用户在训练集上的行为给用户做出的推荐列表，而T(u）是用户在测试集上的行为列表 召回率定义为： Recall=\frac{\sum_ {u\in U} | R(u) \cap T(u)|}{\sum_{u\in U} | T(u) |}准确率定义为： Precision=\frac{\sum_ {u\in U} | R(u) \cap T(u)|}{\sum_{u\in U} | R(u) |}12345678910def PrecisionRecall(test, N): hit = 0 n_recall = 0 n_precision = 0 for user, items in test.items(): rank = Recommend(user, N) hit += len(rank &amp; items) n_recall += len(items) n_precision += N return [hit / (1.0 * n_recall), hit / (1.0 * n_precision)] 有时候，为了全面评测TopN推荐的准确率和召回率，会选取不同的推荐列表长度N，计算出一组准确率、召回率 覆盖率覆盖率（coverage)描述一个推荐系统对物品长尾的发掘能力。最简单的定义为推荐系统能够推荐出来的物品占总物品集合的比例。 假设系统的用户集合为U,推荐系统给每一个用户推荐一个长度为N的物品列表R(u)。$Coverage=\frac{|\cup_{u\in U}R(u)|}{|I|}$ 为了更细致地描述推荐系统发掘长尾的能力，需要统计推荐列表中不同物品出现次数的分布。如果这个分布较平，则覆盖率高。有两个指标可以用来定义覆盖率 信息熵概率分布越平均，信息熵越大，覆盖率越大。 H=-\sum_i^n p(i)\log{p(i)} 这里p(i)是物品i的流行度除以所有物品流行度之和 物品流行度： 有多少用户与该物品发生关系 基尼系数（Gini Index):G=\frac{1}{n-1}\sum_{j=1}^n(2j-n-1)p(i_j) 这里，$i_j$是按照物品流行度p()从小到大排序的物品列表中第j个物品。 基尼系数的计算原理：基尼系数=SA/(SA+SB),如果系统的流行度很平均，那么SA就会很小，分配不均匀,基尼系数很大 曲线表示最不热门的x%物品的总流行度占系统的比例y% 如果G1是从初始用户行为中计算出的物品流行度的基尼系数，G2是从推荐列表中计算出来的。如果G2&gt;G1,说明推荐算法具有马太效应。系统还需优化。 马太效应：前者更强，弱者更弱。热门的物品更加热门，冷门更加冷门。推荐系统的初衷就是希望消除马太效应 多样性假设s(i,j)∈[0,1]定义了物品i和j之间的相似度，用户u的推荐列表R(u)的多样性定义为： Diversity=1- \frac{\sum_ {i,j \ in R(u),i \neq j} s(i,j)}{\frac{1}{2} |R(u)| (|R(u)| -1)}整体多样性为所有用户推荐列表多样性的平均值 不同物品相似度函数s(i,j)可以定义不同的多样性。如果用内容相似函数描述物品间的相似度，可以得到内容多样性函数。如果用协同过滤的相似函数，得到协同过滤的多样性函数 新颖性评测新颖度的最简单的方法是利用推荐结果的平均流行度，越不热门的物品越可能让用户觉得新颖。目前的关注点在于如何在不牺牲精度的情况下提高多样性和新颖性。 计算平均流行度时对每个物品的流行度取对数，这是因为物品的流行度满足长尾分布，在取对数后，流行度的平均值更加稳定 这里取对数可以使数据更加平稳，同时可以减少区间差异影响。比如log500 + log500 &gt; log200 + log800，两个都是500，相比较后者更为流行。 惊喜度区分新颖性： 惊喜性是推荐结果和用户历史上喜欢的物品不相似，但用户觉得满意新颖性：推荐用户没听说过的 信任度目前有两种方式： 增加推荐系统的透明度（transparency) ： 提供推荐解释 通过社交网络信息，利用好友进行解释 实时性 推荐系统需要实时更新推荐列表 推荐系统需要能够将新加入系统的物品推荐给用户 健壮性（robust）除了选择健壮性高的算法，还有以下方法 设计推荐系统时尽量使用代价比较高的用户行为 使用数据前，进行攻击检测，完成对数据的清洗 总结 离线实验的优化目标是：最大化预测准确度 使得 覆盖率&gt;A , 多样性&gt;B , 新颖性&gt;C 评测维度知道一个算法在什么情况下性能最好 用户维度： 主要包括用户的人口统计学信息、活跃度以及是否为新用户 物品维度： 物品的属性信息、流行度、平均分、是不是新加的物品等 时间维度： 季节、周末还是工作日、白天还是晚上 在不同维度下的评测指标，可以帮助我们全面地了解推荐系统。 利用用户行为数据基于用户行为分析的推荐算法是个性化推荐系统的重要算法，一般把这种类型的算法成为协同过滤算法。 用户行为数据简介用户行为在个性化推荐系统中一般分两种 显性反馈(explicit feedback) 隐性反馈(implicit feedback) 隐性反馈只有正反馈 按照反馈的方向 正反馈：用户的行为倾向用户喜欢该物品 负反馈：用户的行为倾向用户不喜欢该物品 用户行为的统一表示： 代表性数据集： 无上下文信息的隐性反馈数据集： 仅包含用户ID和物品ID 无上下文信息的显性反馈数据集： 每一条记录包含用户ID、物品ID和对物品的评分 有上下文信息的隐性反馈数据集： 每一条记录包含用户ID、物品ID和对物品产生行为的时间戳 有上下文信息的显性反馈数据集： 每一条记录包括用户ID、物品ID、用户对物品的评分和评分行为发生的时间戳 用户行为分析用户活跃度和物品流行度的分布长尾分布： f(x)= \alpha_i k^ {\beta_i}物品流行度，用户的活跃度都近似长尾分布 用户活跃度和物品流行度的关系一般，用户活跃度低，其浏览物品的流行度高； 反之流行度高 协同过滤算法包括： 基于邻域的方法(neighborhood-based) 隐语义模型(latent factor model) 基于图的随机游走算法(random walk on graph) 基于邻域的方法包括： 基于用户的协同过滤算法 基于物品的协同过滤算法 实验设计和算法评测数据集MovieLens. 本章着重研究隐反馈数据集中的TopN推荐问题 实验设计将用户行为数据集按照均匀分布随机分成M份，挑选一份作为测试集，将剩下的M-1份作为训练集。进行M次实验，最后取平均值。 如果数据集够大，模型够简单，为了快速通过离线实验初步地选择算法，也可以只进行一次 评测指标精度、覆盖率、新颖性 基于邻域的算法基于用户的协同过滤基础算法令N(u)表示用户u曾今有过正反馈的物品集合，令N(v)为用户v曾经有过正反馈的物品集合，u和v的兴趣相似度 w_{uv}= \frac{|N(u) \cap N(v)|}{|N(u) \cup N(v)|}或者余弦相似度计算： w_{uv}= \frac{|N(u) \cap N(v)|}{\sqrt{|N(u) || N(v)|}}很多用户之间没有相同的交互物品，先计算出有交互物品的用户对，在除以分母$ \sqrt{|N(u)||N(v)|}$。 为此，先建立物品到用户的倒排表，对于每个物品都保存对该物品产生过行为的用户列表。$C[u][v]=K$,说明用户u和v有K个相同物品 物品-用户倒排表： 得到相似兴趣度之后，UserCF用一下公式度量用户u对物品i的感兴趣度： p(u,i)=\sum_{v\in S(u,K)\cap N(i)}w_{uv}r_{vi} 在MovieLens数据集下的性能显示：准确率和召回率：不和参数K成线性关系，选择合适的K对于获得高的推荐系统精度比较重要流行度：K越大，流行度越大覆盖率：K越大，流行度越大，覆盖率越低 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455# 基于用户余弦相似度的推荐def UserCF(train, K, N): # 计算item-&gt;user的倒排 item_user = &#123;&#125; for user in train: for item in train[user]: if item not in item_user: item_user[item] = [] item_user[item].append(user) # 计算用户相似度矩阵 sim = &#123;&#125; num = &#123;&#125; # 统计user的交互item数 for item in item_user: users = item_user[item] for i in range(len(users)): u = users[i] if u not in num: num[u] = 0 num[u] += 1 if u not in sim: sim[u] = &#123;&#125; for j in range(len(users)): if j == i: continue v = users[j] if v not in sim[u]: sim[u][v] = 0 sim[u][v] += 1 for u in sim: for v in sim[u]: sim[u][v] /= math.sqrt(num[u] * num[v]) # 按照相似度排序 sorted_user_sim = &#123;k: list(sorted(v.items(), \ key=lambda x: x[1], reverse=True)) \ for k, v in sim.items()&#125; #获取接口函数 def GetRecommendation(user): items = &#123;&#125; seen_items = set(train[user]) for v, _ in sorted_user_sim[user][:K]: for item in train[v]: # 去掉用户见过的 if item not in seen_items: if item not in items: items[item] = 0 items[item] += sim[user][v] recs = list(sorted(items.items(), key=lambda x: x[1], reverse=True))[:N] return recs return GetRecommendation 用户相似度计算的改进新的公式： w_{uv} = \frac{\sum_{i\in N(u)\cap N(v)} \frac{1}{log1+|N(i)|}}{sqrt{|N(u)||N(v)|}}该公式通过 $\frac{1}{sqrt{|N(u)||N(v)|}}$ 惩罚了用户u和用户v共同兴趣列表中热门物品对他们相似度的影响 在线使用UserCF的例子Digg博客使用UserCF进行博客推荐。增加指标如下： 用户反馈增加：用户“顶”和“踩”的行为增加了40% 平均每个用户将从34个具相似兴趣好友那儿获得200条推荐结果 用户和好友的交互活跃度增加了24% 用户评论增加了11% 基于物品的协同过滤算法基础算法随着网站的用户数目越来越大，计算用户兴趣相似度越来越困难，其运算时间复杂度和空间复杂度的增长和用户数的增长近似平方关系。并且，基于用户的协同过滤很难对推荐结果做出解释 基于物品的协同过滤算法给用户推荐那些和他们之前喜欢的物品相似的物品。ItemCF算法并不利用物品的内容属性计算物品之间的相似度，它主要通过分析用户的行为记录计算物品之间的相似度 算法: 建立用户-物品倒排表（已有），建立两两物品间的用户数矩阵，得到物品之间的余弦相似度矩阵 通过公式计算用户u对一个物品j的兴趣：p_{uj} = \sum_{i\in N(u)\cap S(j,K)} w_{ji}r_{ui} 计算物品相似度的简单例子： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849# 1. 基于物品余弦相似度的推荐def ItemCF(train, K, N): ''' :params: train, 训练数据集 :params: K, 超参数，设置取TopK相似物品数目 :params: N, 超参数，设置取TopN推荐物品数目 :return: GetRecommendation, 推荐接口函数 ''' # 计算物品相似度矩阵 sim = &#123;&#125; num = &#123;&#125; for user in train: items = train[user] for i in range(len(items)): u = items[i] if u not in num: num[u] = 0 num[u] += 1 if u not in sim: sim[u] = &#123;&#125; for j in range(len(items)): if j == i: continue v = items[j] if v not in sim[u]: sim[u][v] = 0 sim[u][v] += 1 for u in sim: for v in sim[u]: sim[u][v] /= math.sqrt(num[u] * num[v]) # 按照相似度排序 sorted_item_sim = &#123;k: list(sorted(v.items(), \ key=lambda x: x[1], reverse=True)) \ for k, v in sim.items()&#125; # 获取接口函数 def GetRecommendation(user): items = &#123;&#125; seen_items = set(train[user]) for item in train[user]: for u, _ in sorted_item_sim[item][:K]: if u not in seen_items: if u not in items: items[u] = 0 items[u] += sim[item][u] recs = list(sorted(items.items(), key=lambda x: x[1], reverse=True))[:N] return recs return GetRecommendation 用户活跃度对物品相似度的影响 IUF: 活跃用户对物品相似度的贡献应该小于不活跃的用户。 修正物品相似度的计算公式： w_{ij} = \frac{\sum _{u\in N(i)\cap N(j)} \frac{1}{log1+|N(u)|}}{\sqrt{|N(i)||N(j)|}}物品相似度的归一化将ItemCFde的相似矩阵按最大值归一化，可以提高推荐的准确率，如果已经得到物品相似度矩阵w,使用如下公式得到w’: w'_{ij} = \frac{w_{ij}}{\max _j w_{ij}} 归一化不仅增加推荐的准确度，它还可以提高推荐的覆盖率和多样性 实验结果： Item-IUF 提高了准确率和召回率，但覆盖率、流行度指标有所下降Item-Norm所有指标都有所提升。 UserCF与ItemCF的比较Digg使用UserCF,亚马逊使用ItemCF。UserCF的推荐更社会化，反映了用户所在的小型兴趣群体中物品的热门程度，而ItemCF的推荐更加个性化，反映了用户自己的兴趣传承 在离线实验中，最原始的UserCF和ItemCF中，往往ItemCF各项指标都不如UserCF. 哈利波特问题加大对物品的惩罚： w_{ij} = \frac{|N(i)\cap N(j)|}{|N(i)|^{1-\alpha} |N(j)^\alpha |}其中α∈[0.5,1]。通过提高α，可以惩罚热门的j。从离线实验中，α只有在取值为0.5时才会导致最高的准确率和召回率。α越大，覆盖率越高，平均结果的平均人们会降低。可以通过这种方法适当牺牲准确率和召回率来提高覆盖率和新颖性。 两个不同领域的最热门物品之间往往具有比较高的相似度。这时，仅仅依靠用户行为数据是不能解决的。只能依靠引入物品的内容数据解决这个问题。比如对不同领域的物品降低权重 隐语义模型(latent factor model)隐含语义分析技术(latent variable analysis)采取基于用户行为统计的自动聚类。 可以解决如下问题： 编辑的意见不能代表用户的意见 编辑很难控制分类的粒度 编辑很难给一个物品多个分类 编辑很难给出多维度的分类 编辑很难决定一个物品在某一个分类中的权重 LFM计算用户u对物品i的兴趣： Preference(u,i) =r_{ui} =p_{u} ^T q_i =\sum_{f=1} ^F p_{u,k}q_{i,k}公式中 $p_{u,k}$ 和 $q_{i,k}$是模型的参数，其中$p_{u,k}$度量了用户u的兴趣和第k个隐类的关系，$q_{i,k}$度量了第k个隐类和物品i之间的关系。 算法主要流程： 采样 损失函数 梯度下降 随机梯度下降 由于隐形反馈数据集没有负样本，因此首先要采样: 这里选取那些很热门，而用户却没有行为的物品 123456789101112131415161718# 负采样函数(注意！！！要按照流行度进行采样) def nSample(data, ratio): new_data = &#123;&#125; # 正样本 for user in data: if user not in new_data: new_data[user] = &#123;&#125; for item in data[user]: new_data[user][item] = 1 # 负样本 for user in new_data: seen = set(new_data[user]) pos_num = len(seen) item = np.random.choice(items, int(pos_num * ratio * 3), p=pops) # 按照pops的概率进行选择 item = [x for x in item if x not in seen][:int(pos_num * ratio)] new_data[user].update(&#123;x: 0 for x in item&#125;) return new_data 采样后，得到一个用户-物品集K={(u,i)},其中如果(u,i)是正样本，则有$r_{ui}$=1,否则有$r_{ui}$=0。利用如下损失函数来找最合适的参数p和q C=\sum _{(u,i)\in K}(r_{ui}- \widehat{r}_{ui})^2=\sum_{(u,i)\in K}(r_{ui} - \sum_{k=1}^K p_{u,k}q_{i,k})^2 + \lambda\parallel p_u\parallel ^2+ \lambda\parallel q_i\parallel ^2这里，$\lambda\parallel p_u\parallel ^2+ \lambda\parallel q_i\parallel ^2$ 是用来防止过拟合的正则化项。λ可通过实验获得。 梯度公式 \frac{\partial C}{\partial p_{uk}}=-2(r_{ui} - \sum_{k=1}^K p_{u,k}q_{i,k})q_{ik} +2\lambda p_{uk}\frac{\partial C}{\partial q_{ik}}=-2(r_{ui} - \sum_{k=1}^K p_{u,k}q_{i,k})p_{uk} +2\lambda q_{ik}随机梯度下降 p_{uk}=p_{uk}+\alpha ((r_{ui} - \sum_{k=1}^K p_{u,k}q_{i,k})q_{ik} - \lambda p_{uk}q_{ik}=q_{ik}+\alpha ((r_{ui} - \sum_{k=1}^K p_{u,k}q_{i,k})p_{uk} - \lambda q_{ik}12345678910111213141516171819202122232425262728# 训练 P, Q = &#123;&#125;, &#123;&#125; for user in train: P[user] = np.random.random(K) for item in items: Q[item] = np.random.random(K) for s in trange(step): data = nSample(train, ratio) for user in data: for item in data[user]: eui = data[user][item] - (P[user] * Q[item]).sum() for k in range(0, K): P[user] += lr * (Q[item] * eui - lmbda * P[user]) Q[item] += lr * (P[user] * eui - lmbda * Q[item]) lr *= 0.9 # 调整学习率 # 获取接口函数 def GetRecommendation(user): seen_items = set(train[user]) recs = &#123;&#125; for item in items: if item not in seen_items: recs[item] = (P[user] * Q[item]) recs = list(sorted(recs.items(), key=lambda x: x[1], reverse=True))[:N] return recs return GetRecommendation 结果 选取4个隐类中排名最高（$q_{ik}$最大）的一些电影，结果表明，每一类电影都是合理的，都代表了一类用户喜欢看的电影。 基于LFM的实际系统例子雅虎新闻推荐: LFM训练十分耗时，一般在实际应用中只能每天训练一次。雅虎使用如下公式预测用户u是否会单机链接i r_{ui}=x_u ^T \cdot y_i + p_u ^T \cdot q_i其中$y_i$是根据物品的内容属性直接生成的，$x_{uk}$是用户u对内容特征k的兴趣程度。用户向量$x_k$可以根据历史行为记录获得，每天只计算一些。而$p_u$、$q_i$是根据实时拿到的用户最近几小时的行为训练LFM获得的。 LFM和基于邻域的方法的比较 理论基础： LFM是一种基于机器学习的方法，邻域是一种统计学方法，没有学习过程 离线计算的空间复杂度： 假设有M个用户和N个物品。 用户相关表需要O(M×M)的空间。物品相关表需要O(N×N)的空间。 LFM需要O(F×(M+N))。LFM大量节省了训练过程中的内存 离线计算的时间复杂度： 假设有M个用户，N个物品，K条用户对物品的行为记录。 UserCF的时间复杂度 O（N×(K/N)^2); ItemCF的时间复杂度 O(M×(K/M)^2); 如果有K个隐类，迭代S次，LFM的时间复杂度 O(F×S×K)。 总体上没有质的差别 在线实时推荐： ItemCF一旦用户有了新行为，推荐列表马上发生变化。 对于LFM,当物品量很多时，O(M×N×F)，因此LFM不适合物品数非常庞大的系统。所以，当用户有了新行为，LFM的推荐列表不会发生变化 推荐解释： ItemCF可以支持很好的解释。LFM无法提供解释 基于图的模型用户行为数据的二分图表示（graph-based model)令G(V,E)表示用户物品二分图： 基于图的推荐算法图中顶点的相关度主要取决于以下因素： 两个顶点之间路径数 两个顶点之间路径长度 两个顶点之间路径经过的顶点 相关度高的顶点一般有如下特性： 两个顶点有很多路径相连 连接两个顶点之间的路径长度比较短 连接两个顶点之间的路径不会经过出度较大的顶点 算法描述从用户u对应的结点$v_u$开始，在任何一个节点，以α的概率往下走，1-α的概率回到$v_u$节点。如果继续游走，则从当前节点指向的节点中按照均匀分布随机选择一个节点作为游走下次经过的结点。经过很多次随机游走之后，每个物品结点被访问到的概率会收敛到一个数。 公式如下： PR(v)=\begin{cases}\alpha \sum_{v'\in in(v)} \frac{PR(v')}{|out(v')|} & (v\neq v_u)\\(1-\alpha)+\alpha\sum_{v'\in in(v)} \frac{PR(v')}{|out(v')|} & (v=v_u)\end{cases}公式中PR(i)表示物品i的访问概率(物品i的权重),out(i)表示物品节点i的出度。 算法举例 12345678910111213141516171819202122232425262728293031323334353637383940import timedef PersonalRank(G, alpha, root, max_depth): rank = dict() rank = &#123;x: 0 for x in G.keys()&#125; rank[root] = 1 # 开始迭代 begin = time.time() for k in range(max_depth): tmp = &#123;x: 0 for x in G.keys()&#125; # 取出节点i和他的出边尾节点集合ri for i, ri in G.items(): # 取节点i的出边的尾节点j以及边E(i,j)的权重wij,边的权重都为1，归一化后就是1/len(ri) for j, wij in ri.items(): if j not in tmp: tmp[j] = 0 tmp[j] += alpha * rank[i] / (1.0 * len(ri)) if j == root: tmp[root] += (1 - alpha) rank = tmp end = time.time() print('use_time', end-begin) lst = sorted(rank.items(), key=lambda x: x[1], reverse=True) for ele in lst: print("%s:%.3f, \t" % (ele[0], ele[1])) return rankif __name__ == '__main__': alpha = 0.6 G = &#123;'A': &#123;'a': 1, 'c': 1&#125;, 'B': &#123;'a': 1, 'b': 1, 'c': 1, 'd': 1&#125;, 'C': &#123;'c': 1, 'd': 1&#125;, 'a': &#123;'A': 1, 'B': 1&#125;, 'b': &#123;'B': 1&#125;, 'c': &#123;'A': 1, 'B': 1, 'C': 1&#125;, 'd': &#123;'B': 1, 'C': 1&#125;&#125; PersonalRank(G, alpha, 'A', 50) 结果得到对于A,d的访问概率大于b。PersonalRank算法在时间复杂度上有明显的缺点。对每个用户进行推荐时，都需要在整个用户物品二分图上进行迭代，直到整个图上的每个顶点的PR值收敛。 矩阵形式PersonalRank令M为用户物品二分图的转移概率矩阵 M_{ij}=\begin{cases}\frac{1}{|out(j)|} & if(j\in out(i))\\0 & else\end{cases}迭代公式变为： r=(1-\alpha)r_0+\alpha M^T r其中，r是个n维向量，$r_0$代表起点，第i个位置上是1，其余元素均为0。解出方程，得到： r=(1-\alpha)(1-\alpha M_T)^{-1}r_0只需计算一次 $(1-\alpha M_T)^{-1}$,快速求解。 12345678910111213141516171819202122232425262728293031import numpy as npfrom numpy.linalg import solveimport timeif __name__ == &apos;__main__&apos;: alpha = 0.8 vertex = [&apos;A&apos;, &apos;B&apos;, &apos;C&apos;, &apos;a&apos;, &apos;b&apos;, &apos;c&apos;, &apos;d&apos;] M = np.matrix([[0, 0, 0, 0.5, 0, 0.5, 0], [0, 0, 0, 0.25, 0.25, 0.25, 0.25], [0, 0, 0, 0, 0, 0.5, 0.5], [0.5, 0.5, 0, 0, 0, 0, 0], [0, 1.0, 0, 0, 0, 0, 0], [0.333, 0.333, 0.333, 0, 0, 0, 0], [0, 0.5, 0.5, 0, 0, 0, 0]]) r0 = np.matrix([[1], [0], [0], [0], [0], [0], [0]]) # 从&apos;A&apos;开始游走 print(r0.shape) n = M.shape[0] # 直接解线性方程法 A = np.eye(n)-alpha*M.T b = (1-alpha)*r0 begin = time.time() r = solve(A, b) end = time.time() print(&apos;user time&apos;, end-begin) print(r) rank = &#123;&#125; for j in range(n): rank[vertex[j]] = r[j][0] li = sorted(rank.items(), key=lambda x: x[1], reverse=True) for ele in li: print(&quot;%s:%.3f,\t&quot; % (ele[0], ele[1])) 这里采用直接解线性方程法，还可以对求解进行优化，采用CSC矩阵压缩等方法。 基于标签的推荐 标签一般分为两种： 作者或专家给物品打标签 让普通用户打标签， 也就是UGC（User Generated Content） 推荐系统实例外围架构 数据收集和存储 从实时存储的角度看，购买、收藏、评论、评分等行为都需要实时存取。而浏览网页的行为和搜索行为并不需要实时存取。 从存储媒介上来看。需要实时存取的数据存储在数据库和缓存中，大规模的非实时地存取数据存储在分布式文件系统（HDFS)中。 推荐系统架构（基于特征）特征种类 人口统计学特征 包括用户的年龄、性别、国籍信息 用户的行为特征 用户的话题特征 推荐系统架构图 推荐系统需要由多个推荐引擎组成，每个推荐引擎负责一类特征和一种任务。推荐系统的任务是将推荐引擎的结果按照一定权重或者优先级合并、排序然后返回。 推荐引擎的架构 生成用户特征向量计算特征向量时考虑一下因素： 用户行为的种类 用户行为产生的时间 用户行为的次数 物品的热门程度 特征-物品相关推荐对于每个特征，可以在相关表中存储和它最相关的N个物品的ID 特征-物品相关推荐模块可以接受一个候选物品集合。目的是保证推荐结果只包含候选物品集合中的物品。 过滤模块过滤以下物品： 用户已经产生过行为的物品 候选物品以外的物品 某些质量很差的物品 排名模块 新颖性排名 多样性 时间多样性 用户反馈 排名模块最重要的部分就是用户反馈模块。用户反馈模块主要通过分析用户之前和推荐结果的交互日志，预测用户会对什么样的推荐结果比较感兴趣。 eg： 点击率预测]]></content>
      <categories>
        <category>推荐系统</category>
      </categories>
      <tags>
        <tag>推荐系统</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hexo]]></title>
    <url>%2F2019%2F09%2F30%2Fhello%20world%2F</url>
    <content type="text"><![CDATA[Hexo基本操作本地预览1hexo s --debug 生成部署12hexo ghexo d Markdown基本操作多行代码 使用三个反引号 在每一行前面缩进4个空格 ```key 代码块 ``` key可以为cpp,java,python，key进行高亮 单行代码使用反引号 ` 来标记或插入代码区段 eg：打印使用`代码`来进行输出]]></content>
  </entry>
</search>
