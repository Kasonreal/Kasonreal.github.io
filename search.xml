<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[Learning Geo-Social User Topical Profiles with Bayesian Hierarchical User Factorization]]></title>
    <url>%2F2019%2F11%2F13%2FLearning%20Geo-Social%20User%20Topical%20Profiles%20with%20Bayesian%20Hierarchical%20User%20Factorization%2F</url>
    <content type="text"><![CDATA[Title 使用贝叶斯分层用户分解学习地理-社交用户画像 Research Objective在社会空间系统中，实现地理位置和用户画像的交互 Background and Problems 虽然很多现有用户画像关注的每个用户的全局视角，但仍有一些重要的地缘社会因素需要考虑 每个用户在不同地方被不同感知 具有相似画像的用户可能有巨大的地缘影响差异 建模地理画像挑战 经常分散，由于用户异质性，地理画像中的受欢迎程度计数存在很大差异 由于多维性，通常非常稀疏 先前研究 用户聚合标签被用于生成用户地理画像 研究基于内容、评分的画像 Method(s) 为了克服异质性，提出了一个两层的贝叶斯层级用户分解生成框架（bHUF），该框架很容易推广到深度用户分解。 为了减少稀疏性，研究用户上下文（特别是地理位置和社会关系），针对多层因式分解方案的非共轭性,提出一个增强模型（bHUF+）。然后，使用NB分布的数据增强方案，开发一种有效的封闭式吉布斯抽样方案进行推理 两层贝叶斯分层用户分解，将泊松伽马信念网络从二维非负计数推广到多维异构计数。与单层分解相比，用户分解的额外层通过允许更大的用户地理位置分布方差-均值比，比单层具有的学习。更好地处理过度分散和用户异质性。 Conclusion作者给了哪些结论，哪些是strong conclusions,哪些是weak的conclusions？哪些构思？ 根据GPS标记的Twitter数据集上的几个基线，对bHUF和bHUF+进行了评估，观察到bHUF在最佳替代单层基线的精确度和召回率上提高了约5%~13%，对用户地理位置和社会环境的改善率提高了6%~11% Evaluation作者如何评估自己的方法，实验的setup是什么样的，有没有问题或者可以借鉴的地方 数据来源+重要指标+模型步骤+每个步骤得出的结论 Summary写完笔记之后最后填，概述文章的内容。切记需要通过自己的思考，用自己的语言描述 Notes额外笔记 Reference(optional)列出相关性高的文献，一遍之后可以继续track]]></content>
      <categories>
        <category>论文合集</category>
      </categories>
      <tags>
        <tag>用户画像</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[推荐系统可解释性]]></title>
    <url>%2F2019%2F11%2F13%2F%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E5%8F%AF%E8%A7%A3%E9%87%8A%E6%80%A7%2F</url>
    <content type="text"><![CDATA[Introduction解释的两个维度： 显示样式（display style）： 相关用户或项目 用户或项目特征 文本解释 图像解释 社会解释 词簇 模型/方法 基于邻域 矩阵分解 主题建模 基于图 深度学习 知识图谱 关联分析 两种可解释性： 以人为方式工作的可解释模型。目前大多数属于这一类 只关注产品，将推荐模型视为一个复杂的黑盒。称为事后可解释性。 可解释性与时效性： 近些年的研究表明，这两项并不冲突，可以使用深度学习等方法来解决。]]></content>
      <categories>
        <category>推荐系统</category>
      </categories>
      <tags>
        <tag>可解释性</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[文献阅读方法]]></title>
    <url>%2F2019%2F11%2F13%2F%E6%96%87%E7%8C%AE%E9%98%85%E8%AF%BB%E6%96%B9%E6%B3%95%2F</url>
    <content type="text"><![CDATA[阅读文献Abstract 作者想要解决什么问题？ question 作者通过什么理论/模型来解决这个问题？ method 作者给出的答案是什么？ answer Introduction 作者为什么研究这个课题？ 目前这个课题的研究进行到了哪一个阶段？ 作者使用的理论是基于哪些假设? Conclusion 这篇文章存在哪些缺陷？ 作者关于这个课题的构思是哪几点？ Table数据来源+重要指标+模型步骤+每个步骤得出的结论 归纳 笔记框架 Title文章标题 Research Objective作者的研究目标 Background and Problems我们要研究这个课题？这个课题研究进行到哪个阶段？基于哪些假设？ Method(s)作者解决问题的理论/模型？是否基于前人的方法？ Conclusion作者给了哪些结论，哪些是strong conclusions,哪些是weak的conclusions？哪些构思？ Evaluation作者如何评估自己的方法，实验的setup是什么样的，有没有问题或者可以借鉴的地方 数据来源+重要指标+模型步骤+每个步骤得出的结论 Summary写完笔记之后最后填，概述文章的内容。切记需要通过自己的思考，用自己的语言描述 Notes额外笔记 Reference(optional)列出相关性高的文献，一遍之后可以继续track]]></content>
      <categories>
        <category>论文合集</category>
      </categories>
      <tags>
        <tag>方法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[推荐系统实践]]></title>
    <url>%2F2019%2F10%2F18%2F%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E5%AE%9E%E8%B7%B5%2F</url>
    <content type="text"><![CDATA[好的推荐系统随着信息技术和互联网的发展，人们逐渐从信息匮乏的时代走入了信息过载（information overload) 。为了解决信息过载问题，出现了分类目录（雅虎、hao123） 和 搜索引擎(google) 。 和搜索引擎一样，推荐系统也是一种帮助用户快速发现有用信息的工具。但是它不需要用户提供明确需求，而是通过分析用户的历史行为给用户的兴趣建模，从而主动给用户推荐。 物品的长尾(long tail)。长尾商品代表一小部分用户的个性化需求。推荐系统通过发掘用户的行为，找到用户的个性化需求，从而将长尾商品准确地推荐给需要它的用户。 个性化推荐系统的应用几乎所有的推荐系统都是由前台的展示页面、后台的日志系统、推荐算法系统3部分构成 电子商务在亚马逊平台上 个性化推荐：基于物品、 基于好友 相关推荐列表：购买（浏览）过这个商品的用户购买的其它商品，然后进行打包销售（cross selling) 电影视频、音乐推荐电影视频主要通过基于物品的推荐 音乐推荐是推荐系统里非常特殊的领域。具有一些特点 物品空间大 听一首歌耗时很少 物品重用率很高 上下文相关 次序很重要 不需要全神贯注 高度社会化 以上特点决定了音乐是一种非常适合用来推荐的物品。 社交网络社交网络中的个性化推荐技术主要应用在三个方面： 利用用户的社交网络信息对用户进行个性化的物品推荐 信息流的会话推荐 推荐好友 会话推荐用户在Facebook上的每个分享和它的所有评论被称为一个会话，如何给这些会话排序是重要的。 个性化阅读、邮件，位置推荐个性化广告（计算广告）个性化广告与狭义个性化推荐的区别： 个性化推荐这种帮助用户找到可能令他们感兴趣的物品，而广告推荐着重帮助广告找到对他们感兴趣的用户。 个性化广告投放技术主要分3种： 上下文广告 搜索广告 个性化展示广告： 根据用户的兴趣 推荐系统的评测一个完整的推荐系统一般存在3个参与方：用户、物品提供者和提供推荐系统的网站。推荐系统是一个三方共赢的系统 推荐系统的实验方法离线实验步骤 通过日志系统获取用户行为数据，按照一定标准生成一个数据集 将数据集划分成训练集和测试集 在训练集上训练用户兴趣模型，在测试集上进行预测 通过事先定义的离线指标评测算法在测试集上预测结果 离线实验的优缺点如下： 用户调查在上线之前，需要做一次用户调查的测试。以减少直接上线的巨大风险。优点是：可以获得用户主观的感受，相对在线风险低。缺点是：很难组织大规模的测试用户，测试环境下的用户行为和真实环境下可能有所不同 在线实验AB测试是一种常见的在线评测算法的实验方法。通过一定的规则将用户随机分成几组，并对不同组的用户采用不同的算法，然后统计不同组用户的各种不同的评测指标。优点：公平缺点：周期长，所以一般只测试在离线实验和用户调查中表现好的算法。AB测试设计也是一项复杂的工程（一般不同层及控制这些层的团队需要从一个统一的地方获得自己AB测试的流量，不同层之间的流量应该是正交的） AB测试系统： 一个新的推荐算法最终上线，需要完成以上3个实验 离线实验证明它在很多离线指标上优于现有的算法 用户调查保证满意度 AB测试确定优越性 评测指标用户满意度用户满意度不能通过离线实验得到，只能通过用户调查或者在线实验。用户调查主要使用调查问卷在线实验可以通过点击率、停留时间、转化率等指标 预测准确度最重要的离线评测指标。准确度有几个方向 评分预测一般通过均方根误差(RMSE)和平均绝对误差(RAM)计算 令$r_{ui}$是用户u对物品i的实际评分，而$\hat{r}_{ui}$是推荐算法给出的预测评分 RMSE=\frac{\sqrt{\sum _{u,i\in T} ( r_{ui} - \hat{r}_{ui})^2}}{|T|} RAM=\frac{\sum _{u,i\in T} | r_{ui} - \hat{r}_{ui}|}{|T|} 如果评分系统是基于整数建立的（即用户给的评分都是整数），那么对预测结果取整会降低MAE的误差 TopN推荐TopN推荐的准确率一般通过准确率（precision)，召回率（recall)度量 令R(u)是根据用户在训练集上的行为给用户做出的推荐列表，而T(u）是用户在测试集上的行为列表 召回率定义为： Recall=\frac{\sum_ {u\in U} | R(u) \cap T(u)|}{\sum_{u\in U} | T(u) |}准确率定义为： Precision=\frac{\sum_ {u\in U} | R(u) \cap T(u)|}{\sum_{u\in U} | R(u) |}12345678910def PrecisionRecall(test, N): hit = 0 n_recall = 0 n_precision = 0 for user, items in test.items(): rank = Recommend(user, N) hit += len(rank &amp; items) n_recall += len(items) n_precision += N return [hit / (1.0 * n_recall), hit / (1.0 * n_precision)] 有时候，为了全面评测TopN推荐的准确率和召回率，会选取不同的推荐列表长度N，计算出一组准确率、召回率 覆盖率覆盖率（coverage)描述一个推荐系统对物品长尾的发掘能力。最简单的定义为推荐系统能够推荐出来的物品占总物品集合的比例。 假设系统的用户集合为U,推荐系统给每一个用户推荐一个长度为N的物品列表R(u)。 Coverage=\frac{|\cup_{u\in U}R(u)|}{|I|}为了更细致地描述推荐系统发掘长尾的能力，需要统计推荐列表中不同物品出现次数的分布。如果这个分布较平，则覆盖率高。有两个指标可以用来定义覆盖率 信息熵概率分布越平均，信息熵越大，覆盖率越大。 H=-\sum_i^n p(i)\log{p(i)} 这里p(i)是物品i的流行度除以所有物品流行度之和 物品流行度： 有多少用户与该物品发生关系 基尼系数（Gini Index):G=\frac{1}{n-1}\sum_{j=1}^n(2j-n-1)p(i_j) 这里，$i_j$是按照物品流行度p()从小到大排序的物品列表中第j个物品。 基尼系数的计算原理：基尼系数=SA/(SA+SB),如果系统的流行度很平均，那么SA就会很小，分配不均匀,基尼系数很大 曲线表示最不热门的x%物品的总流行度占系统的比例y% 如果G1是从初始用户行为中计算出的物品流行度的基尼系数，G2是从推荐列表中计算出来的。如果G2&gt;G1,说明推荐算法具有马太效应。系统还需优化。 马太效应：前者更强，弱者更弱。热门的物品更加热门，冷门更加冷门。推荐系统的初衷就是希望消除马太效应 多样性假设s(i,j)∈[0,1]定义了物品i和j之间的相似度，用户u的推荐列表R(u)的多样性定义为： Diversity=1- \frac{\sum_ {i,j \ in R(u),i \neq j} s(i,j)}{\frac{1}{2} |R(u)| (|R(u)| -1)}整体多样性为所有用户推荐列表多样性的平均值 不同物品相似度函数s(i,j)可以定义不同的多样性。如果用内容相似函数描述物品间的相似度，可以得到内容多样性函数。如果用协同过滤的相似函数，得到协同过滤的多样性函数 新颖性评测新颖度的最简单的方法是利用推荐结果的平均流行度，越不热门的物品越可能让用户觉得新颖。目前的关注点在于如何在不牺牲精度的情况下提高多样性和新颖性。 计算平均流行度时对每个物品的流行度取对数，这是因为物品的流行度满足长尾分布，在取对数后，流行度的平均值更加稳定 这里取对数可以使数据更加平稳，同时可以减少区间差异影响。比如log500 + log500 &gt; log200 + log800，两个都是500，相比较后者更为流行。 惊喜度区分新颖性： 惊喜性是推荐结果和用户历史上喜欢的物品不相似，但用户觉得满意新颖性：推荐用户没听说过的 信任度目前有两种方式： 增加推荐系统的透明度（transparency) ： 提供推荐解释 通过社交网络信息，利用好友进行解释 实时性 推荐系统需要实时更新推荐列表 推荐系统需要能够将新加入系统的物品推荐给用户 健壮性（robust）除了选择健壮性高的算法，还有以下方法 设计推荐系统时尽量使用代价比较高的用户行为 使用数据前，进行攻击检测，完成对数据的清洗 总结 离线实验的优化目标是：最大化预测准确度 使得 覆盖率&gt;A , 多样性&gt;B , 新颖性&gt;C 评测维度知道一个算法在什么情况下性能最好 用户维度： 主要包括用户的人口统计学信息、活跃度以及是否为新用户 物品维度： 物品的属性信息、流行度、平均分、是不是新加的物品等 时间维度： 季节、周末还是工作日、白天还是晚上 在不同维度下的评测指标，可以帮助我们全面地了解推荐系统。 利用用户行为数据基于用户行为分析的推荐算法是个性化推荐系统的重要算法，一般把这种类型的算法成为协同过滤算法。 用户行为数据简介用户行为在个性化推荐系统中一般分两种 显性反馈(explicit feedback) 隐性反馈(implicit feedback) 隐性反馈只有正反馈 按照反馈的方向 正反馈：用户的行为倾向用户喜欢该物品 负反馈：用户的行为倾向用户不喜欢该物品 用户行为的统一表示： 代表性数据集： 无上下文信息的隐性反馈数据集： 仅包含用户ID和物品ID 无上下文信息的显性反馈数据集： 每一条记录包含用户ID、物品ID和对物品的评分 有上下文信息的隐性反馈数据集： 每一条记录包含用户ID、物品ID和对物品产生行为的时间戳 有上下文信息的显性反馈数据集： 每一条记录包括用户ID、物品ID、用户对物品的评分和评分行为发生的时间戳 用户行为分析用户活跃度和物品流行度的分布长尾分布： f(x)= \alpha_i k^ {\beta_i}物品流行度，用户的活跃度都近似长尾分布 用户活跃度和物品流行度的关系一般，用户活跃度低，其浏览物品的流行度高； 反之流行度高 协同过滤算法包括： 基于邻域的方法(neighborhood-based) 隐语义模型(latent factor model) 基于图的随机游走算法(random walk on graph) 基于邻域的方法包括： 基于用户的协同过滤算法 基于物品的协同过滤算法 实验设计和算法评测数据集MovieLens. 本章着重研究隐反馈数据集中的TopN推荐问题 实验设计将用户行为数据集按照均匀分布随机分成M份，挑选一份作为测试集，将剩下的M-1份作为训练集。进行M次实验，最后取平均值。 如果数据集够大，模型够简单，为了快速通过离线实验初步地选择算法，也可以只进行一次 评测指标精度、覆盖率、新颖性 基于邻域的算法基于用户的协同过滤基础算法令N(u)表示用户u曾今有过正反馈的物品集合，令N(v)为用户v曾经有过正反馈的物品集合，u和v的兴趣相似度 w_{uv}= \frac{|N(u) \cap N(v)|}{|N(u) \cup N(v)|}或者余弦相似度计算： w_{uv}= \frac{|N(u) \cap N(v)|}{\sqrt{|N(u) || N(v)|}}很多用户之间没有相同的交互物品，先计算出有交互物品的用户对，在除以分母$ \sqrt{|N(u)||N(v)|}$。 为此，先建立物品到用户的倒排表，对于每个物品都保存对该物品产生过行为的用户列表。C[u][v]=K,说明用户u和v有K个相同物品 物品-用户倒排表： 得到相似兴趣度之后，UserCF用一下公式度量用户u对物品i的感兴趣度： p(u,i)=\sum_{v\in S(u,K)\cap N(i)}w_{uv}r_{vi} 在MovieLens数据集下的性能显示：准确率和召回率：不和参数K成线性关系，选择合适的K对于获得高的推荐系统精度比较重要流行度：K越大，流行度越大覆盖率：K越大，流行度越大，覆盖率越低 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455# 基于用户余弦相似度的推荐def UserCF(train, K, N): # 计算item-&gt;user的倒排 item_user = &#123;&#125; for user in train: for item in train[user]: if item not in item_user: item_user[item] = [] item_user[item].append(user) # 计算用户相似度矩阵 sim = &#123;&#125; num = &#123;&#125; # 统计user的交互item数 for item in item_user: users = item_user[item] for i in range(len(users)): u = users[i] if u not in num: num[u] = 0 num[u] += 1 if u not in sim: sim[u] = &#123;&#125; for j in range(len(users)): if j == i: continue v = users[j] if v not in sim[u]: sim[u][v] = 0 sim[u][v] += 1 for u in sim: for v in sim[u]: sim[u][v] /= math.sqrt(num[u] * num[v]) # 按照相似度排序 sorted_user_sim = &#123;k: list(sorted(v.items(), \ key=lambda x: x[1], reverse=True)) \ for k, v in sim.items()&#125; #获取接口函数 def GetRecommendation(user): items = &#123;&#125; seen_items = set(train[user]) for v, _ in sorted_user_sim[user][:K]: for item in train[v]: # 去掉用户见过的 if item not in seen_items: if item not in items: items[item] = 0 items[item] += sim[user][v] recs = list(sorted(items.items(), key=lambda x: x[1], reverse=True))[:N] return recs return GetRecommendation 用户相似度计算的改进新的公式： w_{uv} = \frac{\sum_{i\in N(u)\cap N(v)} \frac{1}{log1+|N(i)|}}{sqrt{|N(u)||N(v)|}}该公式通过 $\frac{1}{sqrt{|N(u)||N(v)|}}$ 惩罚了用户u和用户v共同兴趣列表中热门物品对他们相似度的影响 在线使用UserCF的例子Digg博客使用UserCF进行博客推荐。增加指标如下： 用户反馈增加：用户“顶”和“踩”的行为增加了40% 平均每个用户将从34个具相似兴趣好友那儿获得200条推荐结果 用户和好友的交互活跃度增加了24% 用户评论增加了11% 基于物品的协同过滤算法基础算法随着网站的用户数目越来越大，计算用户兴趣相似度越来越困难，其运算时间复杂度和空间复杂度的增长和用户数的增长近似平方关系。并且，基于用户的协同过滤很难对推荐结果做出解释 基于物品的协同过滤算法给用户推荐那些和他们之前喜欢的物品相似的物品。ItemCF算法并不利用物品的内容属性计算物品之间的相似度，它主要通过分析用户的行为记录计算物品之间的相似度 算法: 建立用户-物品倒排表（已有），建立两两物品间的用户数矩阵，得到物品之间的余弦相似度矩阵 通过公式计算用户u对一个物品j的兴趣：p_{uj} = \sum_{i\in N(u)\cap S(j,K)} w_{ji}r_{ui} 计算物品相似度的简单例子： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849# 1. 基于物品余弦相似度的推荐def ItemCF(train, K, N): ''' :params: train, 训练数据集 :params: K, 超参数，设置取TopK相似物品数目 :params: N, 超参数，设置取TopN推荐物品数目 :return: GetRecommendation, 推荐接口函数 ''' # 计算物品相似度矩阵 sim = &#123;&#125; num = &#123;&#125; for user in train: items = train[user] for i in range(len(items)): u = items[i] if u not in num: num[u] = 0 num[u] += 1 if u not in sim: sim[u] = &#123;&#125; for j in range(len(items)): if j == i: continue v = items[j] if v not in sim[u]: sim[u][v] = 0 sim[u][v] += 1 for u in sim: for v in sim[u]: sim[u][v] /= math.sqrt(num[u] * num[v]) # 按照相似度排序 sorted_item_sim = &#123;k: list(sorted(v.items(), \ key=lambda x: x[1], reverse=True)) \ for k, v in sim.items()&#125; # 获取接口函数 def GetRecommendation(user): items = &#123;&#125; seen_items = set(train[user]) for item in train[user]: for u, _ in sorted_item_sim[item][:K]: if u not in seen_items: if u not in items: items[u] = 0 items[u] += sim[item][u] recs = list(sorted(items.items(), key=lambda x: x[1], reverse=True))[:N] return recs return GetRecommendation 用户活跃度对物品相似度的影响 IUF: 活跃用户对物品相似度的贡献应该小于不活跃的用户。 修正物品相似度的计算公式： w_{ij} = \frac{\sum _{u\in N(i)\cap N(j)} \frac{1}{log1+|N(u)|}}{\sqrt{|N(i)||N(j)|}}物品相似度的归一化将ItemCFde的相似矩阵按最大值归一化，可以提高推荐的准确率，如果已经得到物品相似度矩阵w,使用如下公式得到w’: w'_{ij} = \frac{w_{ij}}{\max _j w_{ij}} 归一化不仅增加推荐的准确度，它还可以提高推荐的覆盖率和多样性 实验结果： Item-IUF 提高了准确率和召回率，但覆盖率、流行度指标有所下降Item-Norm所有指标都有所提升。 UserCF与ItemCF的比较Digg使用UserCF,亚马逊使用ItemCF。UserCF的推荐更社会化，反映了用户所在的小型兴趣群体中物品的热门程度，而ItemCF的推荐更加个性化，反映了用户自己的兴趣传承 在离线实验中，最原始的UserCF和ItemCF中，往往ItemCF各项指标都不如UserCF. 哈利波特问题加大对物品的惩罚： w_{ij} = \frac{|N(i)\cap N(j)|}{|N(i)|^{1-\alpha} |N(j)^\alpha |}其中α∈[0.5,1]。通过提高α，可以惩罚热门的j。从离线实验中，α只有在取值为0.5时才会导致最高的准确率和召回率。α越大，覆盖率越高，平均结果的平均人们会降低。可以通过这种方法适当牺牲准确率和召回率来提高覆盖率和新颖性。 两个不同领域的最热门物品之间往往具有比较高的相似度。这时，仅仅依靠用户行为数据是不能解决的。只能依靠引入物品的内容数据解决这个问题。比如对不同领域的物品降低权重 隐语义模型(latent factor model)隐含语义分析技术(latent variable analysis)采取基于用户行为统计的自动聚类。 可以解决如下问题： 编辑的意见不能代表用户的意见 编辑很难控制分类的粒度 编辑很难给一个物品多个分类 编辑很难给出多维度的分类 编辑很难决定一个物品在某一个分类中的权重 LFM计算用户u对物品i的兴趣： Preference(u,i) =r_{ui} =p_{u} ^T q_i =\sum_{f=1} ^F p_{u,k}q_{i,k}公式中 $p_{u,k}$ 和 $q_{i,k}$是模型的参数，其中$p_{u,k}$度量了用户u的兴趣和第k个隐类的关系，$q_{i,k}$度量了第k个隐类和物品i之间的关系。 算法主要流程： 采样 损失函数 梯度下降 随机梯度下降 由于隐形反馈数据集没有负样本，因此首先要采样: 这里选取那些很热门，而用户却没有行为的物品 123456789101112131415161718# 负采样函数(注意！！！要按照流行度进行采样) def nSample(data, ratio): new_data = &#123;&#125; # 正样本 for user in data: if user not in new_data: new_data[user] = &#123;&#125; for item in data[user]: new_data[user][item] = 1 # 负样本 for user in new_data: seen = set(new_data[user]) pos_num = len(seen) item = np.random.choice(items, int(pos_num * ratio * 3), p=pops) # 按照pops的概率进行选择 item = [x for x in item if x not in seen][:int(pos_num * ratio)] new_data[user].update(&#123;x: 0 for x in item&#125;) return new_data 采样后，得到一个用户-物品集K={(u,i)},其中如果(u,i)是正样本，则有$r_{ui}$=1,否则有$r_{ui}$=0。利用如下损失函数来找最合适的参数p和q C=\sum _{(u,i)\in K}(r_{ui}- \widehat{r}_{ui})^2=\sum_{(u,i)\in K}(r_{ui} - \sum_{k=1}^K p_{u,k}q_{i,k})^2 + \lambda\parallel p_u\parallel ^2+ \lambda\parallel q_i\parallel ^2这里，$\lambda\parallel p_u\parallel ^2+ \lambda\parallel q_i\parallel ^2$ 是用来防止过拟合的正则化项。λ可通过实验获得。 梯度公式 \frac{\partial C}{\partial p_{uk}}=-2(r_{ui} - \sum_{k=1}^K p_{u,k}q_{i,k})q_{ik} +2\lambda p_{uk}\frac{\partial C}{\partial q_{ik}}=-2(r_{ui} - \sum_{k=1}^K p_{u,k}q_{i,k})p_{uk} +2\lambda q_{ik}随机梯度下降 p_{uk}=p_{uk}+\alpha ((r_{ui} - \sum_{k=1}^K p_{u,k}q_{i,k})q_{ik} - \lambda p_{uk}q_{ik}=q_{ik}+\alpha ((r_{ui} - \sum_{k=1}^K p_{u,k}q_{i,k})p_{uk} - \lambda q_{ik}12345678910111213141516171819202122232425262728# 训练 P, Q = &#123;&#125;, &#123;&#125; for user in train: P[user] = np.random.random(K) for item in items: Q[item] = np.random.random(K) for s in trange(step): data = nSample(train, ratio) for user in data: for item in data[user]: eui = data[user][item] - (P[user] * Q[item]).sum() for k in range(0, K): P[user] += lr * (Q[item] * eui - lmbda * P[user]) Q[item] += lr * (P[user] * eui - lmbda * Q[item]) lr *= 0.9 # 调整学习率 # 获取接口函数 def GetRecommendation(user): seen_items = set(train[user]) recs = &#123;&#125; for item in items: if item not in seen_items: recs[item] = (P[user] * Q[item]) recs = list(sorted(recs.items(), key=lambda x: x[1], reverse=True))[:N] return recs return GetRecommendation 结果 选取4个隐类中排名最高（$q_{ik}$最大）的一些电影，结果表明，每一类电影都是合理的，都代表了一类用户喜欢看的电影。 基于LFM的实际系统例子雅虎新闻推荐: LFM训练十分耗时，一般在实际应用中只能每天训练一次。雅虎使用如下公式预测用户u是否会单机链接i r_{ui}=x_u ^T \cdot y_i + p_u ^T \cdot q_i其中$y_i$是根据物品的内容属性直接生成的，$x_{uk}$是用户u对内容特征k的兴趣程度。用户向量$x_k$可以根据历史行为记录获得，每天只计算一些。而$p_u$、$q_i$是根据实时拿到的用户最近几小时的行为训练LFM获得的。 LFM和基于邻域的方法的比较 理论基础： LFM是一种基于机器学习的方法，邻域是一种统计学方法，没有学习过程 离线计算的空间复杂度： 假设有M个用户和N个物品。 用户相关表需要O(M×M)的空间。物品相关表需要O(N×N)的空间。 LFM需要O(F×(M+N))。LFM大量节省了训练过程中的内存 离线计算的时间复杂度： 假设有M个用户，N个物品，K条用户对物品的行为记录。 UserCF的时间复杂度 O（N×(K/N)^2); ItemCF的时间复杂度 O(M×(K/M)^2); 如果有K个隐类，迭代S次，LFM的时间复杂度 O(F×S×K)。 总体上没有质的差别 在线实时推荐： ItemCF一旦用户有了新行为，推荐列表马上发生变化。 对于LFM,当物品量很多时，O(M×N×F)，因此LFM不适合物品数非常庞大的系统。所以，当用户有了新行为，LFM的推荐列表不会发生变化 推荐解释： ItemCF可以支持很好的解释。LFM无法提供解释 基于图的模型用户行为数据的二分图表示（graph-based model)令G(V,E)表示用户物品二分图： 基于图的推荐算法图中顶点的相关度主要取决于以下因素： 两个顶点之间路径数 两个顶点之间路径长度 两个顶点之间路径经过的顶点 相关度高的顶点一般有如下特性： 两个顶点有很多路径相连 连接两个顶点之间的路径长度比较短 连接两个顶点之间的路径不会经过出度较大的顶点 算法描述从用户u对应的结点$v_u$开始，在任何一个节点，以α的概率往下走，1-α的概率回到$v_u$节点。如果继续游走，则从当前节点指向的节点中按照均匀分布随机选择一个节点作为游走下次经过的结点。经过很多次随机游走之后，每个物品结点被访问到的概率会收敛到一个数。 公式如下： PR(v)=\begin{cases}\alpha \sum_{v'\in in(v)} \frac{PR(v')}{|out(v')|} & (v\neq v_u)\\(1-\alpha)+\alpha\sum_{v'\in in(v)} \frac{PR(v')}{|out(v')|} & (v=v_u)\end{cases}公式中PR(i)表示物品i的访问概率(物品i的权重),out(i)表示物品节点i的出度。 算法举例 12345678910111213141516171819202122232425262728293031323334353637383940import timedef PersonalRank(G, alpha, root, max_depth): rank = dict() rank = &#123;x: 0 for x in G.keys()&#125; rank[root] = 1 # 开始迭代 begin = time.time() for k in range(max_depth): tmp = &#123;x: 0 for x in G.keys()&#125; # 取出节点i和他的出边尾节点集合ri for i, ri in G.items(): # 取节点i的出边的尾节点j以及边E(i,j)的权重wij,边的权重都为1，归一化后就是1/len(ri) for j, wij in ri.items(): if j not in tmp: tmp[j] = 0 tmp[j] += alpha * rank[i] / (1.0 * len(ri)) if j == root: tmp[root] += (1 - alpha) rank = tmp end = time.time() print('use_time', end-begin) lst = sorted(rank.items(), key=lambda x: x[1], reverse=True) for ele in lst: print("%s:%.3f, \t" % (ele[0], ele[1])) return rankif __name__ == '__main__': alpha = 0.6 G = &#123;'A': &#123;'a': 1, 'c': 1&#125;, 'B': &#123;'a': 1, 'b': 1, 'c': 1, 'd': 1&#125;, 'C': &#123;'c': 1, 'd': 1&#125;, 'a': &#123;'A': 1, 'B': 1&#125;, 'b': &#123;'B': 1&#125;, 'c': &#123;'A': 1, 'B': 1, 'C': 1&#125;, 'd': &#123;'B': 1, 'C': 1&#125;&#125; PersonalRank(G, alpha, 'A', 50) 结果得到对于A,d的访问概率大于b。PersonalRank算法在时间复杂度上有明显的缺点。对每个用户进行推荐时，都需要在整个用户物品二分图上进行迭代，直到整个图上的每个顶点的PR值收敛。 矩阵形式PersonalRank令M为用户物品二分图的转移概率矩阵 M_{ij}=\begin{cases}\frac{1}{|out(j)|} & if(j\in out(i))\\0 & else\end{cases}迭代公式变为： r=(1-\alpha)r_0+\alpha M^T r其中，r是个n维向量，$r_0$代表起点，第i个位置上是1，其余元素均为0。解出方程，得到： r=(1-\alpha)(1-\alpha M_T)^{-1}r_0只需计算一次 $(1-\alpha M_T)^{-1}$,快速求解。 12345678910111213141516171819202122232425262728293031import numpy as npfrom numpy.linalg import solveimport timeif __name__ == &apos;__main__&apos;: alpha = 0.8 vertex = [&apos;A&apos;, &apos;B&apos;, &apos;C&apos;, &apos;a&apos;, &apos;b&apos;, &apos;c&apos;, &apos;d&apos;] M = np.matrix([[0, 0, 0, 0.5, 0, 0.5, 0], [0, 0, 0, 0.25, 0.25, 0.25, 0.25], [0, 0, 0, 0, 0, 0.5, 0.5], [0.5, 0.5, 0, 0, 0, 0, 0], [0, 1.0, 0, 0, 0, 0, 0], [0.333, 0.333, 0.333, 0, 0, 0, 0], [0, 0.5, 0.5, 0, 0, 0, 0]]) r0 = np.matrix([[1], [0], [0], [0], [0], [0], [0]]) # 从&apos;A&apos;开始游走 print(r0.shape) n = M.shape[0] # 直接解线性方程法 A = np.eye(n)-alpha*M.T b = (1-alpha)*r0 begin = time.time() r = solve(A, b) end = time.time() print(&apos;user time&apos;, end-begin) print(r) rank = &#123;&#125; for j in range(n): rank[vertex[j]] = r[j][0] li = sorted(rank.items(), key=lambda x: x[1], reverse=True) for ele in li: print(&quot;%s:%.3f,\t&quot; % (ele[0], ele[1])) 这里采用直接解线性方程法，还可以对求解进行优化，采用CSC矩阵压缩等方法。]]></content>
      <categories>
        <category>推荐系统</category>
      </categories>
      <tags>
        <tag>推荐系统</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[回归]]></title>
    <url>%2F2019%2F10%2F08%2F%E5%9B%9E%E5%BD%92%2F</url>
    <content type="text"><![CDATA[线性回归(Linear Regression)描述回归问题的标记$m$ 代表训练集中实例的数量 $x$ 代表特征/输入变量 $y$ 代表目标变量/输出变量 $\left( x,y \right)$ 代表训练集中的实例 $\left(x^\left(i\right),y^\left(i\right)\right)$ 代表第$i$ 个观察实例 $h$ 代表学习算法的解决方案或函数也称为假设（hypothesis） h的表达形式： 一种表达形式 $h_\theta \left( x \right)=\theta_{0} + \theta_{1}x_1 +···+\theta_nx_n$ 代价函数： $J(\theta_0,\theta_1,···\theta_n)=\frac{1}{2m}\sum_{i=1}^m (h_\theta(x^{(i)})-y^{(i)})^2$ 批量梯度下降算法： $\theta_j:=\theta_j-\alpha\frac{\partial }{\partial \theta_j}J(\theta_0,\theta_1,···\theta_n) $ 线性回归问题可以改写为： $\theta_0:=\theta_0-\alpha\frac{1}{m}\sum_{i=1}^m(h_\theta(x^{(i)})-y^{(i)}·x_0^{(i)})$ $x_0^{(i)}=1$ $\theta_1:=\theta_1-\alpha\frac{1}{m}\sum_{i=1}^m(h_\theta(x^{(i)})-y^{(i)}·x_1^{(i)})$ $···$ 梯度下降实践特征缩放 最简单的方法: $x_n=\frac{x_n-\mu_n}{s_n}$，其中$\mu_n$是平均值，$s_n$是范围 学习率 画出代价函数随迭代次数的图像。若出现上升情形，很可能是因为学习率$\alpha$取值过大 通常考虑$\alpha=0.03,0.3,1,3,10$ 正规方程算术求解出最优$\theta$ $\theta=(X^TX)^{-1}X^Ty$ 大多数情况下，$(X^TX)^{-1}$是可逆的，若不可逆，有以下两种情况： 特征值里有一些多余的特征，如果其中$x_1$和$x_2$是线性相关的，会导致不可逆，我们需要删除重复特征里的其中一个 特征数量太多(m&lt;=n)，导致不可逆。可以用较少的特征来反映尽可能多内容，或者考虑使用正规化的方法。 $\theta$的推导过程（略）]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>回归</tag>
        <tag>代价函数</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[机器学习引言]]></title>
    <url>%2F2019%2F10%2F02%2F%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%BC%95%E8%A8%80%2F</url>
    <content type="text"><![CDATA[监督学习(Supervised learning)数据集中的每个样本都有相应的“正确答案”，根据这些样本作出预测。 监督学习的类型 回归： 推出一个连续的输出 分类： 推出一组离散的结果 非监督学习(Unsupervised learning)在未加标签的数据中，试图找到隐藏的结构。 非监督学习的类型聚类，降维，隐马尔可夫模型等。 聚类的应用： 谷歌新闻：将非常多的新闻事件自动地聚类到一起 基因学的应用：根据基因将个体聚类到不同的类或组 社交网络的分析：根据Facebook或email自动给出朋友的分组 市场分析]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Hexo]]></title>
    <url>%2F2019%2F09%2F30%2Fhello%20world%2F</url>
    <content type="text"><![CDATA[Hexo基本操作本地预览hexo s --debug 生成部署hexo g hexo d Markdown基本操作多行代码 使用三个反引号 在每一行前面缩进4个空格 ```key 代码块 ``` key可以为cpp,java,python，key进行高亮 单行代码使用反引号 ` 来标记或插入代码区段 eg：打印使用`代码`来进行输出]]></content>
  </entry>
</search>
