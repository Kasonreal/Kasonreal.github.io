<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[推荐系统实践]]></title>
    <url>%2F2019%2F10%2F18%2F%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E5%AE%9E%E8%B7%B5%2F</url>
    <content type="text"><![CDATA[好的推荐系统随着信息技术和互联网的发展，人们逐渐从信息匮乏的时代走入了信息过载（information overload) 。为了解决信息过载问题，出现了分类目录（雅虎、hao123） 和 搜索引擎(google) 。 和搜索引擎一样，推荐系统也是一种帮助用户快速发现有用信息的工具。但是它不需要用户提供明确需求，而是通过分析用户的历史行为给用户的兴趣建模，从而主动给用户推荐。 物品的长尾(long tail)。长尾商品代表一小部分用户的个性化需求。推荐系统通过发掘用户的行为，找到用户的个性化需求，从而将长尾商品准确地推荐给需要它的用户。 个性化推荐系统的应用几乎所有的推荐系统都是由前台的展示页面、后台的日志系统、推荐算法系统3部分构成 电子商务在亚马逊平台上 个性化推荐：基于物品、 基于好友 相关推荐列表：购买（浏览）过这个商品的用户购买的其它商品，然后进行打包销售（cross selling) 电影视频、音乐推荐电影视频主要通过基于物品的推荐 音乐推荐是推荐系统里非常特殊的领域。具有一些特点 物品空间大 听一首歌耗时很少 物品重用率很高 上下文相关 次序很重要 不需要全神贯注 高度社会化 以上特点决定了音乐是一种非常适合用来推荐的物品。 社交网络社交网络中的个性化推荐技术主要应用在三个方面： 利用用户的社交网络信息对用户进行个性化的物品推荐 信息流的会话推荐 推荐好友 会话推荐用户在Facebook上的每个分享和它的所有评论被称为一个会话，如何给这些会话排序是重要的。 个性化阅读、邮件，位置推荐个性化广告（计算广告）个性化广告与狭义个性化推荐的区别： 个性化推荐这种帮助用户找到可能令他们感兴趣的物品，而广告推荐着重帮助广告找到对他们感兴趣的用户。 个性化广告投放技术主要分3种： 上下文广告 搜索广告 个性化展示广告： 根据用户的兴趣 推荐系统的评测一个完整的推荐系统一般存在3个参与方：用户、物品提供者和提供推荐系统的网站。推荐系统是一个三方共赢的系统 推荐系统的实验方法离线实验步骤 通过日志系统获取用户行为数据，按照一定标准生成一个数据集 将数据集划分成训练集和测试集 在训练集上训练用户兴趣模型，在测试集上进行预测 通过事先定义的离线指标评测算法在测试集上预测结果 离线实验的优缺点如下： 用户调查在上线之前，需要做一次用户调查的测试。以减少直接上线的巨大风险。优点是：可以获得用户主观的感受，相对在线风险低。缺点是：很难组织大规模的测试用户，测试环境下的用户行为和真实环境下可能有所不同 在线实验AB测试是一种常见的在线评测算法的实验方法。通过一定的规则将用户随机分成几组，并对不同组的用户采用不同的算法，然后统计不同组用户的各种不同的评测指标。优点：公平缺点：周期长，所以一般只测试在离线实验和用户调查中表现好的算法。AB测试设计也是一项复杂的工程（一般不同层及控制这些层的团队需要从一个统一的地方获得自己AB测试的流量，不同层之间的流量应该是正交的） AB测试系统： 一个新的推荐算法最终上线，需要完成以上3个实验 离线实验证明它在很多离线指标上优于现有的算法 用户调查保证满意度 AB测试确定优越性 评测指标用户满意度用户满意度不能通过离线实验得到，只能通过用户调查或者在线实验。用户调查主要使用调查问卷在线实验可以通过点击率、停留时间、转化率等指标 预测准确度最重要的离线评测指标。准确度有几个方向 评分预测一般通过均方根误差(RMSE)和平均绝对误差(RAM)计算 令$r_{ui}$是用户u对物品i的实际评分，而$\hat{r}_{ui}$是推荐算法给出的预测评分 RMSE=\frac{\sqrt{\sum _{u,i\in T} ( r_{ui} - \hat{r}_{ui})^2}}{|T|} RAM=\frac{\sum _{u,i\in T} | r_{ui} - \hat{r}_{ui}|}{|T|} 如果评分系统是基于整数建立的（即用户给的评分都是整数），那么对预测结果取整会降低MAE的误差 TopN推荐TopN推荐的准确率一般通过准确率（precision)，召回率（recall)度量 令R(u)是根据用户在训练集上的行为给用户做出的推荐列表，而T(u）是用户在测试集上的行为列表 召回率定义为： Recall=\frac{\sum_ {u\in U} | R(u) \cap T(u)|}{\sum_{u\in U} | T(u) |}准确率定义为： Precision=\frac{\sum_ {u\in U} | R(u) \cap T(u)|}{\sum_{u\in U} | R(u) |}12345678910def PrecisionRecall(test, N): hit = 0 n_recall = 0 n_precision = 0 for user, items in test.items(): rank = Recommend(user, N) hit += len(rank &amp; items) n_recall += len(items) n_precision += N return [hit / (1.0 * n_recall), hit / (1.0 * n_precision)] 有时候，为了全面评测TopN推荐的准确率和召回率，会选取不同的推荐列表长度N，计算出一组准确率、召回率 覆盖率覆盖率（coverage)描述一个推荐系统对物品长尾的发掘能力。最简单的定义为推荐系统能够推荐出来的物品占总物品集合的比例。 假设系统的用户集合为U,推荐系统给每一个用户推荐一个长度为N的物品列表R(u)。 Coverage=\frac{|\cup_{u\in U}R(u)|}{|I|}为了更细致地描述推荐系统发掘长尾的能力，需要统计推荐列表中不同物品出现次数的分布。如果这个分布较平，则覆盖率高。有两个指标可以用来定义覆盖率 信息熵概率分布越平均，信息熵越大，覆盖率越大。 H=-\sum_i^n p(i)\log{p(i)} 这里p(i)是物品i的流行度除以所有物品流行度之和 物品流行度： 有多少用户与该物品发生关系 基尼系数（Gini Index):G=\frac{1}{n-1}\sum_{j=1}^n(2j-n-1)p(i_j) 这里，$i_j$是按照物品流行度p()从小到大排序的物品列表中第j个物品。 基尼系数的计算原理：基尼系数=SA/(SA+SB),如果系统的流行度很平均，那么SA就会很小，分配不均匀,基尼系数很大 曲线表示最不热门的x%物品的总流行度占系统的比例y% 如果G1是从初始用户行为中计算出的物品流行度的基尼系数，G2是从推荐列表中计算出来的。如果G2&gt;G1,说明推荐算法具有马太效应。系统还需优化。 马太效应：前者更强，弱者更弱。热门的物品更加热门，冷门更加冷门。推荐系统的初衷就是希望消除马太效应 多样性假设s(i,j)∈[0,1]定义了物品i和j之间的相似度，用户u的推荐列表R(u)的多样性定义为： Diversity=1- \frac{\sum_ {i,j \ in R(u),i \neq j} s(i,j)}{\frac{1}{2} |R(u)| (|R(u)| -1)}整体多样性为所有用户推荐列表多样性的平均值 不同物品相似度函数s(i,j)可以定义不同的多样性。如果用内容相似函数描述物品间的相似度，可以得到内容多样性函数。如果用协同过滤的相似函数，得到协同过滤的多样性函数 新颖性评测新颖度的最简单的方法是利用推荐结果的平均流行度，越不热门的物品越可能让用户觉得新颖。目前的关注点在于如何在不牺牲精度的情况下提高多样性和新颖性。 计算平均流行度时对每个物品的流行度取对数，这是因为物品的流行度满足长尾分布，在取对数后，流行度的平均值更加稳定 这里取对数可以使数据更加平稳，同时可以减少区间差异影响。比如log500 + log500 &gt; log200 + log800，两个都是500，相比较后者更为流行。 惊喜度区分新颖性： 惊喜性是推荐结果和用户历史上喜欢的物品不相似，但用户觉得满意新颖性：推荐用户没听说过的 信任度目前有两种方式： 增加推荐系统的透明度（transparency) ： 提供推荐解释 通过社交网络信息，利用好友进行解释 实时性 推荐系统需要实时更新推荐列表 推荐系统需要能够将新加入系统的物品推荐给用户 健壮性（robust）除了选择健壮性高的算法，还有以下方法 设计推荐系统时尽量使用代价比较高的用户行为 使用数据前，进行攻击检测，完成对数据的清洗 总结 离线实验的优化目标是：最大化预测准确度 使得 覆盖率&gt;A , 多样性&gt;B , 新颖性&gt;C 评测维度知道一个算法在什么情况下性能最好 用户维度： 主要包括用户的人口统计学信息、活跃度以及是否为新用户 物品维度： 物品的属性信息、流行度、平均分、是不是新加的物品等 时间维度： 季节、周末还是工作日、白天还是晚上 在不同维度下的评测指标，可以帮助我们全面地了解推荐系统。 利用用户行为数据基于用户行为分析的推荐算法是个性化推荐系统的重要算法，一般把这种类型的算法成为协同过滤算法。 用户行为数据简介用户行为在个性化推荐系统中一般分两种 显性反馈(explicit feedback) 隐性反馈(implicit feedback) 隐性反馈只有正反馈 按照反馈的方向 正反馈：用户的行为倾向用户喜欢该物品 负反馈：用户的行为倾向用户不喜欢该物品 用户行为的统一表示： 代表性数据集： 无上下文信息的隐性反馈数据集： 仅包含用户ID和物品ID 无上下文信息的显性反馈数据集： 每一条记录包含用户ID、物品ID和对物品的评分 有上下文信息的隐性反馈数据集： 每一条记录包含用户ID、物品ID和对物品产生行为的时间戳 有上下文信息的显性反馈数据集： 每一条记录包括用户ID、物品ID、用户对物品的评分和评分行为发生的时间戳 用户行为分析用户活跃度和物品流行度的分布长尾分布： f(x)= \alpha_i k^ {\beta_i}物品流行度，用户的活跃度都近似长尾分布 用户活跃度和物品流行度的关系一般，用户活跃度低，其浏览物品的流行度高； 反之流行度高 协同过滤算法包括： 基于邻域的方法(neighborhood-based) 隐语义模型(latent factor model) 基于图的随机游走算法(random walk on graph) 基于邻域的方法包括： 基于用户的协同过滤算法 基于物品的协同过滤算法 实验设计和算法评测数据集MovieLens. 本章着重研究隐反馈数据集中的TopN推荐问题 实验设计将用户行为数据集按照均匀分布随机分成M份，挑选一份作为测试集，将剩下的M-1份作为训练集。进行M次实验，最后取平均值。 如果数据集够大，模型够简单，为了快速通过离线实验初步地选择算法，也可以只进行一次 评测指标精度、覆盖率、新颖性 基于邻域的算法基于用户的协同过滤基础算法令N(u)表示用户u曾今有过正反馈的物品集合，令N(v)为用户v曾经有过正反馈的物品集合，u和v的兴趣相似度 w_{uv}= \frac{|N(u) \cap N(v)|}{|N(u) \cup N(v)|}或者余弦相似度计算： w_{uv}= \frac{|N(u) \cap N(v)|}{\sqrt{|N(u) || N(v)|}}很多用户之间没有相同的交互物品，先计算出有交互物品的用户对，在除以分母$ \sqrt{|N(u)||N(v)|}$。 为此，先建立物品到用户的倒排表，对于每个物品都保存对该物品产生过行为的用户列表。C[u][v]=K,说明用户u和v有K个相同物品 物品-用户倒排表： 得到相似兴趣度之后，UserCF用一下公式度量用户u对物品i的感兴趣度： p(u,i)=\sum_{v\in S(u,K)\cap N(i)}w_{uv}r_{vi} 在MovieLens数据集下的性能显示：准确率和召回率：不和参数K成线性关系，选择合适的K对于获得高的推荐系统精度比较重要流行度：K越大，流行度越大覆盖率：K越大，流行度越大，覆盖率越低]]></content>
      <categories>
        <category>推荐系统</category>
      </categories>
      <tags>
        <tag>推荐系统</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[回归]]></title>
    <url>%2F2019%2F10%2F08%2F%E5%9B%9E%E5%BD%92%2F</url>
    <content type="text"><![CDATA[单变量线性回归(Linear Regression with One Variable)描述回归问题的标记$m$ 代表训练集中实例的数量 $x$ 代表特征/输入变量 $y$ 代表目标变量/输出变量 $\left( x,y \right)$ 代表训练集中的实例 $\left(x^\left(i\right),y^\left(i\right)\right)$ 代表第$i$ 个观察实例 $h$ 代表学习算法的解决方案或函数也称为假设（hypothesis） h的表达方式一种可能的表达方式为：$h_\theta \left( x \right)=\theta_{0} + \theta_{1}x$]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>回归</tag>
        <tag>代价函数</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[机器学习引言]]></title>
    <url>%2F2019%2F10%2F02%2F%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%BC%95%E8%A8%80%2F</url>
    <content type="text"><![CDATA[监督学习(Supervised learning)数据集中的每个样本都有相应的“正确答案”，根据这些样本作出预测。 监督学习的类型 回归： 推出一个连续的输出 分类： 推出一组离散的结果 非监督学习(Unsupervised learning)在未加标签的数据中，试图找到隐藏的结构。 非监督学习的类型聚类，降维，隐马尔可夫模型等。 聚类的应用： 谷歌新闻：将非常多的新闻事件自动地聚类到一起 基因学的应用：根据基因将个体聚类到不同的类或组 社交网络的分析：根据Facebook或email自动给出朋友的分组 市场分析]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Hexo]]></title>
    <url>%2F2019%2F09%2F30%2Fhello%20world%2F</url>
    <content type="text"><![CDATA[Hexo基本操作本地预览hexo s --debug 生成部署hexo g hexo d Markdown基本操作多行代码 使用三个反引号 在每一行前面缩进4个空格 ```key 代码块 ``` key可以为cpp,java,python，key进行高亮 单行代码使用反引号 ` 来标记或插入代码区段 eg：打印使用`代码`来进行输出]]></content>
  </entry>
</search>
