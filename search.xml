<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[机器学习]]></title>
    <url>%2F2019%2F11%2F22%2F%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%2F</url>
    <content type="text"><![CDATA[机器学习引言监督学习(Supervised learning)数据集中的每个样本都有相应的“正确答案”，根据这些样本作出预测。 监督学习的类型 回归： 推出一个连续的输出 分类： 推出一组离散的结果 非监督学习(Unsupervised learning)在未加标签的数据中，试图找到隐藏的结构。 非监督学习的类型聚类，降维，隐马尔可夫模型等。 聚类的应用： 谷歌新闻：将非常多的新闻事件自动地聚类到一起 基因学的应用：根据基因将个体聚类到不同的类或组 社交网络的分析：根据Facebook或email自动给出朋友的分组 市场分析 线性回归(Linear Regression)描述回归问题的标记$m$ 代表训练集中实例的数量 $x$ 代表特征/输入变量 $y$ 代表目标变量/输出变量 $\left( x,y \right)$ 代表训练集中的实例 $\left(x^\left(i\right),y^\left(i\right)\right)$ 代表第$i$ 个观察实例 $h$ 代表学习算法的解决方案或函数也称为假设（hypothesis） h的表达形式： 一种表达形式 $h_\theta \left( x \right)=\theta_{0} + \theta_{1}x_1 +···+\theta_nx_n$ 代价函数：（均方误差） $J(\theta_0,\theta_1,···\theta_n)=\frac{1}{2m}\sum_{i=1}^m (h_\theta(x^{(i)})-y^{(i)})^2$ 这里除以m是希望之后计算梯度时大小不随样本数量的增多而增大 批量梯度下降算法： $\theta_j:=\theta_j-\alpha\frac{\partial }{\partial \theta_j}J(\theta_0,\theta_1,···\theta_n) $ 线性回归问题可以改写为： $\theta_0:=\theta_0-\alpha\frac{1}{m}\sum_{i=1}^m(h_\theta(x^{(i)})-y^{(i)}·x_0^{(i)})$ $x_0^{(i)}=1$ $\theta_1:=\theta_1-\alpha\frac{1}{m}\sum_{i=1}^m(h_\theta(x^{(i)})-y^{(i)}·x_1^{(i)})$ $···$ 123456789101112131415theta = np.zeros(X.shape[1]) # theta代表特征（变量）数def gradient(theta, X, y): # 求导，这里将x0赋为1，同其他变量一起求导 m = X.shape[0] # 样本数 inner = X.T @ (X @ theta - y) return inner / mdef batch_gradient_decent(theta, X, y, epoch, alpha=0.01): _theta = theta.copy() cost_data = [lr_cost(theta, X, y)] for _ in range(epoch): _theta = _theta - alpha * gradient(_theta, X, y) cost_data.append(lr_cost(_theta, X, y)) return _theta, cost_data 梯度下降实践特征缩放 最简单的方法: $x_n=\frac{x_n-\mu_n}{s_n}$，其中$\mu_n$是平均值，$s_n$是范围 学习率 画出代价函数随迭代次数的图像。若出现上升情形，很可能是因为学习率$\alpha$取值过大 通常考虑$\alpha=0.03,0.3,1,3,10$ 正规方程算术求解出最优$\theta$ $\theta=(X^TX)^{-1}X^Ty$ 大多数情况下，$(X^TX)^{-1}$是可逆的，若不可逆，有以下两种情况： 特征值里有一些多余的特征，如果其中$x_1$和$x_2$是线性相关的，会导致不可逆，我们需要删除重复特征里的其中一个 特征数量太多(m&lt;=n)，导致不可逆。可以用较少的特征来反映尽可能多内容，或者考虑使用正则化的方法。 $\theta$的推导过程（略） 逻辑回归在分类问题中，逻辑回归（Logistic Regression)是目前最流行使用最广泛的一种学习算法。 二分类模型假设 $h_\theta(x)=g(\theta^TX)$ 其中 X代表特征向量，g代表逻辑函数 一个常用的逻辑函数为S形函数，公式为$g(z)=\frac{1}{1+e^{-z}}$ 代价函数（交叉熵） 若仍使用平方误差，得到的代价函数是非凸函数，因此采用交叉熵 $J(\theta ) = -\frac{1}{m}\left[\sum_{i=1}^{m}y^{(i)}log(h_\theta (x^{(i)}))+(1-y^{(i)})log(1-h_\theta (x^{(i)})) \right]$ 其中，$h_\theta (x^{(i)}) = \frac{1}{1+e^{-\theta^\mathrm {T} x}}$ 梯度下降 $\frac{\partial J(\theta)}{\partial \theta_{j}} = \frac{1}{m}\left[\sum_{i=1}^{m}(h_\theta(x^{(i)})-y^{(i)})x_{j}^{(i)}\right]$ $\theta_j:=\theta_j-\alpha\frac{1}{m}\left[\sum_{i=1}^{m}(h_\theta(x^{(i)})-y^{(i)})x_{j}^{(i)}\right]$ 即使更新参数的规则看起来和线性回归一致，由于假设的定义发生了变化，所以是完全不同的 高级优化 除了梯度下降法，我们还可以采用其他方法进行优化，比如共轭梯度法，BFGS（变尺度法），L-BFGS（限制变尺度法）。这三种算法不需要手动选择学习率$\alpha$，它们内部有一个线性搜索算法 一对多使用二分类的思想，将一个类别标记为正向类，其他的所有类标记为负向类，进行多次分类。 得到的一系列模型记为： $h_\theta^{(i)}(x)=p(y=i|x;\theta)$其中：i=(1,2,…k) 目标 $\max_i h_\theta^{(i)}(x)$ 在n个分类器中输入x，选择一个让$h_\theta^{(i)}(x)$最大的i Exercise(多项式特征映射)如果样本量多，逻辑问题很复杂原始特征只有x1，x2，可以用多项式创建更多的特征。因为更多的特征可以得到的分割线可以是高阶函数的形状 eg: 有a,b两个特征，那么它的2次多项式的次数为[1,a,b,$a^2$,ab,$b^2$] 123456789101112def feature_mapping(x, y, power, as_ndarray=False):# """return mapped features as ndarray or dataframe""" # data = &#123;&#125; # # inclusive # for i in np.arange(power + 1): # for p in np.arange(i + 1): # data["f&#123;&#125;&#123;&#125;".format(i - p, p)] = np.power(x, i - p) * np.power(y, p) data = &#123;"f&#123;&#125;&#123;&#125;".format(i - p, p): np.power(x, i - p) * np.power(y, p) for i in np.arange(power + 1) for p in np.arange(i + 1) &#125; 其中power的值代表最高阶次数 Question 逻辑回归为什么是线性的？而神经网络不是线性的？ 主要依据决策边界。LR的决策边界是线性的。$\hat\theta·x=0$是线性的 而神经网络的边界不是线性的。 正则化如何解决过拟合： 减少特征变量 正则化。保留所有的特征，但是减少参数的大小 正则化线性回归正则化线性回归的代价函数： $J( \theta)=\frac{1}{2m}[ {\sum\limits_{i = 1}^m ( h_\theta( x^{(i)} - y^{(i)}) ^2+ \lambda \sum\limits_{j = 1}^n {\theta _j^2} } ]$ 此时梯度下降法： Repeat{ ${\theta _0}: = {\theta _0} - \alpha \left[ {\frac{1}{m}\sum\limits_{i = 1}^m {\left( {h_\theta \left( {x^{\left( i \right)}} \right) - {y^{\left( i \right)}}} \right)x_0^{\left( i \right)}} } \right]$ {\theta _j}: = {\theta _j} - \alpha \left[ {\frac{1}{m}\sum\limits_{i = 1}^m {\left( {h_\theta \left( {x^{\left( i \right)}} \right) - {y^{\left( i \right)}}} \right)x_j^{\left( i \right)} + \frac{\lambda }{m}{\theta _j}} } \right]\left( {j = 1,2,...,n} \right)} 正规方程求解： \theta = {\left( {X^TX + \lambda \left[ {\begin{array}{*{20}{c}} 0&0&0&0\\ 0&1&0&0\\ .&.&.&.\\ 0&0&0&1 \end{array}} \right]} \right)^{ - 1}}{X^T}y图中的矩阵尺寸为（n+1)*（n+1) 正则化逻辑回归 正规化逻辑回归代价函数 $J(\theta ) = -\frac{1}{m}\left[\sum_{i=1}^{m}y^{(i)}log(h_\theta (x^{(i)}))+(1-y^{(i)})log(1-h_\theta (x^{(i)})) \right]+\frac{\lambda}{2m}\sum_\limits{j=1}^n\theta_j^2$ 此时梯度下降法： Repeat{ ${\theta _0}: = {\theta _0} - \alpha \left[ {\frac{1}{m}\sum\limits_{i = 1}^m {\left( {h_\theta \left( {x^{\left( i \right)}} \right) - {y^{\left( i \right)}}} \right)x_0^{\left( i \right)}} } \right]$ ${\theta _j}: = {\theta _j} - \alpha \left[ {\frac{1}{m}\sum\limits_{i = 1}^m {\left( {h_\theta \left( {x^{\left( i \right)}} \right) - {y^{\left( i \right)}}} \right)x_j^{\left( i \right)} + \frac{\lambda }{m}{\theta _j}} } \right]\left( {j = 1,2,…,n} \right)$ } 神经网络代价函数 $J(\Theta) = -\frac{ 1 }{ m }[\sum_\limits{ i=1 }^{ m } \sum_\limits{ k=1 }^{ k } ({y_k^{(i)} \log(h_\Theta(x^{(i)}))_k + (1 - y_k^{(i)}) \log (1 - (h_\Theta(x^{(i)}))_k})]+\frac{\lambda}{2m}\sum_\limits{l=1}^{L-1}\sum_\limits{i=1}^{s_l}\sum_\limits{j=1}^{s_{l+1}}(\Theta_{ji}^{(l)})^2)$ 其中 ${\left( {h_\Theta }\left( x \right) \right)_i}$ = 神经网络的第i个输出 正则化项中：最里层的j循环所有的行，i循环所有的列，最外层是神经元的层数。 向前传播公式$a_j^l=\sigma(\sum\limits_kw_{jk}^l\alpha_k^{l-1}+b_j^l)$ $b_j^l$表示在$l^{th}$层第$j^{th}$个神经元的偏置，$\alpha_j^{l}$表示$l^{th}$层第$j^{th}$个神经元的激活值 $w_{jk}^l$是从$(l-1)^{th}$层的第$k^{th}$个神经元到$l^{th}$层的第$j^{th}$个神经元的连接上的权重 对于一个四层的神经网络 $\begin{array}{l} {a^{\left( 1 \right)}} = x\\ {z^{\left( 2 \right)}} = {\Theta ^{\left( 1 \right)}}{a^{\left( 1 \right)}}\\ {a^{\left( 2 \right)}} = g\left( {z^{\left( 2 \right)}} \right)\left( { + a_0^{\left( 2 \right)}} \right)\\ {z^{\left( 3 \right)}} = {\Theta ^{\left( 2 \right)}}{a^{\left( 2 \right)}}\\ {a^{\left( 3 \right)}} = g\left( {z^{\left( 3 \right)}} \right)\left( { + a_0^{\left( 3 \right)}} \right)\\ {z^{\left( 4 \right)}} = {\Theta ^{\left( 3 \right)}}{a^{\left( 3 \right)}}\\ {a^{\left( 4 \right)}} = {h_\Theta }\left( x \right) = g\left( {z^{\left( 4 \right)}} \right) \end{array}$ 反向传播反向传播的目标是计算代价函数C分别关于w和b的偏导数$\frac{\partial C}{\partial w}$和$\frac{\partial C}{\partial b}$ 反向传播算法描述 梯度检查 $\frac{\text{d}}{\text{d}\Theta}J(\Theta)\approx\frac{J(\Theta+\epsilon)-J(\Theta-\epsilon)}{2\epsilon}$ 没有使用这种方法计算偏导数的原因：反向传播可以同时计算所有的偏导数$\frac{\partial C}{\partial w}$ 随机初始化 初始化所有的$\theta$为0是不行的，因此随机初始化参数矩阵 Exercise（手写数字识别）正向传播 一维模型（一对多分类） 12for k in range(1, 11): y_matrix.append((raw_y == k).astype(int)) 采用LR，一次只能在2个类之间进行分类 k维模型 123456k_theta = np.array([logistic_regression(X, y[k]) for k in range(10)])prob_matrix = sigmoid(X @ k_theta.T)y_pred = np.argmax(prob_matrix, axis=1) #返回沿轴axis最大值的索引，axis=1代表行y_answer = raw_y.copy()y_answer[y_answer==10] = 0 # 之前已将标签为10移至第1列print(classification_report(y_answer, y_pred)) 可以进行所有标签预测 前馈预测（默认已有weight和b矩阵） 12345678910111213141516171819202122232425262728293031323334353637import numpy as npimport scipy.io as siofrom sklearn.metrics import classification_reportdef sigmoid(z): return 1 / (1 + np.exp(-z))def load_weight(path): data = sio.loadmat(path) return data['Theta1'], data['Theta2']def load_data(path): data = sio.loadmat(path) y = data.get('y') # (5000,1) y = y.reshape(y.shape[0]) # make it back to column vector X = data.get('X') # (5000,400) return X, ytheta1, theta2 = load_weight('ex3weights.mat')X, y = load_data('ex3data1.mat')X = np.insert(X, 0, values=np.ones(X.shape[0]), axis=1) # intercepta1 = Xz2 = a1 @ theta1.T # (5000, 401) @ (25,401).T = (5000, 25)z2 = np.insert(z2, 0, values=np.ones(z2.shape[0]), axis=1)a2 = sigmoid(z2)z3 = a2 @ theta2.Ta3 = sigmoid(z3)y_pred = np.argmax(a3, axis=1) + 1 # numpy is 0 base index, +1 for matlab conventionprint(classification_report(y, y_pred)) 反向传播首先进行正向传播 12345678910111213141516def feed_forward(theta, X): """apply to architecture 400+1 * 25+1 *10 X: 5000 * 401 """ t1, t2 = deserialize(theta) # t1: (25,401) t2: (10,26) m = X.shape[0] a1 = X # 5000 * 401 z2 = a1 @ t1.T # 5000 * 25 a2 = np.insert(sigmoid(z2), 0, np.ones(m), axis=1) # 5000*26 z3 = a2 @ t2.T # 5000 * 10 h = sigmoid(z3) # 5000*10, this is h_theta(X) return a1, z2, a2, z3, h # you need all those for backprop 接着进行反向梯度下降 1234567891011121314151617181920212223242526272829303132# 反向传播梯度下降def gradient(theta, X, y): # initialize t1, t2 = deserialize(theta) # t1: (25,401) t2: (10,26) m = X.shape[0] delta1 = np.zeros(t1.shape) # (25, 401) delta2 = np.zeros(t2.shape) # (10, 26) a1, z2, a2, z3, h = feed_forward(theta, X) for i in range(m): a1i = a1[i, :] # (1, 401) z2i = z2[i, :] # (1, 25) a2i = a2[i, :] # (1, 26) hi = h[i, :] # (1, 10) yi = y[i, :] # (1, 10) d3i = hi - yi # (1, 10) z2i = np.insert(z2i, 0, np.ones(1)) # make it (1, 26) to compute d2i d2i = np.multiply(t2.T @ d3i, sigmoid_gradient(z2i)) # (1, 26) # careful with np vector transpose delta2 += np.matrix(d3i).T @ np.matrix(a2i) # (1, 10).T @ (1, 26) -&gt; (10, 26) delta1 += np.matrix(d2i[1:]).T @ np.matrix(a1i) # (1, 25).T @ (1, 401) -&gt; (25, 401) delta1 = delta1 / m delta2 = delta2 / m return serialize(delta1, delta2) 注：$d3i$即为输出层误差，$d2i$为隐含层误差 这里返回的delta1，delta2是C对w求偏导的结果，这里的w包括b 梯度校验12345678910111213141516171819202122232425262728293031323334353637383940def gradient_checking(theta, X, y, epsilon, regularized=False): def a_numeric_grad(plus, minus, regularized=False): """calculate a partial gradient with respect to 1 theta""" if regularized: return (regularized_cost(plus, X, y) - regularized_cost(minus, X, y)) / (epsilon * 2) else: return (cost(plus, X, y) - cost(minus, X, y)) / (epsilon * 2) theta_matrix = expand_array(theta) # expand to (10285, 10285) epsilon_matrix = np.identity(len(theta)) * epsilon plus_matrix = theta_matrix + epsilon_matrix minus_matrix = theta_matrix - epsilon_matrix # calculate numerical gradient with respect to all theta numeric_grad = np.array([a_numeric_grad(plus_matrix[i], minus_matrix[i], regularized) for i in range(len(theta))]) # analytical grad will depend on if you want it to be regularized or not analytic_grad = regularized_gradient(theta, X, y) if regularized else gradient(theta, X, y) # If you have a correct implementation, and assuming you used EPSILON = 0.0001 # the diff below should be less than 1e-9 # this is how original matlab code do gradient checking diff = np.linalg.norm(numeric_grad - analytic_grad) / np.linalg.norm(numeric_grad + analytic_grad) def expand_array(arr): """replicate array into matrix [1, 2, 3] [[1, 2, 3], [1, 2, 3], [1, 2, 3]] """ # turn matrix back to ndarray return np.array(np.matrix(np.ones(arr.shape[0])).T @ np.matrix(arr))# 运行gradient_checking(theta, X, y, epsilon= 0.0001)#这个运行很慢，谨慎运行 If your backpropagation implementation is correct，the relative difference will be smaller than 10e-9 (assume epsilon=0.0001) 机器学习诊断法模型选择一般使用60%的数据作为训练集，使用20%的数据作为交叉验证集，20%的数据作为测试集。 这样比只分训练集和测试集相比，可以得到更好的泛化误差。 模型选择的方法 使用训练集训练出（比如）10个模型 用这些模型在交叉验证集中计算交叉验证误差（代价函数） 选取交叉验证误差最小的模型 利用这个模型计算测试集中的泛化误差（代价函数的值） 训练误差： $J_{train}(\Theta)=\frac{1}{2m}\sum_\limits{i=1}^m (h_\Theta(x^{(i)})-y^{(i)})^2$ 交叉验证误差： $J_{CV}(\Theta)=\frac{1}{2m}\sum_\limits{i=1}^m (h_\Theta(x_{CV}^{(i)})-y_{CV}^{(i)})^2$ 偏差(Bias)和方差(Variance) 如何判断是欠拟合（偏差）还是过拟合（方差）： 训练集误差和交叉验证集误差近似时：偏差/欠拟合- 交叉验证集误差&gt;&gt;训练集误差时：方差/过拟合 正则化对于${h_\theta }\left( x \right) = {\theta _0} + {\theta _1}x + {\theta _2}{x^2} + {\theta _3}{x^3} + {\theta _4}{x^4}$ 及$J( \theta)=\frac{1}{2m}[ {\sum\limits_{i = 1}^m ( h_\theta( x^{(i)} - y^{(i)}) ^2+ \lambda \sum\limits_{j = 1}^n {\theta _j^2} } ]$ 选择$\lambda$的方法 类似选择模型的方法，将训练集和交叉验证集的代价函数误差与$\lambda$的值绘制在一张图表上 当$\lambda$较小时，训练集误差较小（过拟合），交叉验证集误差较大 随着$\lambda$的增加，训练集误差不断增加（欠拟合），而交叉验证集误差先减小后增加 学习曲线学习曲线是学习算法的一个很好的合理检验（sanity check）。绘制训练集误差和交叉验证集误差随训练实例数量（m）的变化图 高偏差 高方差 对于欠拟合，增加数据到训练集不一定有帮助 对于过拟合，增加更多数据到训练集可能提高算法效果 小结改进算法策略 获取更多的训练实例 —解决高方差 尝试减少特征的数量 —解决高方差 获取更多特征 —解决高偏差 增加多项式特征 —解决高偏差 减少正则化程度$\lambda$ —解决高偏差 增加正则化程度$\lambda$ —解决高方差 神经网络中的偏差和方差 使用较小的神经网络，容易导致高偏差和欠拟合 使用较大地神经网络，容易导致高方差和过拟合 通常选择较大的神经网络并采用正则化处理，这样比使用较小网络效果要好 选择隐含层的方法和选择模型的方法类似。 机器学习系统设计学习算法的推荐方法 简答快速的实现一个算法，并用交叉验证集数据测试这个算法 绘制学习曲线，决定是增加更多数据，特征还是其他 进行误差分析：人工检查交叉验证集中我们算法产生预测误差的实例，看看这些实例是否有某种系统化变化的趋势 类偏斜类偏斜（skewed classes）：训练集中有非常多的同一种类的实例，只有很少或没有其他类的实例 分类问题指标 真阳性 TP : 预测为正，实际为正 假阳性 FP：预测为正，实际为负 假阴性 FN：预测为负，实际为正 真阴性 TN：预测为负，实际为负 查准率：预测为正的样本中有多少正样本 $P=\frac{TP}{TP+FP}$ 查全率：样本中的正例有多少被预测正确了 $R=\frac{TP}{TP+FN}$ F1-Score 衡量二分类模型精确度的一种指标 $F_1=2·\frac{precision·recall}{precision+recall}$ 机器学习数据得到一个性能很好的学习算法思路： 特征值有足够多信息，这样可以保证低偏差]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Tensorflow2.0]]></title>
    <url>%2F2019%2F11%2F15%2FTensorflow2.0%E4%B8%8E%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%2F</url>
    <content type="text"><![CDATA[Tensorflow 基础数据类型数值类型在Tensorflow中，为了表示方便，一般把标量、向量、矩阵统称为张量（Tensor） 通过打印张量信息，得到 123456In [2]: x = tf.constant([1,2.,3.3])xOut[2]:&lt;tf.Tensor: id=165, shape=(3,), dtype=float32, numpy=array([1. , 2. , 3.3],dtype=float32)&gt; 其中id是TensorFlow中内部索引对象的编号，shape表示张量的形状，dtype表示张量的精度，张量numpy（）方法可以返回Numpy.array类型的数据 x.numpy() 返回Numpy.array类型的数据 tf.constant([[1,2], [3,4]]) 定义2维张量 字符串类型提供常见的join()，length()，split()，lower()等工具函数 布尔类型 Tensorflow的布尔类型和Python语言的布尔类型不对等 123456In [11]:a = tf.constant(True) # 创建布尔张量a == TrueOut[11]:False 数值精度]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
        <tag>Tensorflow</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Learning Geo-Social User Topical Profiles with Bayesian Hierarchical User Factorization]]></title>
    <url>%2F2019%2F11%2F13%2FLearning%20Geo-Social%20User%20Topical%20Profiles%20with%20Bayesian%20Hierarchical%20User%20Factorization%2F</url>
    <content type="text"><![CDATA[Title 使用贝叶斯分层用户分解学习地理-社交用户画像 Research Objective在社会空间系统中，实现地理位置和用户画像的交互 Background and Problems 虽然很多现有用户画像关注的每个用户的全局视角，但仍有一些重要的地缘社会因素需要考虑 每个用户在不同地方被不同感知 具有相似画像的用户可能有巨大的地缘影响差异 建模地理画像挑战 经常分散，由于用户异质性，地理画像中的受欢迎程度计数存在很大差异 由于多维性，通常非常稀疏 先前研究 用户聚合标签被用于生成用户地理画像 研究基于内容、评分的画像 Method(s) 为了克服异质性，提出了一个两层的贝叶斯层级用户分解生成框架（bHUF），该框架很容易推广到深度用户分解。 为了减少稀疏性，研究用户上下文（特别是地理位置和社会关系），针对多层因式分解方案的非共轭性,提出一个增强模型（bHUF+）。然后，使用NB分布的数据增强方案，开发一种有效的封闭式吉布斯抽样方案进行推理 两层贝叶斯分层用户分解，将泊松伽马信念网络从二维非负计数推广到多维异构计数。与单层分解相比，用户分解的额外层通过允许更大的用户地理位置分布方差-均值比，比单层具有的学习。更好地处理过度分散和用户异质性。 Conclusion作者给了哪些结论，哪些是strong conclusions,哪些是weak的conclusions？哪些构思？ 根据GPS标记的Twitter数据集上的几个基线，对bHUF和bHUF+进行了评估，观察到bHUF在最佳替代单层基线的精确度和召回率上提高了约5%~13%，对用户地理位置和社会环境的改善率提高了6%~11% Evaluation作者如何评估自己的方法，实验的setup是什么样的，有没有问题或者可以借鉴的地方 数据来源+重要指标+模型步骤+每个步骤得出的结论 Summary写完笔记之后最后填，概述文章的内容。切记需要通过自己的思考，用自己的语言描述 Notes额外笔记 Reference(optional)列出相关性高的文献，一遍之后可以继续track]]></content>
      <categories>
        <category>论文合集</category>
      </categories>
      <tags>
        <tag>用户画像</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[推荐系统可解释性]]></title>
    <url>%2F2019%2F11%2F13%2F%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E5%8F%AF%E8%A7%A3%E9%87%8A%E6%80%A7%2F</url>
    <content type="text"><![CDATA[Introduction解释的两个维度： 显示样式（display style）： 相关用户或项目 用户或项目特征 文本解释 图像解释 社会解释 词簇 模型/方法 基于邻域 矩阵分解 主题建模 基于图 深度学习 知识图谱 关联分析 两种可解释性： 以人为方式工作的可解释模型。目前大多数属于这一类 只关注产品，将推荐模型视为一个复杂的黑盒。称为事后可解释性。 可解释性与时效性： 近些年的研究表明，这两项并不冲突，可以使用深度学习等方法来解决。 不同显示风格的解释基于相关用户和项目的解释 协同过滤和基于相关商品的解释 基于特征的解释 基于特征与基于内容密切相关，基于内容的推荐很至关，可以通过生成基于特性的解释来解释]]></content>
      <categories>
        <category>推荐系统</category>
      </categories>
      <tags>
        <tag>可解释性</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[文献阅读方法]]></title>
    <url>%2F2019%2F11%2F13%2F%E6%96%87%E7%8C%AE%E9%98%85%E8%AF%BB%E6%96%B9%E6%B3%95%2F</url>
    <content type="text"><![CDATA[阅读文献Abstract 作者想要解决什么问题？ question 作者通过什么理论/模型来解决这个问题？ method 作者给出的答案是什么？ answer Introduction 作者为什么研究这个课题？ 目前这个课题的研究进行到了哪一个阶段？ 作者使用的理论是基于哪些假设? Conclusion 这篇文章存在哪些缺陷？ 作者关于这个课题的构思是哪几点？ Table数据来源+重要指标+模型步骤+每个步骤得出的结论 归纳 笔记框架 Title文章标题 Research Objective作者的研究目标 Background and Problems我们要研究这个课题？这个课题研究进行到哪个阶段？基于哪些假设？ Method(s)作者解决问题的理论/模型？是否基于前人的方法？ Conclusion作者给了哪些结论，哪些是strong conclusions,哪些是weak的conclusions？哪些构思？ Evaluation作者如何评估自己的方法，实验的setup是什么样的，有没有问题或者可以借鉴的地方 数据来源+重要指标+模型步骤+每个步骤得出的结论 Summary写完笔记之后最后填，概述文章的内容。切记需要通过自己的思考，用自己的语言描述 Notes额外笔记 Reference(optional)列出相关性高的文献，一遍之后可以继续track]]></content>
      <categories>
        <category>论文合集</category>
      </categories>
      <tags>
        <tag>方法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[推荐系统实践]]></title>
    <url>%2F2019%2F10%2F18%2F%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E5%AE%9E%E8%B7%B5%2F</url>
    <content type="text"><![CDATA[好的推荐系统随着信息技术和互联网的发展，人们逐渐从信息匮乏的时代走入了信息过载（information overload) 。为了解决信息过载问题，出现了分类目录（雅虎、hao123） 和 搜索引擎(google) 。 和搜索引擎一样，推荐系统也是一种帮助用户快速发现有用信息的工具。但是它不需要用户提供明确需求，而是通过分析用户的历史行为给用户的兴趣建模，从而主动给用户推荐。 物品的长尾(long tail)。长尾商品代表一小部分用户的个性化需求。推荐系统通过发掘用户的行为，找到用户的个性化需求，从而将长尾商品准确地推荐给需要它的用户。 个性化推荐系统的应用几乎所有的推荐系统都是由前台的展示页面、后台的日志系统、推荐算法系统3部分构成 电子商务在亚马逊平台上 个性化推荐：基于物品、 基于好友 相关推荐列表：购买（浏览）过这个商品的用户购买的其它商品，然后进行打包销售（cross selling) 电影视频、音乐推荐电影视频主要通过基于物品的推荐 音乐推荐是推荐系统里非常特殊的领域。具有一些特点 物品空间大 听一首歌耗时很少 物品重用率很高 上下文相关 次序很重要 不需要全神贯注 高度社会化 以上特点决定了音乐是一种非常适合用来推荐的物品。 社交网络社交网络中的个性化推荐技术主要应用在三个方面： 利用用户的社交网络信息对用户进行个性化的物品推荐 信息流的会话推荐 推荐好友 会话推荐用户在Facebook上的每个分享和它的所有评论被称为一个会话，如何给这些会话排序是重要的。 个性化阅读、邮件，位置推荐个性化广告（计算广告）个性化广告与狭义个性化推荐的区别： 个性化推荐这种帮助用户找到可能令他们感兴趣的物品，而广告推荐着重帮助广告找到对他们感兴趣的用户。 个性化广告投放技术主要分3种： 上下文广告 搜索广告 个性化展示广告： 根据用户的兴趣 推荐系统的评测一个完整的推荐系统一般存在3个参与方：用户、物品提供者和提供推荐系统的网站。推荐系统是一个三方共赢的系统 推荐系统的实验方法离线实验步骤 通过日志系统获取用户行为数据，按照一定标准生成一个数据集 将数据集划分成训练集和测试集 在训练集上训练用户兴趣模型，在测试集上进行预测 通过事先定义的离线指标评测算法在测试集上预测结果 离线实验的优缺点如下： 用户调查在上线之前，需要做一次用户调查的测试。以减少直接上线的巨大风险。优点是：可以获得用户主观的感受，相对在线风险低。缺点是：很难组织大规模的测试用户，测试环境下的用户行为和真实环境下可能有所不同 在线实验AB测试是一种常见的在线评测算法的实验方法。通过一定的规则将用户随机分成几组，并对不同组的用户采用不同的算法，然后统计不同组用户的各种不同的评测指标。优点：公平缺点：周期长，所以一般只测试在离线实验和用户调查中表现好的算法。AB测试设计也是一项复杂的工程（一般不同层及控制这些层的团队需要从一个统一的地方获得自己AB测试的流量，不同层之间的流量应该是正交的） AB测试系统： 一个新的推荐算法最终上线，需要完成以上3个实验 离线实验证明它在很多离线指标上优于现有的算法 用户调查保证满意度 AB测试确定优越性 评测指标用户满意度用户满意度不能通过离线实验得到，只能通过用户调查或者在线实验。用户调查主要使用调查问卷在线实验可以通过点击率、停留时间、转化率等指标 预测准确度最重要的离线评测指标。准确度有几个方向 评分预测一般通过均方根误差(RMSE)和平均绝对误差(RAM)计算 令$r_{ui}$是用户u对物品i的实际评分，而$\hat{r}_{ui}$是推荐算法给出的预测评分 RMSE=\frac{\sqrt{\sum _{u,i\in T} ( r_{ui} - \hat{r}_{ui})^2}}{|T|} RAM=\frac{\sum _{u,i\in T} | r_{ui} - \hat{r}_{ui}|}{|T|} 如果评分系统是基于整数建立的（即用户给的评分都是整数），那么对预测结果取整会降低MAE的误差 TopN推荐TopN推荐的准确率一般通过准确率（precision)，召回率（recall)度量 令R(u)是根据用户在训练集上的行为给用户做出的推荐列表，而T(u）是用户在测试集上的行为列表 召回率定义为： Recall=\frac{\sum_ {u\in U} | R(u) \cap T(u)|}{\sum_{u\in U} | T(u) |}准确率定义为： Precision=\frac{\sum_ {u\in U} | R(u) \cap T(u)|}{\sum_{u\in U} | R(u) |}12345678910def PrecisionRecall(test, N): hit = 0 n_recall = 0 n_precision = 0 for user, items in test.items(): rank = Recommend(user, N) hit += len(rank &amp; items) n_recall += len(items) n_precision += N return [hit / (1.0 * n_recall), hit / (1.0 * n_precision)] 有时候，为了全面评测TopN推荐的准确率和召回率，会选取不同的推荐列表长度N，计算出一组准确率、召回率 覆盖率覆盖率（coverage)描述一个推荐系统对物品长尾的发掘能力。最简单的定义为推荐系统能够推荐出来的物品占总物品集合的比例。 假设系统的用户集合为U,推荐系统给每一个用户推荐一个长度为N的物品列表R(u)。 Coverage=\frac{|\cup_{u\in U}R(u)|}{|I|}为了更细致地描述推荐系统发掘长尾的能力，需要统计推荐列表中不同物品出现次数的分布。如果这个分布较平，则覆盖率高。有两个指标可以用来定义覆盖率 信息熵概率分布越平均，信息熵越大，覆盖率越大。 H=-\sum_i^n p(i)\log{p(i)} 这里p(i)是物品i的流行度除以所有物品流行度之和 物品流行度： 有多少用户与该物品发生关系 基尼系数（Gini Index):G=\frac{1}{n-1}\sum_{j=1}^n(2j-n-1)p(i_j) 这里，$i_j$是按照物品流行度p()从小到大排序的物品列表中第j个物品。 基尼系数的计算原理：基尼系数=SA/(SA+SB),如果系统的流行度很平均，那么SA就会很小，分配不均匀,基尼系数很大 曲线表示最不热门的x%物品的总流行度占系统的比例y% 如果G1是从初始用户行为中计算出的物品流行度的基尼系数，G2是从推荐列表中计算出来的。如果G2&gt;G1,说明推荐算法具有马太效应。系统还需优化。 马太效应：前者更强，弱者更弱。热门的物品更加热门，冷门更加冷门。推荐系统的初衷就是希望消除马太效应 多样性假设s(i,j)∈[0,1]定义了物品i和j之间的相似度，用户u的推荐列表R(u)的多样性定义为： Diversity=1- \frac{\sum_ {i,j \ in R(u),i \neq j} s(i,j)}{\frac{1}{2} |R(u)| (|R(u)| -1)}整体多样性为所有用户推荐列表多样性的平均值 不同物品相似度函数s(i,j)可以定义不同的多样性。如果用内容相似函数描述物品间的相似度，可以得到内容多样性函数。如果用协同过滤的相似函数，得到协同过滤的多样性函数 新颖性评测新颖度的最简单的方法是利用推荐结果的平均流行度，越不热门的物品越可能让用户觉得新颖。目前的关注点在于如何在不牺牲精度的情况下提高多样性和新颖性。 计算平均流行度时对每个物品的流行度取对数，这是因为物品的流行度满足长尾分布，在取对数后，流行度的平均值更加稳定 这里取对数可以使数据更加平稳，同时可以减少区间差异影响。比如log500 + log500 &gt; log200 + log800，两个都是500，相比较后者更为流行。 惊喜度区分新颖性： 惊喜性是推荐结果和用户历史上喜欢的物品不相似，但用户觉得满意新颖性：推荐用户没听说过的 信任度目前有两种方式： 增加推荐系统的透明度（transparency) ： 提供推荐解释 通过社交网络信息，利用好友进行解释 实时性 推荐系统需要实时更新推荐列表 推荐系统需要能够将新加入系统的物品推荐给用户 健壮性（robust）除了选择健壮性高的算法，还有以下方法 设计推荐系统时尽量使用代价比较高的用户行为 使用数据前，进行攻击检测，完成对数据的清洗 总结 离线实验的优化目标是：最大化预测准确度 使得 覆盖率&gt;A , 多样性&gt;B , 新颖性&gt;C 评测维度知道一个算法在什么情况下性能最好 用户维度： 主要包括用户的人口统计学信息、活跃度以及是否为新用户 物品维度： 物品的属性信息、流行度、平均分、是不是新加的物品等 时间维度： 季节、周末还是工作日、白天还是晚上 在不同维度下的评测指标，可以帮助我们全面地了解推荐系统。 利用用户行为数据基于用户行为分析的推荐算法是个性化推荐系统的重要算法，一般把这种类型的算法成为协同过滤算法。 用户行为数据简介用户行为在个性化推荐系统中一般分两种 显性反馈(explicit feedback) 隐性反馈(implicit feedback) 隐性反馈只有正反馈 按照反馈的方向 正反馈：用户的行为倾向用户喜欢该物品 负反馈：用户的行为倾向用户不喜欢该物品 用户行为的统一表示： 代表性数据集： 无上下文信息的隐性反馈数据集： 仅包含用户ID和物品ID 无上下文信息的显性反馈数据集： 每一条记录包含用户ID、物品ID和对物品的评分 有上下文信息的隐性反馈数据集： 每一条记录包含用户ID、物品ID和对物品产生行为的时间戳 有上下文信息的显性反馈数据集： 每一条记录包括用户ID、物品ID、用户对物品的评分和评分行为发生的时间戳 用户行为分析用户活跃度和物品流行度的分布长尾分布： f(x)= \alpha_i k^ {\beta_i}物品流行度，用户的活跃度都近似长尾分布 用户活跃度和物品流行度的关系一般，用户活跃度低，其浏览物品的流行度高； 反之流行度高 协同过滤算法包括： 基于邻域的方法(neighborhood-based) 隐语义模型(latent factor model) 基于图的随机游走算法(random walk on graph) 基于邻域的方法包括： 基于用户的协同过滤算法 基于物品的协同过滤算法 实验设计和算法评测数据集MovieLens. 本章着重研究隐反馈数据集中的TopN推荐问题 实验设计将用户行为数据集按照均匀分布随机分成M份，挑选一份作为测试集，将剩下的M-1份作为训练集。进行M次实验，最后取平均值。 如果数据集够大，模型够简单，为了快速通过离线实验初步地选择算法，也可以只进行一次 评测指标精度、覆盖率、新颖性 基于邻域的算法基于用户的协同过滤基础算法令N(u)表示用户u曾今有过正反馈的物品集合，令N(v)为用户v曾经有过正反馈的物品集合，u和v的兴趣相似度 w_{uv}= \frac{|N(u) \cap N(v)|}{|N(u) \cup N(v)|}或者余弦相似度计算： w_{uv}= \frac{|N(u) \cap N(v)|}{\sqrt{|N(u) || N(v)|}}很多用户之间没有相同的交互物品，先计算出有交互物品的用户对，在除以分母$ \sqrt{|N(u)||N(v)|}$。 为此，先建立物品到用户的倒排表，对于每个物品都保存对该物品产生过行为的用户列表。C[u][v]=K,说明用户u和v有K个相同物品 物品-用户倒排表： 得到相似兴趣度之后，UserCF用一下公式度量用户u对物品i的感兴趣度： p(u,i)=\sum_{v\in S(u,K)\cap N(i)}w_{uv}r_{vi} 在MovieLens数据集下的性能显示：准确率和召回率：不和参数K成线性关系，选择合适的K对于获得高的推荐系统精度比较重要流行度：K越大，流行度越大覆盖率：K越大，流行度越大，覆盖率越低 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455# 基于用户余弦相似度的推荐def UserCF(train, K, N): # 计算item-&gt;user的倒排 item_user = &#123;&#125; for user in train: for item in train[user]: if item not in item_user: item_user[item] = [] item_user[item].append(user) # 计算用户相似度矩阵 sim = &#123;&#125; num = &#123;&#125; # 统计user的交互item数 for item in item_user: users = item_user[item] for i in range(len(users)): u = users[i] if u not in num: num[u] = 0 num[u] += 1 if u not in sim: sim[u] = &#123;&#125; for j in range(len(users)): if j == i: continue v = users[j] if v not in sim[u]: sim[u][v] = 0 sim[u][v] += 1 for u in sim: for v in sim[u]: sim[u][v] /= math.sqrt(num[u] * num[v]) # 按照相似度排序 sorted_user_sim = &#123;k: list(sorted(v.items(), \ key=lambda x: x[1], reverse=True)) \ for k, v in sim.items()&#125; #获取接口函数 def GetRecommendation(user): items = &#123;&#125; seen_items = set(train[user]) for v, _ in sorted_user_sim[user][:K]: for item in train[v]: # 去掉用户见过的 if item not in seen_items: if item not in items: items[item] = 0 items[item] += sim[user][v] recs = list(sorted(items.items(), key=lambda x: x[1], reverse=True))[:N] return recs return GetRecommendation 用户相似度计算的改进新的公式： w_{uv} = \frac{\sum_{i\in N(u)\cap N(v)} \frac{1}{log1+|N(i)|}}{sqrt{|N(u)||N(v)|}}该公式通过 $\frac{1}{sqrt{|N(u)||N(v)|}}$ 惩罚了用户u和用户v共同兴趣列表中热门物品对他们相似度的影响 在线使用UserCF的例子Digg博客使用UserCF进行博客推荐。增加指标如下： 用户反馈增加：用户“顶”和“踩”的行为增加了40% 平均每个用户将从34个具相似兴趣好友那儿获得200条推荐结果 用户和好友的交互活跃度增加了24% 用户评论增加了11% 基于物品的协同过滤算法基础算法随着网站的用户数目越来越大，计算用户兴趣相似度越来越困难，其运算时间复杂度和空间复杂度的增长和用户数的增长近似平方关系。并且，基于用户的协同过滤很难对推荐结果做出解释 基于物品的协同过滤算法给用户推荐那些和他们之前喜欢的物品相似的物品。ItemCF算法并不利用物品的内容属性计算物品之间的相似度，它主要通过分析用户的行为记录计算物品之间的相似度 算法: 建立用户-物品倒排表（已有），建立两两物品间的用户数矩阵，得到物品之间的余弦相似度矩阵 通过公式计算用户u对一个物品j的兴趣：p_{uj} = \sum_{i\in N(u)\cap S(j,K)} w_{ji}r_{ui} 计算物品相似度的简单例子： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849# 1. 基于物品余弦相似度的推荐def ItemCF(train, K, N): ''' :params: train, 训练数据集 :params: K, 超参数，设置取TopK相似物品数目 :params: N, 超参数，设置取TopN推荐物品数目 :return: GetRecommendation, 推荐接口函数 ''' # 计算物品相似度矩阵 sim = &#123;&#125; num = &#123;&#125; for user in train: items = train[user] for i in range(len(items)): u = items[i] if u not in num: num[u] = 0 num[u] += 1 if u not in sim: sim[u] = &#123;&#125; for j in range(len(items)): if j == i: continue v = items[j] if v not in sim[u]: sim[u][v] = 0 sim[u][v] += 1 for u in sim: for v in sim[u]: sim[u][v] /= math.sqrt(num[u] * num[v]) # 按照相似度排序 sorted_item_sim = &#123;k: list(sorted(v.items(), \ key=lambda x: x[1], reverse=True)) \ for k, v in sim.items()&#125; # 获取接口函数 def GetRecommendation(user): items = &#123;&#125; seen_items = set(train[user]) for item in train[user]: for u, _ in sorted_item_sim[item][:K]: if u not in seen_items: if u not in items: items[u] = 0 items[u] += sim[item][u] recs = list(sorted(items.items(), key=lambda x: x[1], reverse=True))[:N] return recs return GetRecommendation 用户活跃度对物品相似度的影响 IUF: 活跃用户对物品相似度的贡献应该小于不活跃的用户。 修正物品相似度的计算公式： w_{ij} = \frac{\sum _{u\in N(i)\cap N(j)} \frac{1}{log1+|N(u)|}}{\sqrt{|N(i)||N(j)|}}物品相似度的归一化将ItemCFde的相似矩阵按最大值归一化，可以提高推荐的准确率，如果已经得到物品相似度矩阵w,使用如下公式得到w’: w'_{ij} = \frac{w_{ij}}{\max _j w_{ij}} 归一化不仅增加推荐的准确度，它还可以提高推荐的覆盖率和多样性 实验结果： Item-IUF 提高了准确率和召回率，但覆盖率、流行度指标有所下降Item-Norm所有指标都有所提升。 UserCF与ItemCF的比较Digg使用UserCF,亚马逊使用ItemCF。UserCF的推荐更社会化，反映了用户所在的小型兴趣群体中物品的热门程度，而ItemCF的推荐更加个性化，反映了用户自己的兴趣传承 在离线实验中，最原始的UserCF和ItemCF中，往往ItemCF各项指标都不如UserCF. 哈利波特问题加大对物品的惩罚： w_{ij} = \frac{|N(i)\cap N(j)|}{|N(i)|^{1-\alpha} |N(j)^\alpha |}其中α∈[0.5,1]。通过提高α，可以惩罚热门的j。从离线实验中，α只有在取值为0.5时才会导致最高的准确率和召回率。α越大，覆盖率越高，平均结果的平均人们会降低。可以通过这种方法适当牺牲准确率和召回率来提高覆盖率和新颖性。 两个不同领域的最热门物品之间往往具有比较高的相似度。这时，仅仅依靠用户行为数据是不能解决的。只能依靠引入物品的内容数据解决这个问题。比如对不同领域的物品降低权重 隐语义模型(latent factor model)隐含语义分析技术(latent variable analysis)采取基于用户行为统计的自动聚类。 可以解决如下问题： 编辑的意见不能代表用户的意见 编辑很难控制分类的粒度 编辑很难给一个物品多个分类 编辑很难给出多维度的分类 编辑很难决定一个物品在某一个分类中的权重 LFM计算用户u对物品i的兴趣： Preference(u,i) =r_{ui} =p_{u} ^T q_i =\sum_{f=1} ^F p_{u,k}q_{i,k}公式中 $p_{u,k}$ 和 $q_{i,k}$是模型的参数，其中$p_{u,k}$度量了用户u的兴趣和第k个隐类的关系，$q_{i,k}$度量了第k个隐类和物品i之间的关系。 算法主要流程： 采样 损失函数 梯度下降 随机梯度下降 由于隐形反馈数据集没有负样本，因此首先要采样: 这里选取那些很热门，而用户却没有行为的物品 123456789101112131415161718# 负采样函数(注意！！！要按照流行度进行采样) def nSample(data, ratio): new_data = &#123;&#125; # 正样本 for user in data: if user not in new_data: new_data[user] = &#123;&#125; for item in data[user]: new_data[user][item] = 1 # 负样本 for user in new_data: seen = set(new_data[user]) pos_num = len(seen) item = np.random.choice(items, int(pos_num * ratio * 3), p=pops) # 按照pops的概率进行选择 item = [x for x in item if x not in seen][:int(pos_num * ratio)] new_data[user].update(&#123;x: 0 for x in item&#125;) return new_data 采样后，得到一个用户-物品集K={(u,i)},其中如果(u,i)是正样本，则有$r_{ui}$=1,否则有$r_{ui}$=0。利用如下损失函数来找最合适的参数p和q C=\sum _{(u,i)\in K}(r_{ui}- \widehat{r}_{ui})^2=\sum_{(u,i)\in K}(r_{ui} - \sum_{k=1}^K p_{u,k}q_{i,k})^2 + \lambda\parallel p_u\parallel ^2+ \lambda\parallel q_i\parallel ^2这里，$\lambda\parallel p_u\parallel ^2+ \lambda\parallel q_i\parallel ^2$ 是用来防止过拟合的正则化项。λ可通过实验获得。 梯度公式 \frac{\partial C}{\partial p_{uk}}=-2(r_{ui} - \sum_{k=1}^K p_{u,k}q_{i,k})q_{ik} +2\lambda p_{uk}\frac{\partial C}{\partial q_{ik}}=-2(r_{ui} - \sum_{k=1}^K p_{u,k}q_{i,k})p_{uk} +2\lambda q_{ik}随机梯度下降 p_{uk}=p_{uk}+\alpha ((r_{ui} - \sum_{k=1}^K p_{u,k}q_{i,k})q_{ik} - \lambda p_{uk}q_{ik}=q_{ik}+\alpha ((r_{ui} - \sum_{k=1}^K p_{u,k}q_{i,k})p_{uk} - \lambda q_{ik}12345678910111213141516171819202122232425262728# 训练 P, Q = &#123;&#125;, &#123;&#125; for user in train: P[user] = np.random.random(K) for item in items: Q[item] = np.random.random(K) for s in trange(step): data = nSample(train, ratio) for user in data: for item in data[user]: eui = data[user][item] - (P[user] * Q[item]).sum() for k in range(0, K): P[user] += lr * (Q[item] * eui - lmbda * P[user]) Q[item] += lr * (P[user] * eui - lmbda * Q[item]) lr *= 0.9 # 调整学习率 # 获取接口函数 def GetRecommendation(user): seen_items = set(train[user]) recs = &#123;&#125; for item in items: if item not in seen_items: recs[item] = (P[user] * Q[item]) recs = list(sorted(recs.items(), key=lambda x: x[1], reverse=True))[:N] return recs return GetRecommendation 结果 选取4个隐类中排名最高（$q_{ik}$最大）的一些电影，结果表明，每一类电影都是合理的，都代表了一类用户喜欢看的电影。 基于LFM的实际系统例子雅虎新闻推荐: LFM训练十分耗时，一般在实际应用中只能每天训练一次。雅虎使用如下公式预测用户u是否会单机链接i r_{ui}=x_u ^T \cdot y_i + p_u ^T \cdot q_i其中$y_i$是根据物品的内容属性直接生成的，$x_{uk}$是用户u对内容特征k的兴趣程度。用户向量$x_k$可以根据历史行为记录获得，每天只计算一些。而$p_u$、$q_i$是根据实时拿到的用户最近几小时的行为训练LFM获得的。 LFM和基于邻域的方法的比较 理论基础： LFM是一种基于机器学习的方法，邻域是一种统计学方法，没有学习过程 离线计算的空间复杂度： 假设有M个用户和N个物品。 用户相关表需要O(M×M)的空间。物品相关表需要O(N×N)的空间。 LFM需要O(F×(M+N))。LFM大量节省了训练过程中的内存 离线计算的时间复杂度： 假设有M个用户，N个物品，K条用户对物品的行为记录。 UserCF的时间复杂度 O（N×(K/N)^2); ItemCF的时间复杂度 O(M×(K/M)^2); 如果有K个隐类，迭代S次，LFM的时间复杂度 O(F×S×K)。 总体上没有质的差别 在线实时推荐： ItemCF一旦用户有了新行为，推荐列表马上发生变化。 对于LFM,当物品量很多时，O(M×N×F)，因此LFM不适合物品数非常庞大的系统。所以，当用户有了新行为，LFM的推荐列表不会发生变化 推荐解释： ItemCF可以支持很好的解释。LFM无法提供解释 基于图的模型用户行为数据的二分图表示（graph-based model)令G(V,E)表示用户物品二分图： 基于图的推荐算法图中顶点的相关度主要取决于以下因素： 两个顶点之间路径数 两个顶点之间路径长度 两个顶点之间路径经过的顶点 相关度高的顶点一般有如下特性： 两个顶点有很多路径相连 连接两个顶点之间的路径长度比较短 连接两个顶点之间的路径不会经过出度较大的顶点 算法描述从用户u对应的结点$v_u$开始，在任何一个节点，以α的概率往下走，1-α的概率回到$v_u$节点。如果继续游走，则从当前节点指向的节点中按照均匀分布随机选择一个节点作为游走下次经过的结点。经过很多次随机游走之后，每个物品结点被访问到的概率会收敛到一个数。 公式如下： PR(v)=\begin{cases}\alpha \sum_{v'\in in(v)} \frac{PR(v')}{|out(v')|} & (v\neq v_u)\\(1-\alpha)+\alpha\sum_{v'\in in(v)} \frac{PR(v')}{|out(v')|} & (v=v_u)\end{cases}公式中PR(i)表示物品i的访问概率(物品i的权重),out(i)表示物品节点i的出度。 算法举例 12345678910111213141516171819202122232425262728293031323334353637383940import timedef PersonalRank(G, alpha, root, max_depth): rank = dict() rank = &#123;x: 0 for x in G.keys()&#125; rank[root] = 1 # 开始迭代 begin = time.time() for k in range(max_depth): tmp = &#123;x: 0 for x in G.keys()&#125; # 取出节点i和他的出边尾节点集合ri for i, ri in G.items(): # 取节点i的出边的尾节点j以及边E(i,j)的权重wij,边的权重都为1，归一化后就是1/len(ri) for j, wij in ri.items(): if j not in tmp: tmp[j] = 0 tmp[j] += alpha * rank[i] / (1.0 * len(ri)) if j == root: tmp[root] += (1 - alpha) rank = tmp end = time.time() print('use_time', end-begin) lst = sorted(rank.items(), key=lambda x: x[1], reverse=True) for ele in lst: print("%s:%.3f, \t" % (ele[0], ele[1])) return rankif __name__ == '__main__': alpha = 0.6 G = &#123;'A': &#123;'a': 1, 'c': 1&#125;, 'B': &#123;'a': 1, 'b': 1, 'c': 1, 'd': 1&#125;, 'C': &#123;'c': 1, 'd': 1&#125;, 'a': &#123;'A': 1, 'B': 1&#125;, 'b': &#123;'B': 1&#125;, 'c': &#123;'A': 1, 'B': 1, 'C': 1&#125;, 'd': &#123;'B': 1, 'C': 1&#125;&#125; PersonalRank(G, alpha, 'A', 50) 结果得到对于A,d的访问概率大于b。PersonalRank算法在时间复杂度上有明显的缺点。对每个用户进行推荐时，都需要在整个用户物品二分图上进行迭代，直到整个图上的每个顶点的PR值收敛。 矩阵形式PersonalRank令M为用户物品二分图的转移概率矩阵 M_{ij}=\begin{cases}\frac{1}{|out(j)|} & if(j\in out(i))\\0 & else\end{cases}迭代公式变为： r=(1-\alpha)r_0+\alpha M^T r其中，r是个n维向量，$r_0$代表起点，第i个位置上是1，其余元素均为0。解出方程，得到： r=(1-\alpha)(1-\alpha M_T)^{-1}r_0只需计算一次 $(1-\alpha M_T)^{-1}$,快速求解。 12345678910111213141516171819202122232425262728293031import numpy as npfrom numpy.linalg import solveimport timeif __name__ == &apos;__main__&apos;: alpha = 0.8 vertex = [&apos;A&apos;, &apos;B&apos;, &apos;C&apos;, &apos;a&apos;, &apos;b&apos;, &apos;c&apos;, &apos;d&apos;] M = np.matrix([[0, 0, 0, 0.5, 0, 0.5, 0], [0, 0, 0, 0.25, 0.25, 0.25, 0.25], [0, 0, 0, 0, 0, 0.5, 0.5], [0.5, 0.5, 0, 0, 0, 0, 0], [0, 1.0, 0, 0, 0, 0, 0], [0.333, 0.333, 0.333, 0, 0, 0, 0], [0, 0.5, 0.5, 0, 0, 0, 0]]) r0 = np.matrix([[1], [0], [0], [0], [0], [0], [0]]) # 从&apos;A&apos;开始游走 print(r0.shape) n = M.shape[0] # 直接解线性方程法 A = np.eye(n)-alpha*M.T b = (1-alpha)*r0 begin = time.time() r = solve(A, b) end = time.time() print(&apos;user time&apos;, end-begin) print(r) rank = &#123;&#125; for j in range(n): rank[vertex[j]] = r[j][0] li = sorted(rank.items(), key=lambda x: x[1], reverse=True) for ele in li: print(&quot;%s:%.3f,\t&quot; % (ele[0], ele[1])) 这里采用直接解线性方程法，还可以对求解进行优化，采用CSC矩阵压缩等方法。]]></content>
      <categories>
        <category>推荐系统</category>
      </categories>
      <tags>
        <tag>推荐系统</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hexo]]></title>
    <url>%2F2019%2F09%2F30%2Fhello%20world%2F</url>
    <content type="text"><![CDATA[Hexo基本操作本地预览hexo s --debug 生成部署hexo g hexo d Markdown基本操作多行代码 使用三个反引号 在每一行前面缩进4个空格 ```key 代码块 ``` key可以为cpp,java,python，key进行高亮 单行代码使用反引号 ` 来标记或插入代码区段 eg：打印使用`代码`来进行输出]]></content>
  </entry>
</search>
