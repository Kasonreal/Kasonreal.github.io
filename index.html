<!DOCTYPE html>



  


<html class="theme-next gemini use-motion" lang="zh-Hans">
<head><meta name="generator" content="Hexo 3.9.0">
  <meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform">
<meta http-equiv="Cache-Control" content="no-siteapp">
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css">







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css">

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.4">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="Hexo, NexT">










<meta name="description" content="Kason&apos;s technology blog">
<meta property="og:type" content="website">
<meta property="og:title" content="Kason&#39;s Blog">
<meta property="og:url" content="http://yoursite.com/index.html">
<meta property="og:site_name" content="Kason&#39;s Blog">
<meta property="og:description" content="Kason&apos;s technology blog">
<meta property="og:locale" content="zh-Hans">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Kason&#39;s Blog">
<meta name="twitter:description" content="Kason&apos;s technology blog">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Gemini',
    version: '5.1.4',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://yoursite.com/">





  <title>Kason's Blog</title>
  








</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  
  
    
  

  <div class="container sidebar-position-left 
  page-home">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Kason's Blog</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle"></p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br>
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br>
            
            标签
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br>
            
            分类
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br>
            
            归档
          </a>
        </li>
      

      
        <li class="menu-item menu-item-search">
          
            <a href="javascript:;" class="popup-trigger">
          
            
              <i class="menu-item-icon fa fa-search fa-fw"></i> <br>
            
            搜索
          </a>
        </li>
      
    </ul>
  

  
    <div class="site-search">
      
  <div class="popup search-popup local-search-popup">
  <div class="local-search-header clearfix">
    <span class="search-icon">
      <i class="fa fa-search"></i>
    </span>
    <span class="popup-btn-close">
      <i class="fa fa-times-circle"></i>
    </span>
    <div class="local-search-input-wrapper">
      <input autocomplete="off" placeholder="搜索..." spellcheck="false" type="text" id="local-search-input">
    </div>
  </div>
  <div id="local-search-result"></div>
</div>



    </div>
  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            
  <section id="posts" class="posts-expand">
    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2020/02/25/概率论/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Kason">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/westbrook.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Kason's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2020/02/25/概率论/" itemprop="url">概率论</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2020-02-25T23:28:54+08:00">
                2020-02-25
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/理论基础/" itemprop="url" rel="index">
                    <span itemprop="name">理论基础</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2020/02/25/概率论/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count valine-comment-count" data-xid="/2020/02/25/概率论/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p><strong>贝叶斯公式</strong></p>
<p>$P(A|B)=P(A)\frac{P(B|A)}{P(B)}$</p>
<p>先验概率： $P(A)$</p>
<p>可能性函数： $P(B|A)P(B)$</p>
<p>后验概率： $P(A|B)$</p>
<p><strong>似然函数</strong></p>
<p>$P(x|\theta)$</p>
<p>$x$是已知确定的，$\theta$是变量，函数描述对于不同的模型参数，出现$x$个这样样本点的概率</p>
<p><strong>最大似然估计（MLE)</strong></p>
<p>利用已知的样本信息，反推最具有可能（最大概率）导致这些样本结果出现的模型参数值</p>
<p>使得<u>似然函数</u>的值最大的参数$\theta$就是我们要找的模型参数</p>
<p>&lt; !—more—&gt;</p>
<p><strong>最大后验概率估计（MAP)</strong></p>
<p>MAP是求$\theta$使得$P(x_0|\theta)P(\theta)$最大。即最大化$P(\theta|x_0)$</p>
<p>MAP就是多个作为因子的先验概率$P(\theta)$</p>

          
        
      
    </div>
    
    
    

    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2020/02/21/论文研究模板/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Kason">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/westbrook.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Kason's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2020/02/21/论文研究模板/" itemprop="url">论文模板</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2020-02-21T20:23:47+08:00">
                2020-02-21
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/论文合集/" itemprop="url" rel="index">
                    <span itemprop="name">论文合集</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2020/02/21/论文研究模板/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count valine-comment-count" data-xid="/2020/02/21/论文研究模板/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="Title"><a href="#Title" class="headerlink" title="Title"></a>Title</h1><h2 id="Research-Objective"><a href="#Research-Objective" class="headerlink" title="Research Objective"></a>Research Objective</h2><h2 id="Background-and-Problems"><a href="#Background-and-Problems" class="headerlink" title="Background and Problems"></a>Background and Problems</h2><p><strong>为什么要研究？</strong></p>
<p><strong>先前研究阶段</strong></p>
<p><strong>有哪些困难？</strong></p>
<h2 id="Method-s"><a href="#Method-s" class="headerlink" title="Method(s)"></a>Method(s)</h2><p><strong>解决问题的理论/模型？</strong></p>
<p><strong>是否基于前人的方法？</strong></p>
<h2 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h2><p><strong>strong conclusions</strong></p>
<p><strong>weak conclusions</strong></p>
<p><strong>构思</strong></p>
<h2 id="Evaluation"><a href="#Evaluation" class="headerlink" title="Evaluation"></a>Evaluation</h2><p><strong>数据来源</strong></p>
<p><strong>重要指标</strong></p>
<p><strong>Baseline</strong></p>
<p><strong>评价方案</strong></p>
<p><strong>步骤</strong></p>
<h2 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h2><h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2>
          
        
      
    </div>
    
    
    

    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2020/01/13/用户画像推荐系统/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Kason">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/westbrook.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Kason's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2020/01/13/用户画像推荐系统/" itemprop="url">用户画像推荐系统</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2020-01-13T21:15:33+08:00">
                2020-01-13
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/推荐系统/" itemprop="url" rel="index">
                    <span itemprop="name">推荐系统</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2020/01/13/用户画像推荐系统/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count valine-comment-count" data-xid="/2020/01/13/用户画像推荐系统/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="用户画像推荐系统"><a href="#用户画像推荐系统" class="headerlink" title="用户画像推荐系统"></a>用户画像推荐系统</h1><p>用户画像是特征空间中的<strong>高维向量</strong></p>
<p>每个标签是特征空间中的<strong>基向量</strong></p>
<h2 id="用户画像系统流程"><a href="#用户画像系统流程" class="headerlink" title="用户画像系统流程"></a>用户画像系统流程</h2><p><img src="http://ww1.sinaimg.cn/large/006M8Ovlgy1gavasel2wrj31680o3gv5.jpg" alt="用户画像系统流程.png"></p>
<h3 id="一、明确问题"><a href="#一、明确问题" class="headerlink" title="一、明确问题"></a>一、明确问题</h3><ul>
<li>我们的需求和数据的匹配</li>
<li>我们是用来做分类、聚类、推荐还是回归等</li>
<li>数据的规模、重要特征的覆盖度等</li>
</ul>
<h3 id="二、-数据预处理"><a href="#二、-数据预处理" class="headerlink" title="二、 数据预处理"></a>二、 数据预处理</h3><ul>
<li>数据集成、冗余处理、冲突处理、采样、清洗、缺失值处理、噪声处理</li>
</ul>
<h3 id="三、-特征工程"><a href="#三、-特征工程" class="headerlink" title="三、 特征工程"></a>三、 特征工程</h3><p>数据和特征决定了机器学习的上限，而模型和算法只是逼近这个上限而已。</p>
<p><strong>特征提取</strong></p>
<ul>
<li>业务日志</li>
<li>WEB公开数据抓取</li>
<li>第三方合作</li>
</ul>
<p><strong>特征处理</strong></p>
<ul>
<li>特征清洗</li>
<li>特征预处理： 特征选择、特征组合、降维等</li>
</ul>
<p><strong>特征监控</strong></p>
<ul>
<li>指标：时效性、覆盖率和异常值</li>
<li>可视化&amp;预警</li>
</ul>
<h3 id="四、-模型和算法"><a href="#四、-模型和算法" class="headerlink" title="四、 模型和算法"></a>四、 模型和算法</h3><p><img src="http://ww1.sinaimg.cn/large/006M8Ovlgy1gavb3fyt1xj315q0opao7.jpg" alt="推荐模型和算法.png"></p>
<h2 id="用户画像建模"><a href="#用户画像建模" class="headerlink" title="用户画像建模"></a>用户画像建模</h2><p><em>标签化</em>是用户定性画像的核心，需要考虑如下问题：</p>
<ol>
<li>如何定义和表示标签</li>
<li>如何对标签进行表示</li>
<li>如何对标签进行推理</li>
<li>如何验证标签</li>
</ol>
<p>以视频画像为例</p>
<p><img src="http://ww1.sinaimg.cn/large/006M8Ovlgy1gbum373lalj30nn09wmzi.jpg" alt="用户定性画像.png"></p>
<h1 id="电商推荐系统"><a href="#电商推荐系统" class="headerlink" title="电商推荐系统"></a>电商推荐系统</h1><p>基于内容</p>
<p>基于协同过滤</p>
<p>用户画像举例：医学用户画像</p>
<p><img src="C:\Users\18439\AppData\Roaming\Typora\typora-user-images\image-20200202163428069.png" alt="image-20200202163428069"></p>
<h1 id="音乐推荐系统"><a href="#音乐推荐系统" class="headerlink" title="音乐推荐系统"></a>音乐推荐系统</h1>
          
        
      
    </div>
    
    
    

    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2020/01/11/Flink商品实时推荐系统/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Kason">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/westbrook.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Kason's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2020/01/11/Flink商品实时推荐系统/" itemprop="url">Flink商品实时推荐系统</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2020-01-11T14:55:39+08:00">
                2020-01-11
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/推荐系统/" itemprop="url" rel="index">
                    <span itemprop="name">推荐系统</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2020/01/11/Flink商品实时推荐系统/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count valine-comment-count" data-xid="/2020/01/11/Flink商品实时推荐系统/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="Flink商品实时推荐系统"><a href="#Flink商品实时推荐系统" class="headerlink" title="Flink商品实时推荐系统"></a>Flink商品实时推荐系统</h1>
          
        
      
    </div>
    
    
    

    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/12/26/What Are You Known For Learning User Topical Profiles with Implicit and Explicit Footprints/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Kason">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/westbrook.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Kason's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/12/26/What Are You Known For Learning User Topical Profiles with Implicit and Explicit Footprints/" itemprop="url">What Are You Known For? Learning User Topical Profiles with Implicit and Explicit Footprints</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-12-26T14:44:41+08:00">
                2019-12-26
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/论文合集/" itemprop="url" rel="index">
                    <span itemprop="name">论文合集</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2019/12/26/What Are You Known For Learning User Topical Profiles with Implicit and Explicit Footprints/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count valine-comment-count" data-xid="/2019/12/26/What Are You Known For Learning User Topical Profiles with Implicit and Explicit Footprints/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="Title"><a href="#Title" class="headerlink" title="Title"></a>Title</h1><p> 你以什么著称？通过隐式和显示足迹学习用户主题画像</p>
<h2 id="Research-Objective"><a href="#Research-Objective" class="headerlink" title="Research Objective"></a>Research Objective</h2><p>通过多个足迹（多源异构）构造用户主题画像</p>
<h2 id="Background-and-Problems"><a href="#Background-and-Problems" class="headerlink" title="Background and Problems"></a>Background and Problems</h2><ol>
<li>为什么</li>
<li><p>挑战</p>
</li>
<li><p>先前研究</p>
</li>
</ol>
<h2 id="Method-s"><a href="#Method-s" class="headerlink" title="Method(s)"></a>Method(s)</h2><ul>
<li>解决了匿名化Web浏览历史记录的问题，同时保留服务实用性</li>
<li>提出PBooster框架，用于量化用户隐私和在线服务质量之间的权衡，并进行验证</li>
</ul>
<h2 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h2><p>作者给了哪些结论，哪些是strong conclusions,哪些是weak的conclusions？哪些构思？</p>
<p>同时考虑隐私性和效用性，设置 $\lambda$=10时，可以返回尽可能高的隐私性，同时保持与原始数据相当的效用。</p>
<h2 id="Evaluation"><a href="#Evaluation" class="headerlink" title="Evaluation"></a>Evaluation</h2><p>作者如何评估自己的方法，实验的setup是什么样的，有没有问题或者可以借鉴的地方</p>
<p>数据来源+重要指标+模型步骤+每个步骤得出的结论</p>
<h2 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h2><p>写完笔记之后最后填，概述文章的内容。切记需要通过自己的思考，用自己的语言描述</p>
<h2 id="Notes"><a href="#Notes" class="headerlink" title="Notes"></a>Notes</h2><p>额外笔记</p>
<h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><p>(optional)列出相关性高的文献，一遍之后可以继续track</p>

          
        
      
    </div>
    
    
    

    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/12/25/Protecting User Privacy An Approach for Untraceable Web Browsing History and Unambiguous User Profiles/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Kason">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/westbrook.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Kason's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/12/25/Protecting User Privacy An Approach for Untraceable Web Browsing History and Unambiguous User Profiles/" itemprop="url">Protecting User Privacy An Approach for Untraceable Web Browsing History and Unambiguous User Profiles</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-12-25T21:12:24+08:00">
                2019-12-25
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/论文合集/" itemprop="url" rel="index">
                    <span itemprop="name">论文合集</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2019/12/25/Protecting User Privacy An Approach for Untraceable Web Browsing History and Unambiguous User Profiles/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count valine-comment-count" data-xid="/2019/12/25/Protecting User Privacy An Approach for Untraceable Web Browsing History and Unambiguous User Profiles/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="Title"><a href="#Title" class="headerlink" title="Title"></a>Title</h1><p> 保护用户隐私：一种不可跟踪的网页浏览历史和明确的用户画像方法</p>
<h2 id="Research-Objective"><a href="#Research-Objective" class="headerlink" title="Research Objective"></a>Research Objective</h2><p>保护用户的隐私的同时保留他们的网页浏览历史的效用。</p>
<h2 id="Background-and-Problems"><a href="#Background-and-Problems" class="headerlink" title="Background and Problems"></a>Background and Problems</h2><ol>
<li>为什么</li>
<li><p>挑战</p>
</li>
<li><p>先前研究</p>
</li>
</ol>
<h2 id="Method-s"><a href="#Method-s" class="headerlink" title="Method(s)"></a>Method(s)</h2><ul>
<li>解决了匿名化Web浏览历史记录的问题，同时保留服务实用性</li>
<li>提出PBooster框架，用于量化用户隐私和在线服务质量之间的权衡，并进行验证</li>
</ul>
<h2 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h2><p>作者给了哪些结论，哪些是strong conclusions,哪些是weak的conclusions？哪些构思？</p>
<p>同时考虑隐私性和效用性，设置 $\lambda$=10时，可以返回尽可能高的隐私性，同时保持与原始数据相当的效用。</p>
<h2 id="Evaluation"><a href="#Evaluation" class="headerlink" title="Evaluation"></a>Evaluation</h2><p>作者如何评估自己的方法，实验的setup是什么样的，有没有问题或者可以借鉴的地方</p>
<p>数据来源+重要指标+模型步骤+每个步骤得出的结论</p>
<h2 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h2><p>写完笔记之后最后填，概述文章的内容。切记需要通过自己的思考，用自己的语言描述</p>
<h2 id="Notes"><a href="#Notes" class="headerlink" title="Notes"></a>Notes</h2><p>额外笔记</p>
<h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><p>(optional)列出相关性高的文献，一遍之后可以继续track</p>

          
        
      
    </div>
    
    
    

    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/11/22/机器学习/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Kason">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/westbrook.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Kason's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/11/22/机器学习/" itemprop="url">机器学习</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-11-22T10:41:03+08:00">
                2019-11-22
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/机器学习/" itemprop="url" rel="index">
                    <span itemprop="name">机器学习</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2019/11/22/机器学习/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count valine-comment-count" data-xid="/2019/11/22/机器学习/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="机器学习引言"><a href="#机器学习引言" class="headerlink" title="机器学习引言"></a>机器学习引言</h1><h2 id="监督学习-Supervised-learning"><a href="#监督学习-Supervised-learning" class="headerlink" title="监督学习(Supervised learning)"></a>监督学习(Supervised learning)</h2><p>数据集中的每个样本都有相应的“正确答案”，根据这些样本作出<em>预测</em>。</p>
<h3 id="监督学习的类型"><a href="#监督学习的类型" class="headerlink" title="监督学习的类型"></a>监督学习的类型</h3><ul>
<li>回归： 推出一个<strong>连续</strong>的输出        </li>
<li>分类： 推出一组<strong>离散</strong>的结果</li>
</ul>
<h2 id="非监督学习-Unsupervised-learning"><a href="#非监督学习-Unsupervised-learning" class="headerlink" title="非监督学习(Unsupervised learning)"></a>非监督学习(Unsupervised learning)</h2><p>在未加标签的数据中，试图找到隐藏的结构。</p>
<h3 id="非监督学习的类型"><a href="#非监督学习的类型" class="headerlink" title="非监督学习的类型"></a>非监督学习的类型</h3><p><em>聚类</em>，<em>降维</em>，<em>隐马尔可夫模型</em>等。</p>
<h3 id="聚类的应用："><a href="#聚类的应用：" class="headerlink" title="聚类的应用："></a><strong>聚类</strong>的应用：</h3><ol>
<li>谷歌新闻：将非常多的新闻事件<em>自动地</em>聚类到一起  </li>
<li>基因学的应用：根据基因将个体聚类到不同的类或组  </li>
<li>社交网络的分析：根据Facebook或email自动给出朋友的分组  </li>
<li>市场分析  </li>
</ol>
<h1 id="线性回归-Linear-Regression"><a href="#线性回归-Linear-Regression" class="headerlink" title="线性回归(Linear Regression)"></a>线性回归(Linear Regression)</h1><h2 id="描述回归问题的标记"><a href="#描述回归问题的标记" class="headerlink" title="描述回归问题的标记"></a>描述回归问题的标记</h2><p>$m$ 代表训练集中实例的数量</p>
<p>$x$  代表特征/输入变量</p>
<p>$y$ 代表目标变量/输出变量</p>
<p>$\left( x,y \right)$ 代表训练集中的实例</p>
<p>$\left(x^\left(i\right),y^\left(i\right)\right)$ 代表第$i$ 个观察实例</p>
<p>$h$  代表学习算法的解决方案或函数也称为假设（<strong>hypothesis</strong>）</p>
<p><img src="http://ww1.sinaimg.cn/large/006M8Ovlly1g7qq9p01v9j309f07jweb.jpg" alt="回归流程.png"></p>
<p><strong>h的表达形式</strong>：</p>
<p>一种表达形式 $h_\theta \left( x \right)=\theta_{0} + \theta_{1}x_1 +···+\theta_nx_n$</p>
<p><strong>代价函数：</strong>（均方误差）</p>
<p>$J(\theta_0,\theta_1,···\theta_n)=\frac{1}{2m}\sum_{i=1}^m (h_\theta(x^{(i)})-y^{(i)})^2$</p>
<p>这里除以m是希望之后计算梯度时大小不随样本数量的增多而增大</p>
<p><strong>批量梯度下降算法：</strong></p>
<p>$\theta_j:=\theta_j-\alpha\frac{\partial }{\partial \theta_j}J(\theta_0,\theta_1,···\theta_n)  $    </p>
<p>线性回归问题可以改写为：</p>
<p>$\theta_0:=\theta_0-\alpha\frac{1}{m}\sum_{i=1}^m(h_\theta(x^{(i)})-y^{(i)}·x_0^{(i)})$               $x_0^{(i)}=1$</p>
<p>$\theta_1:=\theta_1-\alpha\frac{1}{m}\sum_{i=1}^m(h_\theta(x^{(i)})-y^{(i)}·x_1^{(i)})$ </p>
<p>$···$</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">theta = np.zeros(X.shape[<span class="number">1</span>]) <span class="comment"># theta代表特征（变量）数</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">gradient</span><span class="params">(theta, X, y)</span>:</span>  <span class="comment"># 求导，这里将x0赋为1，同其他变量一起求导</span></span><br><span class="line">    m = X.shape[<span class="number">0</span>]  <span class="comment"># 样本数</span></span><br><span class="line">    inner = X.T @ (X @ theta - y)</span><br><span class="line">    <span class="keyword">return</span> inner / m</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">batch_gradient_decent</span><span class="params">(theta, X, y, epoch, alpha=<span class="number">0.01</span>)</span>:</span></span><br><span class="line">    _theta = theta.copy()</span><br><span class="line">    cost_data = [lr_cost(theta, X, y)]</span><br><span class="line">    <span class="keyword">for</span> _ <span class="keyword">in</span> range(epoch):</span><br><span class="line">        _theta = _theta - alpha * gradient(_theta, X, y)</span><br><span class="line">        cost_data.append(lr_cost(_theta, X, y))</span><br><span class="line">    <span class="keyword">return</span> _theta, cost_data</span><br></pre></td></tr></table></figure>
<h2 id="梯度下降实践"><a href="#梯度下降实践" class="headerlink" title="梯度下降实践"></a>梯度下降实践</h2><p><strong>特征缩放</strong></p>
<p>最简单的方法:   $x_n=\frac{x_n-\mu_n}{s_n}$，其中$\mu_n$是平均值，$s_n$是范围</p>
<p><strong>学习率</strong></p>
<p>画出代价函数随迭代次数的图像。若出现上升情形，很可能是因为学习率$\alpha$取值过大</p>
<p>通常考虑$\alpha=0.03,0.3,1,3,10$</p>
<h2 id="正规方程"><a href="#正规方程" class="headerlink" title="正规方程"></a>正规方程</h2><p>算术求解出最优$\theta$</p>
<p>$\theta=(X^TX)^{-1}X^Ty$</p>
<p>大多数情况下，$(X^TX)^{-1}$是可逆的，若不可逆，有以下<strong>两种情况</strong>：</p>
<ul>
<li>特征值里有一些多余的特征，如果其中$x_1$和$x_2$是线性相关的，会导致不可逆，我们需要删除重复特征里的其中一个</li>
<li>特征数量太多(m&lt;=n)，导致不可逆。可以用较少的特征来反映尽可能多内容，或者考虑使用正则化的方法。</li>
</ul>
<p><strong>$\theta$的推导过程（略）</strong></p>
<h1 id="逻辑回归"><a href="#逻辑回归" class="headerlink" title="逻辑回归"></a>逻辑回归</h1><p>在分类问题中，逻辑回归（Logistic Regression)是目前最流行使用最广泛的一种学习算法。</p>
<h2 id="二分类"><a href="#二分类" class="headerlink" title="二分类"></a>二分类</h2><p><strong>模型假设</strong></p>
<p>$h_\theta(x)=g(\theta^TX)$  其中 X代表特征向量，g代表逻辑函数</p>
<p>一个常用的逻辑函数为S形函数，公式为$g(z)=\frac{1}{1+e^{-z}}$</p>
<p><strong>代价函数</strong>（交叉熵）</p>
<p>若仍使用平方误差，得到的代价函数是非凸函数，因此采用交叉熵</p>
<p>$J(\theta ) = -\frac{1}{m}\left[\sum_{i=1}^{m}y^{(i)}log(h_\theta (x^{(i)}))+(1-y^{(i)})log(1-h_\theta (x^{(i)})) \right]$</p>
<p>其中，$h_\theta (x^{(i)}) = \frac{1}{1+e^{-\theta^\mathrm {T} x}}$</p>
<p><strong>梯度下降</strong></p>
<p>$\frac{\partial J(\theta)}{\partial \theta_{j}} = \frac{1}{m}\left[\sum_{i=1}^{m}(h_\theta(x^{(i)})-y^{(i)})x_{j}^{(i)}\right]$</p>
<p>$\theta_j:=\theta_j-\alpha\frac{1}{m}\left[\sum_{i=1}^{m}(h_\theta(x^{(i)})-y^{(i)})x_{j}^{(i)}\right]$</p>
<p>即使更新参数的规则看起来和线性回归一致，由于假设的定义发生了变化，所以是完全不同的</p>
<p><strong>高级优化</strong></p>
<p>除了梯度下降法，我们还可以采用其他方法进行优化，比如共轭梯度法，BFGS（变尺度法），L-BFGS（限制变尺度法）。这三种算法不需要手动选择学习率$\alpha$，它们内部有一个<strong>线性搜索</strong>算法</p>
<h2 id="一对多"><a href="#一对多" class="headerlink" title="一对多"></a>一对多</h2><p>使用二分类的思想，将一个类别标记为正向类，其他的所有类标记为负向类，进行多次分类。</p>
<p>得到的一系列模型记为： $h_\theta^{(i)}(x)=p(y=i|x;\theta)$其中：i=(1,2,…k)</p>
<p><strong>目标</strong></p>
<p>$\max_i h_\theta^{(i)}(x)$</p>
<p>在n个分类器中输入x，选择一个让$h_\theta^{(i)}(x)$最大的i</p>
<h2 id="Exercise-多项式特征映射"><a href="#Exercise-多项式特征映射" class="headerlink" title="Exercise(多项式特征映射)"></a>Exercise(多项式特征映射)</h2><p>如果样本量多，逻辑问题很复杂<strong>原始特征</strong>只有x1，x2，可以用多项式创建更多的特征。因为更多的特征可以得到的分割线可以是<strong>高阶</strong>函数的形状</p>
<p>eg: 有a,b两个特征，那么它的2次多项式的次数为[1,a,b,$a^2$,ab,$b^2$]</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">feature_mapping</span><span class="params">(x, y, power, as_ndarray=False)</span>:</span></span><br><span class="line"><span class="comment">#     """return mapped features as ndarray or dataframe"""</span></span><br><span class="line">    <span class="comment"># data = &#123;&#125;</span></span><br><span class="line">    <span class="comment"># # inclusive</span></span><br><span class="line">    <span class="comment"># for i in np.arange(power + 1):</span></span><br><span class="line">    <span class="comment">#     for p in np.arange(i + 1):</span></span><br><span class="line">    <span class="comment">#         data["f&#123;&#125;&#123;&#125;".format(i - p, p)] = np.power(x, i - p) * np.power(y, p)</span></span><br><span class="line"></span><br><span class="line">    data = &#123;<span class="string">"f&#123;&#125;&#123;&#125;"</span>.format(i - p, p): np.power(x, i - p) * np.power(y, p)</span><br><span class="line">                <span class="keyword">for</span> i <span class="keyword">in</span> np.arange(power + <span class="number">1</span>)</span><br><span class="line">                <span class="keyword">for</span> p <span class="keyword">in</span> np.arange(i + <span class="number">1</span>)</span><br><span class="line">            &#125;</span><br></pre></td></tr></table></figure>
<p>其中power的值代表最高阶次数</p>
<h2 id="Question"><a href="#Question" class="headerlink" title="Question"></a>Question</h2><ol>
<li>逻辑回归为什么是线性的？而神经网络不是线性的？</li>
</ol>
<p>主要依据<strong>决策边界</strong>。LR的决策边界是线性的。$\hat\theta·x=0$是线性的</p>
<p>而神经网络的边界不是线性的。</p>
<h1 id="正则化"><a href="#正则化" class="headerlink" title="正则化"></a>正则化</h1><p><strong>如何解决过拟合：</strong></p>
<ul>
<li>减少特征变量</li>
<li>正则化。保留所有的特征，但是减少参数的大小  </li>
</ul>
<h2 id="正则化线性回归"><a href="#正则化线性回归" class="headerlink" title="正则化线性回归"></a>正则化线性回归</h2><p><strong>正则化线性回归的代价函数：</strong></p>
<p>$J( \theta)=\frac{1}{2m}[ {\sum\limits_{i = 1}^m ( h_\theta( x^{(i)}  - y^{(i)}) ^2+ \lambda \sum\limits_{j = 1}^n {\theta _j^2} } ]$</p>
<p>此时梯度下降法：</p>
<p>Repeat{</p>
<p>${\theta _0}: = {\theta _0} - \alpha \left[ {\frac{1}{m}\sum\limits_{i = 1}^m {\left( {h_\theta \left( {x^{\left( i \right)}} \right) - {y^{\left( i \right)}}} \right)x_0^{\left( i \right)}} } \right]$</p>
<script type="math/tex; mode=display">{\theta _j}: = {\theta _j} - \alpha \left[ {\frac{1}{m}\sum\limits_{i = 1}^m {\left( {h_\theta \left( {x^{\left( i \right)}} \right) - {y^{\left( i \right)}}} \right)x_j^{\left( i \right)} + \frac{\lambda }{m}{\theta _j}} } \right]\left( {j = 1,2,...,n} \right)</script><p>}</p>
<p><strong>正规方程求解：</strong></p>
<script type="math/tex; mode=display">\theta = {\left( {X^TX + \lambda \left[ {\begin{array}{*{20}{c}} 0&0&0&0\\ 0&1&0&0\\ .&.&.&.\\ 0&0&0&1 \end{array}} \right]} \right)^{ - 1}}{X^T}y</script><p>图中的矩阵尺寸为（n+1)*（n+1)</p>
<h2 id="正则化逻辑回归"><a href="#正则化逻辑回归" class="headerlink" title="正则化逻辑回归"></a>正则化逻辑回归</h2><p> <strong>正规化逻辑回归代价函数</strong></p>
<p>$J(\theta ) = -\frac{1}{m}\left[\sum_{i=1}^{m}y^{(i)}log(h_\theta (x^{(i)}))+(1-y^{(i)})log(1-h_\theta (x^{(i)})) \right]+\frac{\lambda}{2m}\sum_\limits{j=1}^n\theta_j^2$</p>
<p>此时梯度下降法：</p>
<p>Repeat{</p>
<p>${\theta _0}: = {\theta _0} - \alpha \left[ {\frac{1}{m}\sum\limits_{i = 1}^m {\left( {h_\theta \left( {x^{\left( i \right)}} \right) - {y^{\left( i \right)}}} \right)x_0^{\left( i \right)}} } \right]$</p>
<p>${\theta _j}: = {\theta _j} - \alpha \left[ {\frac{1}{m}\sum\limits_{i = 1}^m {\left( {h_\theta \left( {x^{\left( i \right)}} \right) - {y^{\left( i \right)}}} \right)x_j^{\left( i \right)} + \frac{\lambda }{m}{\theta _j}} } \right]\left( {j = 1,2,…,n} \right)$</p>
<p>}</p>
<h1 id="神经网络"><a href="#神经网络" class="headerlink" title="神经网络"></a>神经网络</h1><p><strong>代价函数</strong></p>
<p>$J(\Theta) = -\frac{ 1 }{ m }[\sum_\limits{ i=1 }^{ m } \sum_\limits{ k=1 }^{ k } ({y_k^{(i)} \log(h_\Theta(x^{(i)}))_k + (1 - y_k^{(i)}) \log (1 - (h_\Theta(x^{(i)}))_k})]+\frac{\lambda}{2m}\sum_\limits{l=1}^{L-1}\sum_\limits{i=1}^{s_l}\sum_\limits{j=1}^{s_{l+1}}(\Theta_{ji}^{(l)})^2)$</p>
<p>其中 ${\left( {h_\Theta }\left( x \right) \right)_i}$ = 神经网络的第i个输出</p>
<p>正则化项中：最里层的j循环所有的行，i循环所有的列，最外层是神经元的层数。</p>
<h2 id="向前传播"><a href="#向前传播" class="headerlink" title="向前传播"></a>向前传播</h2><p>公式$a_j^l=\sigma(\sum\limits_kw_{jk}^l\alpha_k^{l-1}+b_j^l)$</p>
<p>$b_j^l$表示在$l^{th}$层第$j^{th}$个神经元的偏置，$\alpha_j^{l}$表示$l^{th}$层第$j^{th}$个神经元的激活值</p>
<p>$w_{jk}^l$是从$(l-1)^{th}$层的第$k^{th}$个神经元到$l^{th}$层的第$j^{th}$个神经元的连接上的权重</p>
<p>对于一个四层的神经网络</p>
<p>$\begin{array}{l} {a^{\left( 1 \right)}} = x\\ {z^{\left( 2 \right)}} = {\Theta ^{\left( 1 \right)}}{a^{\left( 1 \right)}}\\ {a^{\left( 2 \right)}} = g\left( {z^{\left( 2 \right)}} \right)\left( { + a_0^{\left( 2 \right)}} \right)\\ {z^{\left( 3 \right)}} = {\Theta ^{\left( 2 \right)}}{a^{\left( 2 \right)}}\\ {a^{\left( 3 \right)}} = g\left( {z^{\left( 3 \right)}} \right)\left( { + a_0^{\left( 3 \right)}} \right)\\ {z^{\left( 4 \right)}} = {\Theta ^{\left( 3 \right)}}{a^{\left( 3 \right)}}\\ {a^{\left( 4 \right)}} = {h_\Theta }\left( x \right) = g\left( {z^{\left( 4 \right)}} \right) \end{array}$</p>
<h2 id="反向传播"><a href="#反向传播" class="headerlink" title="反向传播"></a>反向传播</h2><p>反向传播的目标是计算代价函数C分别关于w和b的偏导数$\frac{\partial C}{\partial w}$和$\frac{\partial C}{\partial b}$</p>
<p><img src="http://ww1.sinaimg.cn/large/006M8Ovlly1g9ah3vzgxdj30ef05lq39.jpg" alt="反向传播1.png"></p>
<p><strong>反向传播算法描述</strong></p>
<p><img src="http://ww1.sinaimg.cn/large/006M8Ovlly1g9ahes3t3aj30jv05wt9q.jpg" alt="反向传播2.png"></p>
<p><strong>梯度检查</strong></p>
<p>$\frac{\text{d}}{\text{d}\Theta}J(\Theta)\approx\frac{J(\Theta+\epsilon)-J(\Theta-\epsilon)}{2\epsilon}$</p>
<p>没有使用这种方法计算偏导数的原因：反向传播可以同时计算所有的偏导数$\frac{\partial C}{\partial w}$</p>
<p><strong>随机初始化</strong></p>
<p>初始化所有的$\theta$为0是不行的，因此随机初始化参数矩阵</p>
<h2 id="Exercise（手写数字识别）"><a href="#Exercise（手写数字识别）" class="headerlink" title="Exercise（手写数字识别）"></a>Exercise（手写数字识别）</h2><h3 id="正向传播"><a href="#正向传播" class="headerlink" title="正向传播"></a>正向传播</h3><ul>
<li>一维模型（一对多分类）</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> k <span class="keyword">in</span> range(<span class="number">1</span>, <span class="number">11</span>):</span><br><span class="line">    y_matrix.append((raw_y == k).astype(int))</span><br></pre></td></tr></table></figure>
<p><img src="http://ww1.sinaimg.cn/large/006M8Ovlly1g9alf9j5qwj31360qvq4o.jpg" alt="向量化标签.png"></p>
<p>采用LR，一次只能在2个类之间进行分类</p>
<ul>
<li>k维模型</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">k_theta = np.array([logistic_regression(X, y[k]) <span class="keyword">for</span> k <span class="keyword">in</span> range(<span class="number">10</span>)])</span><br><span class="line">prob_matrix = sigmoid(X @ k_theta.T)</span><br><span class="line">y_pred = np.argmax(prob_matrix, axis=<span class="number">1</span>) <span class="comment">#返回沿轴axis最大值的索引，axis=1代表行</span></span><br><span class="line">y_answer = raw_y.copy()</span><br><span class="line">y_answer[y_answer==<span class="number">10</span>] = <span class="number">0</span>  <span class="comment"># 之前已将标签为10移至第1列</span></span><br><span class="line">print(classification_report(y_answer, y_pred))</span><br></pre></td></tr></table></figure>
<p>可以进行所有标签预测</p>
<ul>
<li>前馈预测（默认已有weight和b矩阵）</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> scipy.io <span class="keyword">as</span> sio</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> classification_report</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">sigmoid</span><span class="params">(z)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> <span class="number">1</span> / (<span class="number">1</span> + np.exp(-z))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">load_weight</span><span class="params">(path)</span>:</span></span><br><span class="line">    data = sio.loadmat(path)</span><br><span class="line">    <span class="keyword">return</span> data[<span class="string">'Theta1'</span>], data[<span class="string">'Theta2'</span>]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">load_data</span><span class="params">(path)</span>:</span></span><br><span class="line">    data = sio.loadmat(path)</span><br><span class="line">    y = data.get(<span class="string">'y'</span>)  <span class="comment"># (5000,1)</span></span><br><span class="line">    y = y.reshape(y.shape[<span class="number">0</span>])  <span class="comment"># make it back to column vector</span></span><br><span class="line"></span><br><span class="line">    X = data.get(<span class="string">'X'</span>)  <span class="comment"># (5000,400)</span></span><br><span class="line">    <span class="keyword">return</span> X, y</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">theta1, theta2 = load_weight(<span class="string">'ex3weights.mat'</span>)</span><br><span class="line"></span><br><span class="line">X, y = load_data(<span class="string">'ex3data1.mat'</span>)</span><br><span class="line"></span><br><span class="line">X = np.insert(X, <span class="number">0</span>, values=np.ones(X.shape[<span class="number">0</span>]), axis=<span class="number">1</span>)  <span class="comment"># intercept</span></span><br><span class="line">a1 = X</span><br><span class="line">z2 = a1 @ theta1.T  <span class="comment"># (5000, 401) @ (25,401).T = (5000, 25)</span></span><br><span class="line">z2 = np.insert(z2, <span class="number">0</span>, values=np.ones(z2.shape[<span class="number">0</span>]), axis=<span class="number">1</span>)</span><br><span class="line">a2 = sigmoid(z2)</span><br><span class="line">z3 = a2 @ theta2.T</span><br><span class="line">a3 = sigmoid(z3)</span><br><span class="line">y_pred = np.argmax(a3, axis=<span class="number">1</span>) + <span class="number">1</span>   <span class="comment"># numpy is 0 base index, +1 for matlab convention</span></span><br><span class="line"></span><br><span class="line">print(classification_report(y, y_pred))</span><br></pre></td></tr></table></figure>
<h3 id="反向传播-1"><a href="#反向传播-1" class="headerlink" title="反向传播"></a>反向传播</h3><p>首先进行<strong>正向传播</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">feed_forward</span><span class="params">(theta, X)</span>:</span></span><br><span class="line">    <span class="string">"""apply to architecture 400+1 * 25+1 *10</span></span><br><span class="line"><span class="string">    X: 5000 * 401</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line"></span><br><span class="line">    t1, t2 = deserialize(theta)  <span class="comment"># t1: (25,401) t2: (10,26)</span></span><br><span class="line">    m = X.shape[<span class="number">0</span>]</span><br><span class="line">    a1 = X  <span class="comment"># 5000 * 401</span></span><br><span class="line"></span><br><span class="line">    z2 = a1 @ t1.T  <span class="comment"># 5000 * 25</span></span><br><span class="line">    a2 = np.insert(sigmoid(z2), <span class="number">0</span>, np.ones(m), axis=<span class="number">1</span>)  <span class="comment"># 5000*26</span></span><br><span class="line"></span><br><span class="line">    z3 = a2 @ t2.T  <span class="comment"># 5000 * 10</span></span><br><span class="line">    h = sigmoid(z3)  <span class="comment"># 5000*10, this is h_theta(X)</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> a1, z2, a2, z3, h  <span class="comment"># you need all those for backprop</span></span><br></pre></td></tr></table></figure>
<p>接着进行<strong>反向梯度下降</strong></p>
<p><img src="http://ww1.sinaimg.cn/large/006M8Ovlly1g9ahes3t3aj30jv05wt9q.jpg" alt="反向传播2.png"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 反向传播梯度下降</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">gradient</span><span class="params">(theta, X, y)</span>:</span></span><br><span class="line">    <span class="comment"># initialize</span></span><br><span class="line">    t1, t2 = deserialize(theta)  <span class="comment"># t1: (25,401) t2: (10,26)</span></span><br><span class="line">    m = X.shape[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">    delta1 = np.zeros(t1.shape)  <span class="comment"># (25, 401)</span></span><br><span class="line">    delta2 = np.zeros(t2.shape)  <span class="comment"># (10, 26)</span></span><br><span class="line"></span><br><span class="line">    a1, z2, a2, z3, h = feed_forward(theta, X)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(m):</span><br><span class="line">        a1i = a1[i, :]  <span class="comment"># (1, 401)</span></span><br><span class="line">        z2i = z2[i, :]  <span class="comment"># (1, 25)</span></span><br><span class="line">        a2i = a2[i, :]  <span class="comment"># (1, 26)</span></span><br><span class="line"></span><br><span class="line">        hi = h[i, :]    <span class="comment"># (1, 10)</span></span><br><span class="line">        yi = y[i, :]    <span class="comment"># (1, 10)</span></span><br><span class="line"></span><br><span class="line">        d3i = hi - yi  <span class="comment"># (1, 10)    </span></span><br><span class="line"></span><br><span class="line">        z2i = np.insert(z2i, <span class="number">0</span>, np.ones(<span class="number">1</span>))  <span class="comment"># make it (1, 26) to compute d2i</span></span><br><span class="line">        d2i = np.multiply(t2.T @ d3i, sigmoid_gradient(z2i))  <span class="comment"># (1, 26)</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># careful with np vector transpose</span></span><br><span class="line">        delta2 += np.matrix(d3i).T @ np.matrix(a2i)  <span class="comment"># (1, 10).T @ (1, 26) -&gt; (10, 26)</span></span><br><span class="line">        delta1 += np.matrix(d2i[<span class="number">1</span>:]).T @ np.matrix(a1i)  <span class="comment"># (1, 25).T @ (1, 401) -&gt; (25, 401)</span></span><br><span class="line"></span><br><span class="line">    delta1 = delta1 / m</span><br><span class="line">    delta2 = delta2 / m</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> serialize(delta1, delta2)</span><br></pre></td></tr></table></figure>
<p><strong>注：</strong>$d3i$即为输出层误差，$d2i$为隐含层误差</p>
<p>这里返回的delta1，delta2是C对w求偏导的结果，这里的w包括b</p>
<h3 id="梯度校验"><a href="#梯度校验" class="headerlink" title="梯度校验"></a>梯度校验</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">gradient_checking</span><span class="params">(theta, X, y, epsilon, regularized=False)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">a_numeric_grad</span><span class="params">(plus, minus, regularized=False)</span>:</span></span><br><span class="line">        <span class="string">"""calculate a partial gradient with respect to 1 theta"""</span></span><br><span class="line">        <span class="keyword">if</span> regularized:</span><br><span class="line">            <span class="keyword">return</span> (regularized_cost(plus, X, y) - regularized_cost(minus, X, y)) / (epsilon * <span class="number">2</span>)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">return</span> (cost(plus, X, y) - cost(minus, X, y)) / (epsilon * <span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">    theta_matrix = expand_array(theta)  <span class="comment"># expand to (10285, 10285)</span></span><br><span class="line">    epsilon_matrix = np.identity(len(theta)) * epsilon</span><br><span class="line"></span><br><span class="line">    plus_matrix = theta_matrix + epsilon_matrix</span><br><span class="line">    minus_matrix = theta_matrix - epsilon_matrix</span><br><span class="line"></span><br><span class="line">    <span class="comment"># calculate numerical gradient with respect to all theta</span></span><br><span class="line">    numeric_grad = np.array([a_numeric_grad(plus_matrix[i], minus_matrix[i], regularized)</span><br><span class="line">                                    <span class="keyword">for</span> i <span class="keyword">in</span> range(len(theta))])</span><br><span class="line"></span><br><span class="line">    <span class="comment"># analytical grad will depend on if you want it to be regularized or not</span></span><br><span class="line">    analytic_grad = regularized_gradient(theta, X, y) <span class="keyword">if</span> regularized <span class="keyword">else</span> gradient(theta, X, y)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># If you have a correct implementation, and assuming you used EPSILON = 0.0001</span></span><br><span class="line">    <span class="comment"># the diff below should be less than 1e-9</span></span><br><span class="line">    <span class="comment"># this is how original matlab code do gradient checking</span></span><br><span class="line">    diff = np.linalg.norm(numeric_grad - analytic_grad) / np.linalg.norm(numeric_grad + analytic_grad)</span><br><span class="line">    </span><br><span class="line">    </span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">expand_array</span><span class="params">(arr)</span>:</span></span><br><span class="line">    <span class="string">"""replicate array into matrix</span></span><br><span class="line"><span class="string">    [1, 2, 3]</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    [[1, 2, 3],</span></span><br><span class="line"><span class="string">     [1, 2, 3],</span></span><br><span class="line"><span class="string">     [1, 2, 3]]</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    <span class="comment"># turn matrix back to ndarray</span></span><br><span class="line">    <span class="keyword">return</span> np.array(np.matrix(np.ones(arr.shape[<span class="number">0</span>])).T @ np.matrix(arr))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 运行</span></span><br><span class="line">gradient_checking(theta, X, y, epsilon= <span class="number">0.0001</span>)<span class="comment">#这个运行很慢，谨慎运行</span></span><br></pre></td></tr></table></figure>
<p>If your backpropagation implementation is correct，the relative difference will be smaller than 10e-9 (assume epsilon=0.0001)</p>
<h1 id="机器学习诊断法"><a href="#机器学习诊断法" class="headerlink" title="机器学习诊断法"></a>机器学习诊断法</h1><h2 id="模型选择"><a href="#模型选择" class="headerlink" title="模型选择"></a>模型选择</h2><p>一般使用60%的数据作为训练集，使用20%的数据作为<strong>交叉验证集</strong>，20%的数据作为测试集。</p>
<p>这样比只分训练集和测试集相比，可以得到更好的泛化误差。</p>
<p><strong>模型选择的方法</strong></p>
<ol>
<li>使用训练集训练出（比如）10个模型</li>
<li>用这些模型在交叉验证集中计算交叉验证误差（代价函数）</li>
<li>选取交叉验证误差最小的模型</li>
<li>利用这个模型计算测试集中的泛化误差（代价函数的值）</li>
</ol>
<p>训练误差：</p>
<p>$J_{train}(\Theta)=\frac{1}{2m}\sum_\limits{i=1}^m (h_\Theta(x^{(i)})-y^{(i)})^2$</p>
<p>交叉验证误差：</p>
<p>$J_{CV}(\Theta)=\frac{1}{2m}\sum_\limits{i=1}^m (h_\Theta(x_{CV}^{(i)})-y_{CV}^{(i)})^2$</p>
<h2 id="偏差-Bias-和方差-Variance"><a href="#偏差-Bias-和方差-Variance" class="headerlink" title="偏差(Bias)和方差(Variance)"></a>偏差(Bias)和方差(Variance)</h2><p><img src="http://ww1.sinaimg.cn/large/006M8Ovlly1g9g8gscmvaj30he0bn76e.jpg" alt="方差和偏差.png"></p>
<p>如何判断是欠拟合（偏差）还是过拟合（方差）：</p>
<ul>
<li><p>训练集误差和交叉验证集误差近似时：偏差/欠拟合- </p>
</li>
<li><p>交叉验证集误差&gt;&gt;训练集误差时：方差/过拟合</p>
</li>
</ul>
<h2 id="正则化-1"><a href="#正则化-1" class="headerlink" title="正则化"></a>正则化</h2><p>对于${h_\theta }\left( x \right) = {\theta _0} + {\theta _1}x + {\theta _2}{x^2} + {\theta _3}{x^3} + {\theta _4}{x^4}$</p>
<p>及$J( \theta)=\frac{1}{2m}[ {\sum\limits_{i = 1}^m ( h_\theta( x^{(i)}  - y^{(i)}) ^2+ \lambda \sum\limits_{j = 1}^n {\theta _j^2} } ]$</p>
<p><strong>选择$\lambda$的方法</strong></p>
<p>类似选择模型的方法，将训练集和交叉验证集的代价函数误差与$\lambda$的值绘制在一张图表上</p>
<p><img src="http://ww1.sinaimg.cn/large/006M8Ovlly1g9g8rzzas0j30fo0apjsn.jpg" alt="正则化偏差和方差.png"></p>
<ul>
<li>当$\lambda$较小时，训练集误差较小（过拟合），交叉验证集误差较大</li>
<li>随着$\lambda$的增加，训练集误差不断增加（欠拟合），而交叉验证集误差先减小后增加</li>
</ul>
<h2 id="学习曲线"><a href="#学习曲线" class="headerlink" title="学习曲线"></a>学习曲线</h2><p>学习曲线是学习算法的一个很好的合理检验（sanity check）。绘制训练集误差和交叉验证集误差随训练实例数量（m）的变化图</p>
<p><strong>高偏差</strong></p>
<p><img src="http://ww1.sinaimg.cn/large/006M8Ovlly1g9g8zh54ubj30fv09vmxw.jpg" alt="高偏差.png"></p>
<p><strong>高方差</strong></p>
<p><img src="http://ww1.sinaimg.cn/large/006M8Ovlly1g9g8zsog2dj30db09374y.jpg" alt="高方差.png"></p>
<ul>
<li>对于欠拟合，增加数据到训练集不一定有帮助</li>
<li>对于过拟合，增加更多数据到训练集可能提高算法效果</li>
</ul>
<h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><p><strong>改进算法策略</strong></p>
<ol>
<li>获取更多的训练实例   —解决高方差</li>
<li>尝试减少特征的数量  —解决高方差</li>
<li>获取更多特征  —解决高偏差</li>
<li>增加多项式特征  —解决高偏差</li>
<li>减少正则化程度$\lambda$  —解决高偏差</li>
<li>增加正则化程度$\lambda$  —解决高方差</li>
</ol>
<h3 id="神经网络中的偏差和方差"><a href="#神经网络中的偏差和方差" class="headerlink" title="神经网络中的偏差和方差"></a>神经网络中的偏差和方差</h3><ul>
<li>使用较小的神经网络，容易导致高偏差和欠拟合</li>
<li>使用较大地神经网络，容易导致高方差和过拟合</li>
</ul>
<p>通常选择较大的神经网络并采用正则化处理，这样比使用较小网络效果要好</p>
<p>选择隐含层的方法和选择模型的方法类似。</p>
<h1 id="机器学习系统设计"><a href="#机器学习系统设计" class="headerlink" title="机器学习系统设计"></a>机器学习系统设计</h1><h2 id="学习算法的推荐方法"><a href="#学习算法的推荐方法" class="headerlink" title="学习算法的推荐方法"></a><strong>学习算法的推荐方法</strong></h2><ol>
<li>简答快速的实现一个算法，并用交叉验证集数据测试这个算法</li>
<li>绘制学习曲线，决定是增加更多数据，特征还是其他</li>
<li>进行<strong>误差分析</strong>：人工检查交叉验证集中我们算法产生预测误差的实例，看看这些实例是否有某种系统化变化的趋势</li>
</ol>
<h2 id="类偏斜"><a href="#类偏斜" class="headerlink" title="类偏斜"></a>类偏斜</h2><p>类偏斜（skewed classes）：训练集中有非常多的同一种类的实例，只有很少或没有其他类的实例</p>
<p><strong>分类问题指标</strong></p>
<ul>
<li>真阳性 TP : 预测为正，实际为正</li>
<li>假阳性 FP：预测为正，实际为负</li>
<li>假阴性 FN：预测为负，实际为正</li>
<li>真阴性 TN：预测为负，实际为负</li>
</ul>
<p><strong>查准率</strong>：预测为正的样本中有多少正样本</p>
<p>$P=\frac{TP}{TP+FP}$</p>
<p><strong>查全率：</strong>样本中的正例有多少被预测正确了</p>
<p>$R=\frac{TP}{TP+FN}$</p>
<p><strong>F1-Score</strong></p>
<p>衡量二分类模型精确度的一种指标</p>
<p>$F_1=2·\frac{precision·recall}{precision+recall}$</p>
<h2 id="机器学习数据"><a href="#机器学习数据" class="headerlink" title="机器学习数据"></a>机器学习数据</h2><p>得到一个性能很好的学习算法思路：</p>
<ul>
<li>特征值有足够多信息，这样可以保证低偏差</li>
</ul>
<h1 id="支持向量机（SVM"><a href="#支持向量机（SVM" class="headerlink" title="支持向量机（SVM)"></a>支持向量机（SVM)</h1><h2 id="假设函数"><a href="#假设函数" class="headerlink" title="假设函数"></a>假设函数</h2><p>在逻辑回归中，对于一个样本（x,y)来说，它的损失函数为：$-ylog(\frac{1}{1+e^{-\theta^Tx}})-(1-y)log(1-\frac{1}{1+e^{-\theta^Tx}})$</p>
<ul>
<li>对于y=1的情况，损失函数变为$-log(\frac{1}{1+e^{-z}})$</li>
</ul>
<p><img src="http://ww1.sinaimg.cn/large/006M8Ovlly1g9hdw1lzgnj30f30ad0tt.jpg" alt="y=1.png"></p>
<p>支持向量机将绿线替换成红线，称改变后的损失函数为：$Cost_1(z)$</p>
<ul>
<li>对于y=0的情况</li>
</ul>
<p><img src="http://ww1.sinaimg.cn/large/006M8Ovlly1g9hdyurbzcj30fk0ajgmy.jpg" alt="y=0.png"></p>
<p><img src="http://ww1.sinaimg.cn/large/006M8Ovlly1g9he0grto0j30l30blwf8.jpg" alt="svm假设函数.png"></p>
<p>因此，支持向量机的目标是：</p>
<p>$\underbrace{min}_\theta\left\{C\left[\sum_\limits{i=1}^my^{(i)}Cost_1\left(\theta^Tx^{(i)}\right)+\left(1-y^{(i)}\right)Cost_0\left(\theta^Tx^{(i)}\right)\right]+\frac{1}{2}\sum_\limits{j=1}^n\theta_j^2\right\}$</p>
<p>其中，假设函数为：</p>
<p>$h_\theta(x)=\begin{cases}1 &amp; \theta^Tx\geq0\\0 &amp; \theta^Tx&lt;0\end{cases}$</p>
<h2 id="大间距分类器（Large-Margin-Classifier"><a href="#大间距分类器（Large-Margin-Classifier" class="headerlink" title="大间距分类器（Large Margin Classifier)"></a>大间距分类器（Large Margin Classifier)</h2><p>支持向量机的<strong>目标</strong>是：</p>
<p>$\underbrace{min}_\theta\left\{C\left[\sum_\limits{i=1}^my^{(i)}Cost_1\left(\theta^Tx^{(i)}\right)+\left(1-y^{(i)}\right)Cost_0\left(\theta^Tx^{(i)}\right)\right]+\frac{1}{2}\sum_\limits{j=1}^n\theta_j^2\right\}$</p>
<p>下图分别是$Cost_1(z)$和$Cost_0(z)$的示意图：</p>
<p><img src="http://ww1.sinaimg.cn/large/006M8Ovlly1g9hfk2oj4pj30fu06874o.jpg" alt="svm cost.png"></p>
<p>如果y=1，我们想要$\theta^Tx\geq1$（而不仅仅是$\theta^Tx\geq0)$</p>
<p>如果y=0，我们想要$\theta^Tx\leq-1$（而不仅仅是$\theta^Tx&lt;0)$</p>
<p><strong>参数C对decision boundary的影响</strong></p>
<p><img src="http://ww1.sinaimg.cn/large/006M8Ovlly1g9hfy4wretj30cs09a0tw.jpg" alt="svm边界.png"></p>
<p>当C非常大时，会得到黄色的线，此时过拟合</p>
<p>当C不是适当时，它可以忽略掉一些异常点的影响，得到更好的决策界</p>
<p><strong>大间距分类器的原因</strong></p>
<p>对于代价目标的后半部分：$\frac{1}{2}\sum_\limits{j=1}^n\theta_j^2$=$\frac{1}{2}\parallel\theta\parallel^2$</p>
<p>当y=1时，$\theta^Tx$会朝着$\theta^Tx\geq1$的趋势去优化$\theta$，加上第二部分的$\theta$尽量小，则对于</p>
<p>$\theta^Tx^{(i)}=p^{(i)}\parallel\theta\parallel$，$p^{(i)}$需要尽量大</p>
<p><img src="http://ww1.sinaimg.cn/large/006M8Ovlly1g9ie3fs8a6j30ei05k3yv.jpg" alt="大间距分类器.png"></p>
<p>支持向量机会选择后者，因为它有较大的p</p>
<h2 id="内核"><a href="#内核" class="headerlink" title="内核"></a>内核</h2><p><strong>高斯内核</strong></p>
<p><img src="http://ww1.sinaimg.cn/large/006M8Ovlly1g9ieg65ga3j30ag04jglo.jpg" alt="高斯内核.png"></p>
<p>这里的”similarity”函数就是“内核”，这种内核又称为“<strong>高斯内核</strong>”</p>
<p>当x距离$l^{(1)}$越近，$f_1$越接近于1，越远越接近于0</p>
<p><strong>选定l</strong></p>
<p>通常根据训练集的数量选择地标的数量，即如果训练集中有m个实例，则选取m个地标。并且令：$l^{(1)}=x^{(1)}$，…，$l^{(m)}=x^{(m)}$。现在支持向量机的任务是：</p>
<p>$\underbrace{min}_\theta\left\{C\left[\sum_\limits{i=1}^my^{(i)}Cost_1\left(\theta^Tf^{(i)}\right)+\left(1-y^{(i)}\right)Cost_0\left(\theta^Tf^{(i)}\right)\right]+\frac{1}{2}\sum_\limits{j=1}^n\theta_j^2\right\}$</p>
<p>并且对正则化做出调整，计算$\sum_\limits{j=1}^{n=m}\theta^2=\theta^T\theta$时，用$\theta^TM\theta$代替$\theta^T\theta$，其中M是根据我们选择的核函数而不同的一个矩阵，这样做简化了计算。</p>
<p><strong>参数影响</strong></p>
<ul>
<li>C较大，过拟合，高方差</li>
<li>C较小，欠拟合，高偏差</li>
<li>$\sigma$较大，低方差，高偏差</li>
<li>$\sigma$较小，低偏差，高方差</li>
</ul>
<h2 id="SVM使用"><a href="#SVM使用" class="headerlink" title="SVM使用"></a>SVM使用</h2><p><strong>准则</strong></p>
<p>n为特征数，m为训练样本数。</p>
<ul>
<li>n比m大很多，选用逻辑回归模型或者线性支持向量机</li>
<li>n较小，m大小中等，比如n在1-1000之间，m在10-10000之间，使用高斯内核的向量机</li>
<li>n较小，m较大，n在1-1000之间，m&gt;50000，使用支持向量机会很慢，解决方案：创造增加更多的特征，然后使用逻辑回归或者线性内核</li>
<li>一般，支持向量机比神经网络快，因为SVM的代价函数是凸函数，不存在局部最小值</li>
</ul>
<h2 id="Exercise"><a href="#Exercise" class="headerlink" title="Exercise"></a>Exercise</h2><h3 id="线性内核"><a href="#线性内核" class="headerlink" title="线性内核"></a>线性内核</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> sklearn.svm</span><br><span class="line"><span class="keyword">import</span> scipy.io <span class="keyword">as</span> sio</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">mat = sio.loadmat(<span class="string">'./data/ex6data1.mat'</span>)</span><br><span class="line">data = pd.DataFrame(mat.get(<span class="string">'X'</span>), columns=[<span class="string">'X1'</span>, <span class="string">'X2'</span>])</span><br><span class="line">data[<span class="string">'y'</span>] = mat.get(<span class="string">'y'</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># try C=1</span></span><br><span class="line">svc1 = sklearn.svm.LinearSVC(C=<span class="number">1</span>, loss=<span class="string">'hinge'</span>)</span><br><span class="line">svc1.fit(data[[<span class="string">'X1'</span>, <span class="string">'X2'</span>]], data[<span class="string">'y'</span>])</span><br><span class="line"><span class="comment"># 类别预测的置信水平，这是该点与超平面距离的函数。</span></span><br><span class="line">data[<span class="string">'SVM1 Confidence'</span>] = svc1.decision_function(data[[<span class="string">'X1'</span>, <span class="string">'X2'</span>]])</span><br><span class="line"></span><br><span class="line">fig, ax = plt.subplots(figsize=(<span class="number">8</span>,<span class="number">6</span>))</span><br><span class="line">ax.scatter(data[<span class="string">'X1'</span>], data[<span class="string">'X2'</span>], s=<span class="number">50</span>, c=data[<span class="string">'SVM1 Confidence'</span>], cmap=<span class="string">'RdBu'</span>)</span><br><span class="line">ax.set_title(<span class="string">'SVM (C=1) Decision Confidence'</span>)</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line"><span class="comment"># try C=100</span></span><br><span class="line"><span class="comment"># 此时过拟合，decision_function的值变大</span></span><br></pre></td></tr></table></figure>
<p><strong>注意</strong>：svc.decision_function含义，C的取值影响</p>
<h3 id="Gaussion-kernels"><a href="#Gaussion-kernels" class="headerlink" title="Gaussion kernels"></a>Gaussion kernels</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> svm</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> scipy.io <span class="keyword">as</span> sio</span><br><span class="line"></span><br><span class="line"><span class="comment"># kernek function 高斯核函数</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">gaussian_kernel</span><span class="params">(x1, x2, sigma)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> np.exp(- np.power(x1 - x2, <span class="number">2</span>).sum() / (<span class="number">2</span> * (sigma ** <span class="number">2</span>)))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">mat = sio.loadmat(<span class="string">'./data/ex6data2.mat'</span>)</span><br><span class="line">data = pd.DataFrame(mat.get(<span class="string">'X'</span>), columns=[<span class="string">'X1'</span>, <span class="string">'X2'</span>])</span><br><span class="line">data[<span class="string">'y'</span>] = mat.get(<span class="string">'y'</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># matplotlib画出分类图</span></span><br><span class="line"><span class="comment"># positive = data[data['y'].isin([1])]</span></span><br><span class="line"><span class="comment"># negative = data[data['y'].isin([0])]</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment"># fig, ax = plt.subplots(figsize=(12,8))</span></span><br><span class="line"><span class="comment"># ax.scatter(positive['X1'], positive['X2'], s=30, marker='x', label='Positive')</span></span><br><span class="line"><span class="comment"># ax.scatter(negative['X1'], negative['X2'], s=30, marker='o', label='Negative')</span></span><br><span class="line"><span class="comment"># ax.legend()</span></span><br><span class="line"><span class="comment"># plt.show()</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 将使用内置的RBF内核构建支持向量机分类器，并检查其对训练数据的准确性</span></span><br><span class="line">svc = svm.SVC(C=<span class="number">100</span>, kernel=<span class="string">'rbf'</span>, gamma=<span class="number">10</span>, probability=<span class="literal">True</span>)</span><br><span class="line">svc.fit(data[[<span class="string">'X1'</span>, <span class="string">'X2'</span>]], data[<span class="string">'y'</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># the predict_proba显示类别，是positive还是negative</span></span><br><span class="line">predict_prob = svc.predict_proba(data[[<span class="string">'X1'</span>, <span class="string">'X2'</span>]])[:, <span class="number">1</span>]</span><br><span class="line"></span><br><span class="line">fig, ax = plt.subplots(figsize=(<span class="number">8</span>,<span class="number">6</span>))</span><br><span class="line">ax.scatter(data[<span class="string">'X1'</span>], data[<span class="string">'X2'</span>], s=<span class="number">30</span>, c=predict_prob, cmap=<span class="string">'Reds'</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p>注意：画图方法，svc.predict_proba含义</p>
<h3 id="选择参数"><a href="#选择参数" class="headerlink" title="选择参数"></a>选择参数</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> svm</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> GridSearchCV</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> metrics</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> scipy.io <span class="keyword">as</span> sio</span><br><span class="line"></span><br><span class="line">mat = sio.loadmat(<span class="string">'./data/ex6data3.mat'</span>)</span><br><span class="line">training = pd.DataFrame(mat.get(<span class="string">'X'</span>), columns=[<span class="string">'X1'</span>, <span class="string">'X2'</span>])</span><br><span class="line">training[<span class="string">'y'</span>] = mat.get(<span class="string">'y'</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 交叉验证集</span></span><br><span class="line">cv = pd.DataFrame(mat.get(<span class="string">'Xval'</span>), columns=[<span class="string">'X1'</span>, <span class="string">'X2'</span>])</span><br><span class="line">cv[<span class="string">'y'</span>] = mat.get(<span class="string">'yval'</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># manual grid search</span></span><br><span class="line">candidate = [<span class="number">0.01</span>, <span class="number">0.03</span>, <span class="number">0.1</span>, <span class="number">0.3</span>, <span class="number">1</span>, <span class="number">3</span>, <span class="number">10</span>, <span class="number">30</span>, <span class="number">100</span>]</span><br><span class="line">combination = [(C, gamma) <span class="keyword">for</span> C <span class="keyword">in</span> candidate <span class="keyword">for</span> gamma <span class="keyword">in</span> candidate]</span><br><span class="line">search = []</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> C, gamma <span class="keyword">in</span> combination:</span><br><span class="line">    svc = svm.SVC(C=C, gamma=gamma)</span><br><span class="line">    svc.fit(training[[<span class="string">'X1'</span>, <span class="string">'X2'</span>]], training[<span class="string">'y'</span>])</span><br><span class="line">    search.append(svc.score(cv[[<span class="string">'X1'</span>, <span class="string">'X2'</span>]], cv[<span class="string">'y'</span>]))</span><br><span class="line"></span><br><span class="line">best_score = search[np.argmax(search)]</span><br><span class="line">best_param = combination[np.argmax(search)]</span><br><span class="line"></span><br><span class="line">best_svc = svm.SVC(C=<span class="number">100</span>, gamma=<span class="number">0.3</span>)</span><br><span class="line">best_svc.fit(training[[<span class="string">'X1'</span>, <span class="string">'X2'</span>]], training[<span class="string">'y'</span>])</span><br><span class="line">ypred = best_svc.predict(cv[[<span class="string">'X1'</span>, <span class="string">'X2'</span>]])</span><br><span class="line"></span><br><span class="line">print(metrics.classification_report(cv[<span class="string">'y'</span>], ypred))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># sklearn GridSearchCV</span></span><br><span class="line">parameters = &#123;<span class="string">'C'</span>: candidate, <span class="string">'gamma'</span>: candidate&#125;</span><br><span class="line">svc = svm.SVC()</span><br><span class="line">clf = GridSearchCV(svc, parameters, n_jobs=<span class="number">-1</span>)</span><br><span class="line">clf.fit(training[[<span class="string">'X1'</span>, <span class="string">'X2'</span>]], training[<span class="string">'y'</span>])</span><br><span class="line">ypred = clf.predict(cv[[<span class="string">'X1'</span>, <span class="string">'X2'</span>]])</span><br><span class="line">print(metrics.classification_report(cv[<span class="string">'y'</span>], ypred))</span><br></pre></td></tr></table></figure>
<p> 自动搜索与人工搜索搜索得到<strong>参数不同</strong>的原因:<br> 自动搜索只使用了部分training data,把剩余training当做CV.</p>
<h3 id="垃圾邮件分类"><a href="#垃圾邮件分类" class="headerlink" title="垃圾邮件分类"></a>垃圾邮件分类</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> svm</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> metrics</span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LogisticRegression</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> scipy.io <span class="keyword">as</span> sio</span><br><span class="line"></span><br><span class="line">mat_tr = sio.loadmat(<span class="string">'data/spamTrain.mat'</span>)</span><br><span class="line">X, y = mat_tr.get(<span class="string">'X'</span>), mat_tr.get(<span class="string">'y'</span>).ravel()</span><br><span class="line"></span><br><span class="line">mat_test = sio.loadmat(<span class="string">'data/spamTest.mat'</span>)</span><br><span class="line">test_X, test_y = mat_test.get(<span class="string">'Xtest'</span>), mat_test.get(<span class="string">'ytest'</span>).ravel()</span><br><span class="line"></span><br><span class="line">svc = svm.SVC()</span><br><span class="line">svc.fit(X, y)</span><br><span class="line"></span><br><span class="line">pred = svc.predict(test_X)</span><br><span class="line">print(metrics.classification_report(test_y, pred))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 逻辑回归试试</span></span><br><span class="line">logit = LogisticRegression()</span><br><span class="line">logit.fit(X, y)</span><br><span class="line">pred = logit.predict(test_X)</span><br><span class="line">print(metrics.classification_report(test_y, pred))</span><br></pre></td></tr></table></figure>
<h1 id="无监督学习"><a href="#无监督学习" class="headerlink" title="无监督学习"></a>无监督学习</h1><h2 id="K-means"><a href="#K-means" class="headerlink" title="K-means"></a>K-means</h2><h3 id="算法步骤"><a href="#算法步骤" class="headerlink" title="算法步骤"></a>算法步骤</h3><p>随机选择K个聚类中心</p>
<p>重复{</p>
<ol>
<li>将所有样本点划分在这K类中</li>
<li>在每个类中重新计算聚类中心</li>
</ol>
<p>}直至聚类中心不再变化</p>
<h3 id="优化目标"><a href="#优化目标" class="headerlink" title="优化目标"></a>优化目标</h3><p>符号：</p>
<p>$c^{(i)}$—样本$x^{(i)}$当前所属的类</p>
<p>$\mu_k$—第k个类别的中心</p>
<p>$\mu_c^{(i)}$—样本x(i)所属类的聚类中心</p>
<p>目标：$\underbrace \min _{c^{( 1 )},…,c^{( m )},\mu _1,…,\mu _K}J( c^{( 1 )},…,c^{( m )},\mu _1,…,\mu _K ) = \frac{1}{m}\sum\limits_{i = 1}^m \parallel x^{(i)}-\mu_c^{(i)} \parallel^2$</p>
<h3 id="随机初始化"><a href="#随机初始化" class="headerlink" title="随机初始化"></a>随机初始化</h3><p>通常多次运行K-means算法，选取代价函数最小的结果。当K=(2-10)时可行。若K值较大，这么做也可能不会有明显改善</p>
<h3 id="K值选择"><a href="#K值选择" class="headerlink" title="K值选择"></a>K值选择</h3><ul>
<li>“肘部法则”</li>
</ul>
<p><img src="http://ww1.sinaimg.cn/large/006M8Ovlly1g9ii4rukprj309f060q3a.jpg" alt="肘部法则.png"></p>
<ul>
<li>根据聚类后的“后续目的”人工选择</li>
</ul>

          
        
      
    </div>
    
    
    

    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/11/15/Tensorflow2.0与深度学习/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Kason">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/westbrook.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Kason's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/11/15/Tensorflow2.0与深度学习/" itemprop="url">Tensorflow2.0</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-11-15T18:02:28+08:00">
                2019-11-15
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/深度学习/" itemprop="url" rel="index">
                    <span itemprop="name">深度学习</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2019/11/15/Tensorflow2.0与深度学习/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count valine-comment-count" data-xid="/2019/11/15/Tensorflow2.0与深度学习/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="Tensorflow-基础"><a href="#Tensorflow-基础" class="headerlink" title="Tensorflow 基础"></a>Tensorflow 基础</h1><h2 id="数据类型"><a href="#数据类型" class="headerlink" title="数据类型"></a>数据类型</h2><h3 id="数值类型"><a href="#数值类型" class="headerlink" title="数值类型"></a>数值类型</h3><p>在Tensorflow中，为了表示方便，一般把标量、向量、矩阵统称为<strong>张量（Tensor）</strong></p>
<ul>
<li>通过打印张量信息，得到</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">In [2]: x = tf.constant([1,2.,3.3])</span><br><span class="line">x</span><br><span class="line"></span><br><span class="line">Out[2]:</span><br><span class="line">&lt;tf.Tensor: id=165, shape=(3,), dtype=float32, numpy=array([1. , 2. , 3.3],</span><br><span class="line">dtype=float32)&gt;</span><br></pre></td></tr></table></figure>
<ul>
<li>其中id是TensorFlow中内部索引对象的编号，shape表示张量的形状，dtype表示张量的精度，张量numpy（）方法可以返回Numpy.array类型的数据</li>
<li>x.numpy() 返回Numpy.array类型的数据</li>
<li>tf.constant([[1,2], [3,4]])  定义2维张量</li>
</ul>
<h3 id="字符串类型"><a href="#字符串类型" class="headerlink" title="字符串类型"></a>字符串类型</h3><p>提供常见的join()，length()，split()，lower()等工具函数</p>
<h3 id="布尔类型"><a href="#布尔类型" class="headerlink" title="布尔类型"></a>布尔类型</h3><ul>
<li>Tensorflow的布尔类型和Python语言的布尔类型不对等</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">In [11]:</span><br><span class="line">a = tf.constant(True) # 创建布尔张量</span><br><span class="line">a == True</span><br><span class="line"></span><br><span class="line">Out[11]:</span><br><span class="line">False</span><br></pre></td></tr></table></figure>
<h2 id="数值精度"><a href="#数值精度" class="headerlink" title="数值精度"></a>数值精度</h2>
          
        
      
    </div>
    
    
    

    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/11/13/Learning Geo-Social User Topical Profiles with Bayesian Hierarchical User Factorization/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Kason">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/westbrook.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Kason's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/11/13/Learning Geo-Social User Topical Profiles with Bayesian Hierarchical User Factorization/" itemprop="url">Learning Geo-Social User Topical Profiles with Bayesian Hierarchical User Factorization</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-11-13T20:25:47+08:00">
                2019-11-13
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/论文合集/" itemprop="url" rel="index">
                    <span itemprop="name">论文合集</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2019/11/13/Learning Geo-Social User Topical Profiles with Bayesian Hierarchical User Factorization/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count valine-comment-count" data-xid="/2019/11/13/Learning Geo-Social User Topical Profiles with Bayesian Hierarchical User Factorization/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="Title"><a href="#Title" class="headerlink" title="Title"></a>Title</h1><p> 使用<strong>贝叶斯分层用户分解</strong>学习地理-社交用户主题画像 </p>
<h2 id="Research-Objective"><a href="#Research-Objective" class="headerlink" title="Research Objective"></a>Research Objective</h2><p>在社会空间系统中，实现地理位置和用户画像的交互</p>
<p>给出已观测到的用户地理画像，对user的tag-location进行ranking预测未知的画像</p>
<h2 id="Background-and-Problems"><a href="#Background-and-Problems" class="headerlink" title="Background and Problems"></a>Background and Problems</h2><ol>
<li><p>虽然很多现有用户画像关注的每个用户的全局视角，但仍有一些重要的地缘社会因素需要考虑</p>
<ul>
<li><p>每个用户在不同地方被不同感知</p>
</li>
<li><p>具有相似画像的用户可能有巨大的地缘影响差异</p>
</li>
</ul>
</li>
<li><strong>建模地理画像挑战</strong></li>
</ol>
<p>可以采用BPTF（贝叶斯泊松张量分解）进行预测，但存在如下问题：</p>
<ul>
<li>经常分散，由于用户异质性，地理画像中的受欢迎程度计数存在很大差异</li>
<li><p>由于多维性，通常非常稀疏</p>
<ol>
<li>先前研究</li>
</ol>
</li>
<li><p>先前研究大多集中在揭示用户的主题画像或潜在兴趣，没有明确考虑地缘社会因素。</p>
</li>
<li>新兴的研究方向侧重于用Gamma-Poisson分布代替传统的高斯分布对离散数据建模</li>
<li>利用各种背景信号来改善学习。包括文本、社交网络等</li>
</ul>
<h2 id="Method-s"><a href="#Method-s" class="headerlink" title="Method(s)"></a>Method(s)</h2><ol>
<li>为了克服异质性，提出了一个两层的贝叶斯层级用户分解生成框架（bHUF），该框架很容易推广到深度用户分解。</li>
<li>为了减少稀疏性，研究用户上下文（特别是地理位置和社会关系），针对多层因式分解方案的非共轭性,提出一个增强模型（bHUF+）。然后，使用NB分布的数据增强方案，开发一种有效的封闭式<strong>吉布斯抽样</strong>方案进行推理</li>
</ol>
<ul>
<li>两层贝叶斯分层用户分解，将泊松伽马信念网络从二维非负计数推广到多维异构计数。与单层分解相比，用户分解的额外层通过允许更大的用户地理位置分布方差-均值比，比单层具有的学习。更好地处理过度分散和用户异质性。</li>
</ul>
<h2 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h2><p>作者给了哪些结论，哪些是strong conclusions,哪些是weak的conclusions？哪些构思？</p>
<p>根据GPS标记的Twitter数据集上的几个基线，对bHUF和bHUF+进行了评估，观察到bHUF在最佳替代单层基线的精确度和召回率上提高了约5%~13%，对用户地理位置和社会环境的改善率提高了6%~11% </p>
<h2 id="Evaluation"><a href="#Evaluation" class="headerlink" title="Evaluation"></a>Evaluation</h2><p>作者如何评估自己的方法，实验的setup是什么样的，有没有问题或者可以借鉴的地方</p>
<p>数据来源+重要指标+模型步骤+每个步骤得出的结论</p>
<h2 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h2><p>写完笔记之后最后填，概述文章的内容。切记需要通过自己的思考，用自己的语言描述</p>
<h2 id="Notes"><a href="#Notes" class="headerlink" title="Notes"></a>Notes</h2><p>额外笔记</p>
<h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><p>(optional)列出相关性高的文献，一遍之后可以继续track</p>

          
        
      
    </div>
    
    
    

    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/11/13/推荐系统可解释性/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Kason">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/westbrook.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Kason's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/11/13/推荐系统可解释性/" itemprop="url">推荐系统可解释性</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-11-13T19:03:58+08:00">
                2019-11-13
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/推荐系统/" itemprop="url" rel="index">
                    <span itemprop="name">推荐系统</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2019/11/13/推荐系统可解释性/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count valine-comment-count" data-xid="/2019/11/13/推荐系统可解释性/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h1><p><strong>解释的两个维度：</strong></p>
<ul>
<li>显示样式（display style）：<ul>
<li>相关用户或项目</li>
<li>用户或项目特征</li>
<li>文本解释</li>
<li>图像解释</li>
<li>社会解释</li>
<li>词簇</li>
</ul>
</li>
<li>模型/方法<ul>
<li>基于邻域    </li>
<li>矩阵分解</li>
<li>主题建模</li>
<li>基于图</li>
<li>深度学习</li>
<li>知识图谱</li>
<li>关联分析</li>
</ul>
</li>
</ul>
<p><strong>两种可解释性：</strong></p>
<ol>
<li>以人为方式工作的可解释模型。目前大多数属于这一类</li>
<li>只关注产品，将推荐模型视为一个复杂的黑盒。称为事后可解释性。</li>
</ol>
<p><strong>可解释性与时效性：</strong></p>
<p>近些年的研究表明，这两项并不冲突，可以使用深度学习等方法来解决。</p>
<p><img src="http://ww1.sinaimg.cn/large/006M8Ovlly1g9p9hjwjl9j30qx0gs77g.jpg" alt="推荐解释.png"></p>
<h1 id="不同显示风格的解释"><a href="#不同显示风格的解释" class="headerlink" title="不同显示风格的解释"></a>不同显示风格的解释</h1><p><strong>基于相关用户和项目的解释</strong></p>
<p>协同过滤和基于相关商品的解释</p>
<p>存在信任性和可依赖性问题，因为我并不认识相似用户。</p>
<p><strong>基于特征的解释</strong></p>
<p>基于特征与基于内容密切相关，推荐与用户目标文件匹配的项目特征作为解释</p>
<ol>
<li>采用标签解释</li>
<li>雷达图</li>
</ol>
<p><strong>基于文本解释</strong></p>
<p>可以分为两个方面</p>
<ul>
<li>Aspect-level 类似基于功能的解释，通常不直接提供aspect，而是从用户意见、评论中提取。</li>
</ul>
<ol>
<li><p>为了提取aspect，采用 方面-观点-情感三元组</p>
</li>
<li><p>或者采用主题建模的方法。生成词云，从几个角度进行推荐</p>
</li>
</ol>
<ul>
<li>sentence-level</li>
</ul>
<ol>
<li><p>可以基于模板，生成句子进行推荐。</p>
</li>
<li><p>无模板，基于自然语言生成模型直接生成。将众包和计算相结合，生成个性化的自然语言解释</p>
</li>
</ol>
<p><strong>图像解释</strong></p>
<p>通过整个图像或图像中特定视觉亮点作为解释</p>
<ol>
<li>运用于衣服推荐（对某种样式特别钟爱）等，目前处于起步阶段。</li>
</ol>
<p><strong>社会解释</strong></p>
<p>依据目标用户的社交关系提供解释，有助于提高用户对推荐的信任</p>
<ol>
<li>地理-社会推荐</li>
<li>基于深交网络的小组推荐</li>
</ol>
<h1 id="推荐解释模型"><a href="#推荐解释模型" class="headerlink" title="推荐解释模型"></a>推荐解释模型</h1><h2 id="矩阵分解"><a href="#矩阵分解" class="headerlink" title="矩阵分解"></a>矩阵分解</h2><ol>
<li>Explicit Factor Models(EFM)  推荐用户关心的特征表现好的产品</li>
<li>学习基于张量分解学习对可解释推荐的特征进行排序</li>
<li>张量分解多任务学习，“用户偏好建模”和“有针对性的内容建模”被整合</li>
<li>Explainable Matrix Factorization(EMF) 基于用户项评级矩阵提供可解释的建议</li>
</ol>
<h2 id="主题建模"><a href="#主题建模" class="headerlink" title="主题建模"></a>主题建模</h2><p>基于可用的文本信息。主题建模通常以主题词云的形式为用户提供直观的解释</p>
<ol>
<li>FLAME model(Factorized Latent Aspect Model) 了解用户对商品不同方面的不同看法。 在词云中显示与其情感成正比的方面进行解释</li>
<li>同时利用社会评论和可信赖的社会关系来改善评分预测</li>
</ol>
<h2 id="基于图的推荐解释"><a href="#基于图的推荐解释" class="headerlink" title="基于图的推荐解释"></a>基于图的推荐解释</h2><ol>
<li>在top-N推荐中引入 user-item-aspect三元关系。对三元图的顶点进行排名。</li>
<li>不使用外部信息下，基于用户-项目聚类得到推荐。</li>
</ol>
<h2 id="深度学习"><a href="#深度学习" class="headerlink" title="深度学习"></a>深度学习</h2><ol>
<li>在文本评论中使用CNN对用户的偏好和商品属性进行建模。有选择地从具有不同注意权重的评论中选择单词，通过获得的注意权重，指出哪个部分更重要。可以突出相关词作为解释。</li>
<li>基于字符级RNN结构自动生成自然语言解释。</li>
<li>结合众包和计算的过程，生成个性化自然语言解释</li>
<li>为突出显示的图像区域生成自然语言解释</li>
<li>基于自然语言生成的可解释推荐</li>
</ol>
<h2 id="知识库嵌入"><a href="#知识库嵌入" class="headerlink" title="知识库嵌入"></a>知识库嵌入</h2><ol>
<li>构造用户-物品知识图，通过知识图找到从用户到推荐商品的最短路径来进行解释</li>
</ol>
<h2 id="关联规则挖掘"><a href="#关联规则挖掘" class="headerlink" title="关联规则挖掘"></a>关联规则挖掘</h2><h2 id="事后解释"><a href="#事后解释" class="headerlink" title="事后解释"></a>事后解释</h2><p>有时推荐解释不是从推荐模型本身生成的。它是在推荐模型推荐了某个项目之后，由解释模型生成的。</p>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><ol>
<li>以人为方式工作的可解释模型。目前大多数属于这一类</li>
<li>只关注产品，将推荐模型视为一个复杂的黑盒。称为事后可解释性</li>
</ol>

          
        
      
    </div>
    
    
    

    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
  </section>

  
  <nav class="pagination">
    <span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><a class="extend next" rel="next" href="/page/2/"><i class="fa fa-angle-right"></i></a>
  </nav>



          </div>
          


          

        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      

      <section class="site-overview-wrap sidebar-panel sidebar-panel-active">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <img class="site-author-image" itemprop="image" src="/images/westbrook.jpg" alt="Kason">
            
              <p class="site-author-name" itemprop="name">Kason</p>
              <p class="site-description motion-element" itemprop="description">Kason's technology blog</p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives/">
              
                  <span class="site-state-item-count">13</span>
                  <span class="site-state-item-name">日志</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-categories">
                <a href="/categories/index.html">
                  <span class="site-state-item-count">5</span>
                  <span class="site-state-item-name">分类</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-tags">
                <a href="/tags/index.html">
                  <span class="site-state-item-count">8</span>
                  <span class="site-state-item-name">标签</span>
                </a>
              </div>
            

          </nav>

          

          
            <div class="links-of-author motion-element">
                
                  <span class="links-of-author-item">
                    <a href="https://github.com/Kasonreal" target="_blank" title="GitHub">
                      
                        <i class="fa fa-fw fa-github"></i>GitHub</a>
                  </span>
                
                  <span class="links-of-author-item">
                    <a href="mailto:shiyuxiang99@163.com" target="_blank" title="E-Mail">
                      
                        <i class="fa fa-fw fa-envelope"></i>E-Mail</a>
                  </span>
                
            </div>
          

          
          

          
          
            <div class="links-of-blogroll motion-element links-of-blogroll-block">
              <div class="links-of-blogroll-title">
                <i class="fa  fa-fw fa-link"></i>
                Links
              </div>
              <ul class="links-of-blogroll-list">
                
                  <li class="links-of-blogroll-item">
                    <a href="https://tristone13th.github.io/" title="云中君" target="_blank">云中君</a>
                  </li>
                
                  <li class="links-of-blogroll-item">
                    <a href="http://101.201.69.42/" title="木偶" target="_blank">木偶</a>
                  </li>
                
              </ul>
            </div>
          

          

        </div>
      </section>

      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2020</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Kason</span>

  
</div>


  <div class="powered-by">由 <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a> 强力驱动</div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">主题 &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Gemini</a> v5.1.4</div>




        







        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  


  <script type="text/javascript" src="/js/src/affix.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/schemes/pisces.js?v=5.1.4"></script>



  

  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  


  




	





  





  










  <script src="//cdn1.lncld.net/static/js/3.0.4/av-min.js"></script>
  <script src="//unpkg.com/valine/dist/Valine.min.js"></script>
  
  <script type="text/javascript">
    var GUEST = ['nick','mail','link'];
    var guest = 'nick,mail,link';
    guest = guest.split(',').filter(item=>{
      return GUEST.indexOf(item)>-1;
    });
    new Valine({
        el: '#comments' ,
        verify: false,
        notify: false,
        appId: 'R4rICLTQsNXFhLpVLOKUtwY8-MdYXbMMI',
        appKey: 'a3s2kYOiN3ocHpSSUvnOw2BM',
        placeholder: '来说两句吧',
        avatar:'mm',
        guest_info:guest,
        pageSize:'10' || 10,
    });
  </script>



  

  <script type="text/javascript">
    // Popup Window;
    var isfetched = false;
    var isXml = true;
    // Search DB path;
    var search_path = "search.xml";
    if (search_path.length === 0) {
      search_path = "search.xml";
    } else if (/json$/i.test(search_path)) {
      isXml = false;
    }
    var path = "/" + search_path;
    // monitor main search box;

    var onPopupClose = function (e) {
      $('.popup').hide();
      $('#local-search-input').val('');
      $('.search-result-list').remove();
      $('#no-result').remove();
      $(".local-search-pop-overlay").remove();
      $('body').css('overflow', '');
    }

    function proceedsearch() {
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay"></div>')
        .css('overflow', 'hidden');
      $('.search-popup-overlay').click(onPopupClose);
      $('.popup').toggle();
      var $localSearchInput = $('#local-search-input');
      $localSearchInput.attr("autocapitalize", "none");
      $localSearchInput.attr("autocorrect", "off");
      $localSearchInput.focus();
    }

    // search function;
    var searchFunc = function(path, search_id, content_id) {
      'use strict';

      // start loading animation
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay">' +
          '<div id="search-loading-icon">' +
          '<i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>' +
          '</div>' +
          '</div>')
        .css('overflow', 'hidden');
      $("#search-loading-icon").css('margin', '20% auto 0 auto').css('text-align', 'center');

      $.ajax({
        url: path,
        dataType: isXml ? "xml" : "json",
        async: true,
        success: function(res) {
          // get the contents from search data
          isfetched = true;
          $('.popup').detach().appendTo('.header-inner');
          var datas = isXml ? $("entry", res).map(function() {
            return {
              title: $("title", this).text(),
              content: $("content",this).text(),
              url: $("url" , this).text()
            };
          }).get() : res;
          var input = document.getElementById(search_id);
          var resultContent = document.getElementById(content_id);
          var inputEventFunction = function() {
            var searchText = input.value.trim().toLowerCase();
            var keywords = searchText.split(/[\s\-]+/);
            if (keywords.length > 1) {
              keywords.push(searchText);
            }
            var resultItems = [];
            if (searchText.length > 0) {
              // perform local searching
              datas.forEach(function(data) {
                var isMatch = false;
                var hitCount = 0;
                var searchTextCount = 0;
                var title = data.title.trim();
                var titleInLowerCase = title.toLowerCase();
                var content = data.content.trim().replace(/<[^>]+>/g,"");
                var contentInLowerCase = content.toLowerCase();
                var articleUrl = decodeURIComponent(data.url);
                var indexOfTitle = [];
                var indexOfContent = [];
                // only match articles with not empty titles
                if(title != '') {
                  keywords.forEach(function(keyword) {
                    function getIndexByWord(word, text, caseSensitive) {
                      var wordLen = word.length;
                      if (wordLen === 0) {
                        return [];
                      }
                      var startPosition = 0, position = [], index = [];
                      if (!caseSensitive) {
                        text = text.toLowerCase();
                        word = word.toLowerCase();
                      }
                      while ((position = text.indexOf(word, startPosition)) > -1) {
                        index.push({position: position, word: word});
                        startPosition = position + wordLen;
                      }
                      return index;
                    }

                    indexOfTitle = indexOfTitle.concat(getIndexByWord(keyword, titleInLowerCase, false));
                    indexOfContent = indexOfContent.concat(getIndexByWord(keyword, contentInLowerCase, false));
                  });
                  if (indexOfTitle.length > 0 || indexOfContent.length > 0) {
                    isMatch = true;
                    hitCount = indexOfTitle.length + indexOfContent.length;
                  }
                }

                // show search results

                if (isMatch) {
                  // sort index by position of keyword

                  [indexOfTitle, indexOfContent].forEach(function (index) {
                    index.sort(function (itemLeft, itemRight) {
                      if (itemRight.position !== itemLeft.position) {
                        return itemRight.position - itemLeft.position;
                      } else {
                        return itemLeft.word.length - itemRight.word.length;
                      }
                    });
                  });

                  // merge hits into slices

                  function mergeIntoSlice(text, start, end, index) {
                    var item = index[index.length - 1];
                    var position = item.position;
                    var word = item.word;
                    var hits = [];
                    var searchTextCountInSlice = 0;
                    while (position + word.length <= end && index.length != 0) {
                      if (word === searchText) {
                        searchTextCountInSlice++;
                      }
                      hits.push({position: position, length: word.length});
                      var wordEnd = position + word.length;

                      // move to next position of hit

                      index.pop();
                      while (index.length != 0) {
                        item = index[index.length - 1];
                        position = item.position;
                        word = item.word;
                        if (wordEnd > position) {
                          index.pop();
                        } else {
                          break;
                        }
                      }
                    }
                    searchTextCount += searchTextCountInSlice;
                    return {
                      hits: hits,
                      start: start,
                      end: end,
                      searchTextCount: searchTextCountInSlice
                    };
                  }

                  var slicesOfTitle = [];
                  if (indexOfTitle.length != 0) {
                    slicesOfTitle.push(mergeIntoSlice(title, 0, title.length, indexOfTitle));
                  }

                  var slicesOfContent = [];
                  while (indexOfContent.length != 0) {
                    var item = indexOfContent[indexOfContent.length - 1];
                    var position = item.position;
                    var word = item.word;
                    // cut out 100 characters
                    var start = position - 20;
                    var end = position + 80;
                    if(start < 0){
                      start = 0;
                    }
                    if (end < position + word.length) {
                      end = position + word.length;
                    }
                    if(end > content.length){
                      end = content.length;
                    }
                    slicesOfContent.push(mergeIntoSlice(content, start, end, indexOfContent));
                  }

                  // sort slices in content by search text's count and hits' count

                  slicesOfContent.sort(function (sliceLeft, sliceRight) {
                    if (sliceLeft.searchTextCount !== sliceRight.searchTextCount) {
                      return sliceRight.searchTextCount - sliceLeft.searchTextCount;
                    } else if (sliceLeft.hits.length !== sliceRight.hits.length) {
                      return sliceRight.hits.length - sliceLeft.hits.length;
                    } else {
                      return sliceLeft.start - sliceRight.start;
                    }
                  });

                  // select top N slices in content

                  var upperBound = parseInt('1');
                  if (upperBound >= 0) {
                    slicesOfContent = slicesOfContent.slice(0, upperBound);
                  }

                  // highlight title and content

                  function highlightKeyword(text, slice) {
                    var result = '';
                    var prevEnd = slice.start;
                    slice.hits.forEach(function (hit) {
                      result += text.substring(prevEnd, hit.position);
                      var end = hit.position + hit.length;
                      result += '<b class="search-keyword">' + text.substring(hit.position, end) + '</b>';
                      prevEnd = end;
                    });
                    result += text.substring(prevEnd, slice.end);
                    return result;
                  }

                  var resultItem = '';

                  if (slicesOfTitle.length != 0) {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + highlightKeyword(title, slicesOfTitle[0]) + "</a>";
                  } else {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + title + "</a>";
                  }

                  slicesOfContent.forEach(function (slice) {
                    resultItem += "<a href='" + articleUrl + "'>" +
                      "<p class=\"search-result\">" + highlightKeyword(content, slice) +
                      "...</p>" + "</a>";
                  });

                  resultItem += "</li>";
                  resultItems.push({
                    item: resultItem,
                    searchTextCount: searchTextCount,
                    hitCount: hitCount,
                    id: resultItems.length
                  });
                }
              })
            };
            if (keywords.length === 1 && keywords[0] === "") {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-search fa-5x" /></div>'
            } else if (resultItems.length === 0) {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-frown-o fa-5x" /></div>'
            } else {
              resultItems.sort(function (resultLeft, resultRight) {
                if (resultLeft.searchTextCount !== resultRight.searchTextCount) {
                  return resultRight.searchTextCount - resultLeft.searchTextCount;
                } else if (resultLeft.hitCount !== resultRight.hitCount) {
                  return resultRight.hitCount - resultLeft.hitCount;
                } else {
                  return resultRight.id - resultLeft.id;
                }
              });
              var searchResultList = '<ul class=\"search-result-list\">';
              resultItems.forEach(function (result) {
                searchResultList += result.item;
              })
              searchResultList += "</ul>";
              resultContent.innerHTML = searchResultList;
            }
          }

          if ('auto' === 'auto') {
            input.addEventListener('input', inputEventFunction);
          } else {
            $('.search-icon').click(inputEventFunction);
            input.addEventListener('keypress', function (event) {
              if (event.keyCode === 13) {
                inputEventFunction();
              }
            });
          }

          // remove loading animation
          $(".local-search-pop-overlay").remove();
          $('body').css('overflow', '');

          proceedsearch();
        }
      });
    }

    // handle and trigger popup window;
    $('.popup-trigger').click(function(e) {
      e.stopPropagation();
      if (isfetched === false) {
        searchFunc(path, 'local-search-input', 'local-search-result');
      } else {
        proceedsearch();
      };
    });

    $('.popup-btn-close').click(onPopupClose);
    $('.popup').click(function(e){
      e.stopPropagation();
    });
    $(document).on('keyup', function (event) {
      var shouldDismissSearchPopup = event.which === 27 &&
        $('.search-popup').is(':visible');
      if (shouldDismissSearchPopup) {
        onPopupClose();
      }
    });
  </script>





  
  

  

  
  

  
  
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
        }
      });
    </script>

    <script type="text/x-mathjax-config">
      MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
      });
    </script>
    <script type="text/javascript" src="//cdn.bootcss.com/mathjax/2.7.1/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
  


  

  

</body>
</html>
